---
title: "ARIMAX SARIMAX VAR"
author: "Corwin Dark" 
engine: knitr         
---


<h2> Planning Models </h2>

We have the following independent variables:
1. Interest Rate Expectation Changes - 3 Months 
2. Interest Rate Expectation Changes - 6 Months 
3. Interest Rate Expectation Changes - 1 Year
4. Extreme Weather Events - Daily Event Number
5. Extreme Weather Events - Daily Property Damage
6. Extreme Weather Events - Daily Casualties
7. Extreme Weather Events - Hurricanes
8. Expected Volatility (VIX) - Value
9. Expected Volatility (VIX) - Daily Change
10. Work Stoppages - Daily Striking Worker Total
11. Work Stoppages - Daily New Strike Beggining
12. Work Stoppages - Daily New Workers Striking




<h3> Preparing Exogenous Data </h3>

First we need to create all 12 predictors, then we can combine them to estimate the models as needed.
```{r}
library(knitr)
library(tidyverse)
library(quantmod)
library(forecast)
library(tseries)
library(lubridate)
library(reticulate)
```

Let's  quickly retrieve the daily stock price ranges for the indices:
```{r}
spyIn <- quantmod::getSymbols("SPY", from = as.Date("2021/01/01"), to = as.Date("2023/09/30"), periodicity = "daily", src = "yahoo", auto.assign = FALSE)
qqqIn <- quantmod::getSymbols("QQQ", from = as.Date("2021/01/01"), to = as.Date("2023/09/30"), periodicity = "daily", src = "yahoo", auto.assign = FALSE)
iwmIn <- quantmod::getSymbols("IWM", from = as.Date("2021/01/01"), to = as.Date("2023/09/30"), periodicity = "daily", src = "yahoo", auto.assign = FALSE)


spyIn$spyRange <- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open
qqqIn$qqqRange <- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open
iwmIn$iwmRange <- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open
```

Now, let's gather the VIX data, since it is also treated like a stock price, and should be available from the same package
```{r}
vixIn <- quantmod::getSymbols("^VIX", from = as.Date("2021/01/01"), to = as.Date("2023/09/30"), periodicity = "daily", src = "yahoo", auto.assign = FALSE)

vixIn$dailyChange <- vixIn$VIX.Close - lag(vixIn$VIX.Close)
# 8 is vixIn$VIX.Close
# 9 is vixIn$dailyChange

#vixIn <- vixIn %>% 
#    mutate(date = ymd(index(vixIn)))
head(vixIn)
```

We have bond yields stored in a CSV, but let's calculate daily changes:
```{r}
yieldCurve <- read.csv('data/treasuries.csv')

yieldCurve$mo3delta <- yieldCurve$X3.Mo - lag(yieldCurve$X3.Mo)
yieldCurve$mo6delta <- yieldCurve$X6.Mo - lag(yieldCurve$X6.Mo)
yieldCurve$mo12delta <- yieldCurve$X1.Yr - lag(yieldCurve$X1.Yr) 

yieldCurve$Date <- mdy(yieldCurve$Date)
```

Worth noting: Both the treasury data and the VIX data only start on January 4th.


Next up, let's prepare the weather event data:
```{r}
weather_data <- read.csv('data/storms_clean.csv')


weather_data$month <- weather_data$BEGIN_YEARMONTH %% 100

weather_data <- weather_data %>%
    mutate(realdate = make_date(YEAR, month, BEGIN_DAY)) %>%
    mutate(DAMAGE_PROPERTY =  str_replace(DAMAGE_PROPERTY, "K", "") )  %>%
    mutate(DAMAGE_PROPERTY = as.numeric(DAMAGE_PROPERTY)) %>%
    mutate(DAMAGE_PROPERTY = replace_na(DAMAGE_PROPERTY, 0))


# Daily Event Number
daily_events <- weather_data %>%
    group_by(realdate) %>%
    summarize(events = length(EPISODE_ID))

# Daily Property Damage
daily_property <-  weather_data %>%
    group_by(realdate) %>%
    summarize(pdam = sum(DAMAGE_PROPERTY))

# Daily Daily Casualties
daily_casualties <-  weather_data %>%
    group_by(realdate) %>%
    summarize(casualties = sum(INJURIES_DIRECT) + sum(INJURIES_INDIRECT) + sum(DEATHS_DIRECT) + sum(DEATHS_INDIRECT))

# Daily Hurricanes
daily_hurricanes <- weather_data %>%
    filter(EVENT_TYPE == "Hurricane") %>%
    group_by(realdate) %>%
    summarize(hurricaneWarnings = length(EPISODE_ID))


# Daily joined data

weather_merged <- full_join(daily_events, daily_property, by = "realdate")
weather_merged <- full_join(weather_merged, daily_casualties, by = 'realdate')
weather_merged <- full_join(weather_merged, daily_hurricanes, by = 'realdate')

head(weather_merged)
```

Finally, lets get the striking worker data ready:
```{r}
strike_data <- read.csv('data/strikes.csv')

# clean date format
strike_data$start = mdy(strike_data$Work.stoppage.beginning.date)
strike_data$end = mdy(strike_data$Work.stoppage.ending.date)
strike_data$workers = as.numeric(str_replace(strike_data$Number.of.workers.2., ",", "" ))


head(strike_data)

target_dates <- ymd(index(spyIn))

daily_workers <- vector(mode = "numeric", length = length(target_dates))

for(i in seq_along(target_dates)) {
    tempDat <- strike_data %>%
        filter(start <= target_dates[i]) %>%
        filter(end >= target_dates[i])

    daily_workers[i] = sum(tempDat$workers)
}

workerDF <- data.frame('workers' = daily_workers, 'date' = target_dates)
plot(daily_workers, type = 'l')
     
```

Now, we can combined all of these datasets into one dataframe, joining on the date columns
```{r}
# Convert TS objects to df, and fix the date column
vixDF <- data.frame(vixIn)
vixDF$date <- ymd(index(vixIn))
spyDF <- data.frame(spyIn)
spyDF$date <- ymd(index(spyIn))
qqqDF <- data.frame(qqqIn)
qqqDF$date <- ymd(index(qqqIn))
iwmDF <- data.frame(iwmIn)
iwmDF$date <- ymd(index(iwmIn))

# Join symbols together
tickers <- left_join(spyDF, vixDF, by = 'date')
tickers <- left_join(tickers, qqqDF, by = 'date')
tickers <- left_join(tickers, iwmDF, by = 'date')

# Join weather data
combinedData <- left_join(tickers, weather_merged, by = c("date" = "realdate"))

# Join Bond Yields
combinedData <- left_join(combinedData, yieldCurve, by = c("date" = "Date"))

# Join Labor Data
combinedData <- left_join(combinedData, workerDF, by = 'date')

head(combinedData)


```


<h3> Select Models Based on These Exogenous Variables </h3>

We will combine these 12 predictors into 5 models, for SPY, QQQ, and IWM intraday volatility:

<h4> Model 1: (ARIMAX) SPY ~ Interest Rate 1-Year + Daily Weather Property Damage + Daily VIX Change + Daily Striking Worker Total </h2>

This model is selected based on the literature review, which suggested that weather events and investor expecations could affect stock prices. This is the "kitchen sink" model, where I am throwing in variables from all data sources. However, looking at the variables individually, such as daily property damage vs. SPY daily price range, we don't nessecarily see clear correlation (see plot below which resembles white noise). But I am interested to see how these variables are related when taking many different contextual factors into account in the same model.

```{r}
ggplot(combinedData, aes(x = log(spyRange), y = log(pdam)) ) + geom_point() + labs(title = "3 Month Interest Rate Changes vs. VIX Change ", x = "Log SPY Daily Spread", y = "Log Property Damage From Storms")
```


<h4> Model 2: (VAR) SPY ~ Interest Rate 3-Months + Daily VIX Value </h4>

This model is based on a belief that there is an interrelationship between VIX prices and bond yields. This is because both would increase and decrease based on investor expectations for macroeconomic performance in upcoming months. If investors feel the economy will perform poorly, then this might predict bond yields lowering, as well as increased volatility which would be reflected by increases in the VIX. We also see a weak linear correlation in these daily values, as pictured in the plot below. 

```{r}
ggplot(combinedData, aes(x = mo3delta, y = dailyChange ) ) + geom_point() + labs(title = "3 Month Interest Rate Changes vs. VIX Change ", x = "Change in 3-Month Interest Rates", y = "Change in VIX Price")
```

<h4> Model 3: (ARIMAX) IWM ~ Casualties + Hurricanes + Interest Rate 3-Months </h4>

This model is all about exogenous shocks. New strikes beggining and hurricane warnings are infrequent but extreme events, which have been grouped together with short-term interest rates (3 month window) to try and capture extreme-but-short-termm influences on volatility.

<h4> Model 4: (ARIMAX) QQQ ~ All Interest Rates + All Extreme Weather Events + Daily VIX Change + Daily Striking Workers </h4>
<h4> Model 5: (ARIMAX) QQQ ~ Interest Rate 3 months + Daily Property Damage + Daily VIX Change + Daily New Striking Workers </h4>

Models 4 and 5 follow the same logic as model 1, being selected based off of the literature review, but looking at QQQ as oppposed to SPY to see whether large-cap tech companies are more likely to be affected by this kind of volatility.

<h2> Model Selection </h2>

In this section, I will begin by identifying the candidate model structures for each of the 5 overarching models outlined above. I will identify candidate models through auto.arima for ARIMAX models, plus hand-selected values. For VAR models, I will identify 2 candidates for each overall model with the autoVAR function.

<h3> Model Selection for ARIMAX Models </h3>



<h4> Model 1: SPY ~ Interest Rate 1-Year + Daily Weather Property Damage + Daily VIX Change + Daily Striking Worker Total </h2>
```{r}

xMatrix = combinedData[,c('mo12delta', 'pdam', 'dailyChange', 'workers')]
xMatrix[is.na(xMatrix)] <- 0
xMatrix = scale(xMatrix)
xMatrix = as.matrix(xMatrix)

#xMatrix

mod1candidate1 = auto.arima(scale(combinedData$spyRange), xreg = xMatrix, trace = TRUE)
checkresiduals(mod1candidate1)
```

Auto ARIMA picks out the model (4,1,1) for the standardized data. The residual diagnostic plots look good, with the residuals normally distributed. 

```{r}
xMatrix = as.data.frame(xMatrix)

# Lets examine the residuals directly to identify 
mod1candidate2 <- lm(scale(combinedData$spyRange) ~ mo12delta + pdam + dailyChange + workers, data = xMatrix )
summary(mod1candidate2)

resid1 <- mod1candidate2$residuals
pacf(resid1)
acf(resid1)

```

Based on the PACF and ACF of the residuals from the regression, it seems we should definitely difference the series, as we have many significant lag terms in the ACF. On the PACF, we can see 4 terms clearly  signfificant. Based on these charts, I might try the model (4,1,0). I will try up through (4,2,2) and look for the lowest aic.
```{r}

SARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){
  
temp=c()
d=1
D=1
s=12
 
i=1
temp= data.frame()
ls=matrix(rep(NA,9*378),nrow=378)
 
 
for (p in p1:p2)
  {
    for(q in q1:q2)
    {
      for(P in P1:P2)
      {
        for(Q in Q1:Q2)
        {
          for(d in d1:d2)
       
        {
          if(p+d+q+P+D+Q<=8)
          {
            
            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))
            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)
            i=i+1
            #print(i)
            
          }
          
        }
      }
    }
    
  }
  
  }
  temp= as.data.frame(ls)
  names(temp)= c("p","d","q","P","D","Q","AIC","BIC","AICc")
  
  temp
  
}


SARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid1) %>% filter(!is.na(p))

mod1candidate2 <- arima(resid1, order = c(1,0,1), seasonal = list(order = c(0,1,0)))
checkresiduals(mod1candidate2)
```

The function to evaluate various p,d,q values returns SARIMA(1,0,1)(0,1,0)[12] with the lowest AIC and BIC. The residuals of this second model show clear correlation around lags 2 and 4, which was not present in the 4,1,0 model that auto arima suggested. So overall, I would say the diagnostics look worse for the second model than the first.



<h4> Model 3: (ARIMAX) IWM ~ Casualties + Hurricanes + Interest Rate 3-Months </h4>

```{r}

xMatrix3 = combinedData[,c('mo3delta', 'casualties', 'hurricaneWarnings')]
xMatrix3[is.na(xMatrix3)] <- 0
xMatrix3 = scale(xMatrix3)
xMatrix3 = as.matrix(xMatrix3)

#xMatrix

mod3candidate1 = auto.arima(scale(combinedData$iwmRange), xreg = xMatrix3, trace = TRUE)
checkresiduals(mod3candidate1)
```

Auto.arima identifies (1,1,3) as the best model. The residuals show a low level of correlation in the lags, which is encouraging, and overall the residuals are mostly normally distributed although they are somewhat skewed to the right. Now, let's see what we manually select, also considering a SARIMAX model.


Prepare residuals:
```{r}
xMatrix3 = as.data.frame(xMatrix3)

# Lets examine the residuals directly to identify 
mod3candidate2 <- lm(scale(combinedData$iwmRange) ~ casualties + mo3delta + hurricaneWarnings, data = xMatrix3 )
summary(mod3candidate2)

resid3 <- mod3candidate2$residuals
pacf(resid3)
acf(resid3)

```

The ACF and PACF plots of the residuals from linear regression are mixed, but there is clear correlation through value 5 in the PACF plot. The ACF plot has many significant terms, suggesting the series should be differenced. Now, I'll loop through all the options to see if there is a suitable SARIMA model for the residuals:


```{r}

output=SARIMA.c(p1=1,p2=3,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid3)
output %>% filter(!is.na(p))

```

The best model identified by a small margin is SARIMA(1,0,1)(1,1,0). Let's check the diagnostics
```{r}
residualsMod3Can2 <- arima(resid3, order = c(1,0,1), seasonal = list(order = c(1,1,0)))
checkresiduals(residualsMod3Can2)

```

The residuals for this model arent encouraging, as the Ljung Box test returns a p value of 0.03. THe residuals also do not look perfectly normally distributed.


<h4> Model 4: (ARIMAX) QQQ ~ All Interest Rates + All Extreme Weather Events + Daily VIX Change + Daily Striking Workers </h4>

Running an auto arima:
```{r}

xMatrix4 = combinedData[,c('mo3delta', 'mo6delta', 'mo12delta', 'events', 'dailyChange', 'workers')]
xMatrix4[is.na(xMatrix4)] <- 0
xMatrix4 = scale(xMatrix4)
xMatrix4 = as.matrix(xMatrix4)

#xMatrix

mod4candidate1 = auto.arima(scale(combinedData$qqqRange), xreg = xMatrix4, trace = TRUE)
checkresiduals(mod4candidate1)

```


Auto Arima returns (1,1,1). The diagnostics look acceptable, although there is clustered volatility in the residual plot. The Ljung-Box test returns p = 0.95, suggesting there is not autocorrelation in the residuals. However, the residual lag plot has high correlation around lag 20, and the correlation of the residuals slightly increases as the lags get greater.

Now let's select a candidate manually, including from SARIMA models. First we calculate and review the residuals from the linear regression:
```{r}

xMatrix4 = as.data.frame(xMatrix4)

# Lets examine the residuals directly to identify 
mod4candidate2 <- lm(scale(combinedData$qqqRange) ~ mo3delta + mo6delta + mo12delta + events + dailyChange, data = xMatrix4 )
summary(mod1candidate2)

resid4 <- mod4candidate2$residuals
pacf(resid4)
acf(resid4)
```

The ACF plot has many significant lags (>10) which suggests we may need to difference the residuals. The PACF plot has high significance through lag 5. Let's run a function to check all of the values up through p=2 and q=5.


```{r}

mod4candidate2fit =SARIMA.c(p1=1,p2=2,q1=1,q2=5,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid4)
mod4candidate2fit %>% filter(!is.na(p))


```


The best AIC and BIC scores returned by the function are for the model SARIMA(1,0,1)(1,1,0). Let's look at the diagnostic plots to see how well this model captures the data:

```{r}
mod4candidate2fit = arima(resid4, order = c(1,0,1), seasonal = list(order = c(1,1,0)))
checkresiduals(mod4candidate2fit)


```

The residuals for this model look similar to the auto.arima model, so it will be interesting to compare them with cross validation. Otherwise, it is notable that the residuals display clustered volatility, while the lag plot shows significant correlations at some values, although the Ljung-Box test returns 0.795 so we can conclude there is no autocorrelation in the residuals.

<h4> Model 5: (ARIMAX) QQQ ~ Interest Rate 3 months + Daily Property Damage + Daily VIX Change + Daily New Striking Workers </h4>

I am leaving this model to fit after the homework.

<h3> Model Selection for VAR Models </h3>

<h4> Model 2: (VAR) SPY ~ Interest Rate 3-Months + Daily VIX Value <h4>

Step 1, let's fit VAR with p=1 just to see the relationship between our 3 variables (SPY intraday range, 3-month interest rate changes, and the real daily VIX values). 

```{r}

xMatrix2 = combinedData[,c('VIX.Adjusted', 'mo3delta', 'spyRange') ]
xMatrix2[is.na(xMatrix2)] <- 0
xMatrix2 = scale(xMatrix2)
xMatrix2 = as.matrix(xMatrix2)

#xMatrix

summary(vars::VAR(xMatrix2, p = 1, type = 'both'))


```

The initial VAR fit is encouraging, as the 3 variables are all significant. SPY range has a p value of 0.09, which is slightly above the 0.05 threshold that would be ideal, but still suggests it helps explain the variance in the other variables in the model. The overall R squared and adjusted R squared are also encouraging, at 0.5, which is exceptionally high for a model concerning stock prices. 

Now lets use VAR select to identify some preferrable p values.
```{r}

vars::VARselect(xMatrix2, lag.max = 10, type = 'both')


```

VAR select returns either p =5 or p = 1 as the best fits, with AIC and FPE selecting p=5, and HQ and SC selecting p =1. We will use cross validation to compare these options.

<h2> Model Evaluation </h2>

In this section, I will use cross validation to select the best candidate model for each of the 5 overaching model designs. First, lets define a cross validation function 


```{r}

#######

crossVal <- function(arima1order, arima2order, sarima2order, data) {

    # window is always 1
    test <- 30
    trainnum <- length(data) - test
    rmse1 <- vector(mode = 'numeric', length = 30)
    rmse2 <- vector(mode = 'numeric', length = 30)


    for(i in 1:30) {
        #print(trainnum + ((i-1) * 4))
        #print(trainnum + (i*4))
        #print(trainnum + ((i-1) * 4) +1)
        
        xtrain <- data[c(1:(trainnum + i - 1))]
        xtest <-  data[c((trainnum+1):(trainnum+i+1))]
        
        
        
        ######## first Model ############
        fit <- arima(xtrain, order = arima1order)
        fcast <- predict(fit, n.ahead = 1)$pred[1]
        
        
        ######## second model ###########
        fit2 <- arima(xtrain, order = arima2order, seasonal = sarima2order)
        fcast2 <- predict(fit2, n.ahead = 1)$pred[1]
        
        # Errors

        rmse1[i]  <-sqrt((fcast-xtest[1])^2)
        rmse2[i]  <-sqrt((fcast2-xtest[1])^2)
        
    }
    
    outputs = data.frame("rmse1" = rmse1, 'rmse2' = rmse2)
    return(outputs)

}
```

<h3> Model 1 (ARIMAX) </h3>

Lets test the function out on the first model, comparing ARIMA(4,1,1) vs. SARIMA(1,0,1)(0,1,0) on the residuals of the linear regression.

```{r}
model1comparison = crossVal(c(4,1,1), c(1,0,1), list(order = c(0,1,0)), resid1)

mean(model1comparison$rmse1)
mean(model1comparison$rmse2)
```

Between the two models, model 1, selected by auto.arima, beats out the sarima model with a mean RMSE of 0.2690 vs. 0.2696. However, the models do perform similarly to eachother. Let's look at a graph to make the difference more clear:


```{r}
index1 = c(1:nrow(model1comparison))
ggplot(data = model1comparison, aes(x = index1, y = rmse1), color = 'blue') + geom_line() + geom_line(aes(x = index1, y = rmse2), color = 'red') + labs(title = 'Comparing RMSE of ARIMAX(4,1,1) Black and SARIMAX(1,0,1)(0,1,0) Red')

```

As we can see in the cross-validation chart, the two models perform similarly, and tend to have higher and lower errors at the same time, with both of the models performing poorly near the middle of the cross validation data sets. But overall, the ARIMA (ARIMAX) model performs the best at predicting the residuals. As such, my chosen model for Model 1 is ARIMAX(4,1,1).

<h4> Predictions </h4>

Now, let's make predictions:
```{r}

#mod1candidate2 <- lm(scale(combinedData$spyRange) ~ mo12delta + pdam + dailyChange + workers, data = xMatrix )


mod1pdam <- forecast(auto.arima(combinedData$pdam), 10)
mod1delta12 <- forecast(auto.arima(combinedData$mo12delta), 10)
mod1dailyChange <- forecast(auto.arima(combinedData$dailyChange), 10)
mod1workers <- forecast(auto.arima(combinedData$workers), 10)

predictors1 <- data.frame(cbind(pdam = mod1pdam$mean, mo12delta = mod1delta12$mean, dailyChange = mod1dailyChange$mean, workers = mod1workers$mean))

fit = arima(combinedData$spyRange, order = c(4,1,1), xreg = xMatrix)

#summary(fit)
#forecast(fit)
mod1 = predict(fit, newxreg = predictors1)

autoplot(mod1$pred)
```

Here we can see the models predictions for the SPY daily upcoming range, using auto.arima generated models to predict the external regressors. Overall, the model predicts a precipitous drop in the daily range in SPY prices in the upcoming 10 days.


<h3> Model 3 (ARIMAX)  IWM ~ Casualties + Hurricanes + Interest Rate 3-Months </h3>

Let's compare the model returned by auto.arima, ARIMA(1,1,3), vs the model I found by hand, SARIMA(1,0,1)(1,1,0), on the residuals of the linear regression for model 3.

```{r}
model3comparison = crossVal(c(1,1,3), c(1,0,1), list(order = c(1,1,0)), resid3)

mean(model3comparison$rmse1)
mean(model3comparison$rmse2)
```

Once again, the simple ARIMA model beats out the SARIMA architecture in terms of average RMSE. The average for ARIMA(1,1,3) was 0.554, while for SARIMA(1,0,1)(1,1,0) it was 0.601. Let's look at a plot of the rmse values to see how the models fared:

```{r}
index3 = c(1:nrow(model3comparison))
ggplot(data = model3comparison, aes(x = index3, y = rmse1), color = 'blue') + geom_line() + geom_line(aes(x = index3, y = rmse2), color = 'red') + labs(title = 'Comparing RMSE of ARIMAX(1,1,3) Black and SARIMAX(1,0,1)(1,1,0) Red')

```

Just like for model 1, the two approaches performed similarly. If one model had a high RMSE for a particular value, the other model was likely to perform poorly as well. Overall however, we can see that for a given value the black line (ARIMA) tended to perform better. In the end, the ARIMAX models seems to fit the data well. As such, my chosen model for Model 3 is: ARIMAX(1,1,3)/.

<h4> Predictions </h4>

Now, let's make predictions:
```{r}
#xMatrix3 = combinedData[,c('mo3delta', 'casualties', 'hurricaneWarnings')]

mod3cas <- forecast(auto.arima(combinedData$casualties), 10)
mod3delta3 <- forecast(auto.arima(combinedData$mo3delta), 10)
mod3hurricane <- forecast(auto.arima(combinedData$hurricaneWarnings), 10)

predictors3 <- data.frame(cbind(casualties = mod3cas$mean, mo3delta = mod3delta3$mean, hurricaneWarnings = mod3hurricane$mean))

fit3 = arima(combinedData$iwmRange, order = c(1,1,3), xreg = xMatrix3)

#summary(fit)
#forecast(fit)
mod3 = predict(fit3, newxreg = predictors3)

autoplot(mod3$pred)
```

Here we can see the models predictions for the IWM daily upcoming range, using auto.arima generated models to predict the external regressors. Overall, the model predicts a steep incline in IWM intraday ranges in the upcoming 10 days, especially in the first 5 before leveling off.

<h3> Model 4 ARIMAX </h3>
Leaving for future work.
<h3> Model 5 ARIMAX </h3>
Leaving for future work.

<h3> Model 2 VAR </h3>

Let's forecast our VAR model, which used 3-month interest rate changes and daily VIX values to predict SPY's intraday range. For this model we wanted to compare the p values of 1 and 5 to find the best model.


Lets, run our CV function:
```{r}

data = xMatrix2

    # window is always 1
    test <- 30
    trainnum <- nrow(data) - test
    rmse1 <- matrix(NA, 30,3)
    rmse1 <- data.frame(rmse1)
    rmse2 <- matrix(NA, 30,3)
    rmse2 <- data.frame(rmse2)


    for(i in 1:29) {

        xtrain <- data[c(1:(trainnum + i - 1)),]
        xtest <-  data[c((trainnum+i):(trainnum+i+1)),]
        
        
        
        ######## first Model ############
        fit <- vars::VAR(xtrain, p = 1, type = 'both')
        
        fcast <- predict(fit, n.ahead = 1)$fcst
        
        ff<-data.frame(fcast$VIX.Adjusted[,1],fcast$mo3delta[,1],fcast$spyRange[,1])
        
        ######## second model ###########
        fit2 <- vars::VAR(xtrain,p =5, type = 'both')
        fcast2 <- predict(fit2, n.ahead = 1)$fcst
        
        ff2<-data.frame(fcast2$VIX.Adjusted[,1],fcast2$mo3delta[,1],fcast2$spyRange[,1])

        # Errors

        rmse1[i,]  = sqrt((ff-xtest)^2)
        rmse2[i,]  = sqrt((ff2-xtest)^2)
        
    }
    
    
#print(rmse1)


names(rmse1) =c("VIXPrice", "3mo","SPYDailyRange")
names(rmse2) =c("VIXPrice", "3mo","SPYDailyRange")

colMeans(rmse1, na.rm = TRUE)
colMeans(rmse2, na.rm = TRUE)
```

After cross validating the 2 VAR models across 30 1-day intervals, we obtain the following average RMSE for the different variables: VIX Price: p=1 -> 0.148, p=5 -> 0.139. 3 Month Interest Rate Changes: p=1 -> 1.109, p=5 -> 1.190. SPY Daily Range: p=1 -> 0.696, p=5 -> 0.682. 

Overall, the p=1 VAR model was better at predicting the interest rate changes variable, and the p=5 VAR model performed better on the VIX Price and SPY daily range variables.

Let's plot their performance:


```{r}
index2 = c(1:nrow(rmse1))

ggplot() + 
  geom_line(data = rmse1, aes(x = index2, y = VIXPrice),color = "blue") +
  geom_line(data = rmse2, aes(x = index2, y = VIXPrice),color = "red") +
  labs(
    title = "CV RMSE for Vix Prices, Blue = (p=1), Red = (p=5)",
    x = "Date",
    y = "RMSE",
    guides(colour=guide_legend(title="Fit")))


ggplot() + 
  geom_line(data = rmse1, aes(x = index2, y = SPYDailyRange),color = "blue") +
  geom_line(data = rmse2, aes(x = index2, y = SPYDailyRange),color = "red") +
  labs(
    title = "CV RMSE for SPY Daily Range, Blue = (p=1), Red = (p=5)",
    x = "Date",
    y = "RMSE",
    guides(colour=guide_legend(title="Fit")))


```

Overall, the charts show what we confirmed with the average values: That the mean performance of the p=5 model was better on average.

Now let's predict:
```{r}

finalmod2 = vars::VAR(xMatrix2, p = 5, type = 'both')
        
mod2forecast <- predict(finalmod2, n.ahead = 10)$fcst

indexmod2 = c(1:10)
ggplot() +
    geom_line(aes(x = indexmod2, y = mod2forecast$spyRange[1:10]),color = "blue") +
    geom_line(aes(x = indexmod2, y = mod2forecast$mo3delta[1:10]),color = "red") +
    geom_line(aes(x = indexmod2, y = mod2forecast$VIX.Adjusted[1:10]),color = "green")

```

Here we can see the scale forecasts for the 3 key variables, which are created with the predict function for the VAR model with p=5. Overall, the model predicts the SPY range to raise slightly for the next 10 days, and the 3 month interest rates to change sharply.
