{"title":"ARMA ARIMA SARIMA MODELS","markdown":{"yaml":{"title":"ARMA ARIMA SARIMA MODELS"},"headingText":"Stationarity of the Time Series","containsRefs":false,"markdown":"\n\nLoading packages\n\n```{r setup, include=FALSE} \nknitr::opts_chunk$set(warning = FALSE, message = FALSE) \n```\n\n\n``` {r message = FALSE}\nlibrary(tidyverse)\nlibrary(quantmod)\nlibrary(forecast)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(lubridate)\n```\n\n\n\nBringing the data into this tab as well:\n\n``` {r}\n#| code-summary: \"Show Code\"\n\nspyIn <- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn <- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn <- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\n\nspyIn$spyRange <- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange <- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange <- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n\n\ndiff1SPY <- diff(spyIn$spyRange)\ndiff1QQQ <- diff(qqqIn$qqqRange)\ndiff1IWM <- diff(iwmIn$iwmRange)\n\n```\n\n\n\n\nBased on previous results, and the fact that I am using \"pseudo-differenced data\" in that I am taking the percentage range in prices, in addition to a single differencing, means that the time series are stationary\n\n\n## Building ARIMA Model\n\nSince I did some of this work with SPY data on the EDA tab, I will focus on QQQ range data here.\n\n``` {r}\n#print(diff1QQQ)\nacf(diff1QQQ, na.action = na.exclude)\npacf(diff1QQQ, na.action = na.exclude)\n\n```\n\nBased on these charts the order I would pick for QQQ is: ARIMA(2,1,0)\n\n``` {r}\n\nmodelQQQ1 <- arima(diff1QQQ, order = c(2,1,0))\nsummary(modelQQQ1)\n```\n\n5. Equation is x = -1.0034x(t-1) - 0.4832x(t-2) + error\n\n6. Model Diagnostic:\n``` {r}\n\nstats::tsdiag(modelQQQ1)\n\n```\n\nThe Ljung Box statistics look cood, although the ACF of the residuals does have 1 significant term.\n\nI originally tried a (4,1,2) model, however the ljung box statistics were highly correlated, and I suspected overfitting. After reducing the parametrization greatly, the new model performed mnuch better.\n\n7.\n``` {r}\n\nautoQQQ <- auto.arima(diff1QQQ)\nsummary(autoQQQ)\n```\n\nThe auto.arima method chose an ARIMA(1,0,1) model. However, this model did not perform as well in terms of AIC, with the Auto arima model having a score of -4799 while my model had a score of -4292.\n\n\n8. Forecasting with my model\n\n``` {r}\nplot(forecast(modelQQQ1, 10), xlim = c(650,750))   \n\n```\n\n\nForecasting with auto arima model\n``` {r}\nplot(forecast(autoQQQ, 10), xlim = c(650,750))\n\n```\n\nOverall, my model has a slightly more dynamic prediction than the auto arima function, which quicly levels out to 0. However, my model also has a much wider uncertainty band.\n\n\n9. Compare ARIMA model with benchmarks\n```{r}\n\nnaiveModelQQQ <- naive(diff1QQQ, h=1)\nsnaiveModelQQQ <- snaive(diff1QQQ, h=1)\n\nsummary(naiveModelQQQ)\nsummary(snaiveModelQQQ)\nsummary(modelQQQ1)\n\n```\n\nI fit a naive and seasonal naive model. On RMSE my model had the best performance, with 0.011, while the naive and snaive models had 0.017 rmse each (since there was no seasonal period I realized they were the same model). On MAE my arima model had 0.008 while the seasonal naive models had 0.0122.\n\nLet's compare forecasts:\n```{r}\nplot(forecast(modelQQQ1, 10), xlim = c(650,750)) \n```\n\n```{r}\nplot(forecast(naiveModelQQQ, 10), xlim = c(650,750))   \n```\n\n\nHere, the naive method can only forecast 1 observation into the future, since the seasonal period is one. Which is an advantage to my model, but realistically means the naive model should be evaluated with cross validation.\n\n\n## SARIMA \n\nLet's look for a seasonal affect in the ACF plots, using the weather events data. First we prepare the data:\n```{r}\nweather_data <- read.csv('data/storms_clean.csv')\n\n\nweather_data$month <- weather_data$BEGIN_YEARMONTH %% 100\n\nweather_data <- weather_data %>%\n    mutate(realdate = make_date(YEAR, month, BEGIN_DAY)) %>%\n    mutate(DAMAGE_PROPERTY =  str_replace(DAMAGE_PROPERTY, \"K\", \"\") )  %>%\n    mutate(DAMAGE_PROPERTY = as.numeric(DAMAGE_PROPERTY)) %>%\n    mutate(DAMAGE_PROPERTY = replace_na(DAMAGE_PROPERTY, 0))\n\n\n# Daily Event Number\ndaily_events <- weather_data %>%\n    group_by(realdate) %>%\n    summarize(events = length(EPISODE_ID))\n\n# Daily Property Damage\ndaily_property <-  weather_data %>%\n    group_by(realdate) %>%\n    summarize(pdam = sum(DAMAGE_PROPERTY))\n\n# Daily Daily Casualties\ndaily_casualties <-  weather_data %>%\n    group_by(realdate) %>%\n    summarize(casualties = sum(INJURIES_DIRECT) + sum(INJURIES_INDIRECT) + sum(DEATHS_DIRECT) + sum(DEATHS_INDIRECT))\n\n# Daily Hurricanes\ndaily_hurricanes <- weather_data %>%\n    filter(EVENT_TYPE == \"Hurricane\") %>%\n    group_by(realdate) %>%\n    summarize(hurricaneWarnings = length(EPISODE_ID))\n\n\n# Daily joined data\n\nweather_merged <- full_join(daily_events, daily_property, by = \"realdate\")\nweather_merged <- full_join(weather_merged, daily_casualties, by = 'realdate')\nweather_merged <- full_join(weather_merged, daily_hurricanes, by = 'realdate')\n\nhead(weather_merged)\n\n```\n\nNow, lets look at the acf plot:\n```{r}\nacf(weather_merged$events, lag.max = 365)\n\n```\n\nWith a 365 lag plot (as we are looking at weather data), we can see that for about 1/4 of the 365 lags, there is some positive correlation in the residuals (the same season), then for 1/2 the lags after that there is negative correlation (the opposite seasons), and then a return to significant positive correlation about 3/4 of the way through the data. This appears to show a clear seasonal effect of about 365. So let's seasonally difference the data.\n\n```{r}\n\nseasonDiff <- weather_merged$events %>% diff(lag = 365)\nacf(seasonDiff, lag.max = 365)\npacf(seasonDiff)\n```\n\nAfter seasonal differencing, this plot looks much much better, without noticeable season-to-season correlations in the lags, although there is still some short-term correlation. And some repeating period which appears to be almost weekly in the residuals.\n\n\nBased on the ACF and PACF plots, I would consider p of 1, d of 0, and q of 3. Then for P and Q I might consider 0, D would be 1 since we seasonally differenced. But let's run some code to see the AIC of different values:\n\n```{r}\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \ntemp=c()\nd=1\nD=1\ns=12\n \ni=1\ntemp= data.frame()\nls=matrix(rep(NA,9*378),nrow=378)\n \nfor (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          for(d in d1:d2)\n       \n        {\n          if(p+d+q+P+D+Q<=8)\n          {\n            \n            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  \n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\nSARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=weather_merged$events) %>% filter(!is.na(p))\n\nSARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=seasonDiff) %>% filter(!is.na(p))\n```\n\nBased on the results of the function, the minimum AIC and BIC are for the model: (0,1,2)(0,1,0). If I run the SARIMA function on the 365 differenced data, then it returns (1,1,1,)(0,1,0) as the model with the lowest AIC. So I will compare these two models for the series, using diagnostics.\n\n```{r}\nmod1 <- Arima(weather_merged$events,order=c(0,1,2),seasonal=c(0,1,0))\nmod2 <- Arima(weather_merged$events,order=c(1,1,1),seasonal=c(0,1,0))\n\ncheckresiduals(mod1 )\n\n```\n\nThe residuals for model 1 (0,1,2)(0,1,0) show some clustering of volatility. In addition, they appear to be skewed to the right, as the right tail of the residual distribution is fatter than the left tail and has more outlying values. Finally, the ACF plot of the residuals looks good, with little visible correlation and no values crossing the significance line. In addition, the Ljung-Box test returns p=0.43, suggesting we can reject the idea that there is autocorrelation in the residuals.\n\n\n```{r}\ncheckresiduals(mod2 )\n```\n\nThe residual diagnostics for model 2 (1,1,1)(0,1,0) are similar to model 1, except that they have even less correlatoin visible in the residual plots. The residual's distribution is still skewed to the right, with a fatter positive tail. The ACF plot, however, has even less correlation visible, with only two values even coming marginally close to the significance line. There is still some heteroskedacticity in the plot over time, however, suggesting clustering of volatility.\n\n\nNow, let's use an Auto.Arima function to determine the correct model:\n```{r}\naaData <- ts(weather_merged$events)\nmod3 <- auto.arima(aaData, seasonal = TRUE, trace = TRUE)\n\n```\n\nRegardless of the frequency fed into the model, Auto.arima only wants to fit a (2,0,1) ARIMA model. I tried 365, 90, 60, 40, 14, and 7 day frequencies, and in each case the seasonal term was not chosen for the data. I think the reason that it doesn't recognize the seasonality is because it doesn't worok with 365, which should be the best frequency for the data. \n\n\nForecast with a confidence band: Model 1 (0,1,2)(0,1,0)\n```{r}\n\nplot(forecast(mod2), xlim = c(850,925))\n\n```\n\nModel 2: (1,1,1)(0,1,0)\n```{r}\nplot(forecast(mod1), xlim = c(850,925))\n```\n\nI think the forecasts are interesting, because model 2 has a more dynamic forecast, with a decrease over several days before leveling out its prediction. Model 1, meanwhile, predicts that the series will hardly change after its first prediction. While the series does not have a lot of trend going into the prediction interval, weather events are dynamic and I would tend to believe the model which includes more variation as opposed to constant numbers of events. Hence, I would select the (1,1,1)(0,1,0) SARIMA model.\n\nBenchmark Comparison\n\nWe will use two benchmark methods: A seasonal naive forecast and a mean forecast.\n```{r}\n\nbase1 <- snaive(aaData, 10)\nbase2 <- meanf(aaData, 10)\n\nplot(base1, xlim = c(850,925))\n```\n\nHere we can see the plot for the seasonal naive model's forecasts (10 days out), which show a predicted value close to the last observed value in the series. It has a high degree of uncertainty as shown by the prediction interval, which is quite wide.\n\n\n```{r}\nplot(base2, xlim = c(850,925) ) \n\n```\n\nThe forecast for the meanf model (above) departs further from the previously observed values, as the mean of the series is substantially below recently observed values. However, the model has a smaller prediction interval than the seasonal naive forecast, which is a slight advantage.\n\nNow let's look at the accuracy of the three forcasts:\n```{r}\n\n\naccuracy(snaive(aaData))\naccuracy(meanf(aaData))\naccuracy(mod2)\n\n```\n\nThe accuracy statistics were a mixed result between the seasonal naive forecast and the SARIMA(1,1,1)(0,1,0) model. The mean forecast did not perform better on any metric than the other two models, and could be discarded. On Root Mean Squared Error, the SARIMA model beat the Seasonal Naive model with a value of 182.4 vs. 222.3, respectively. On Mean Absolute Error, the SARIMA model also performed better, with 120.3 compared to the Seasonal Naive model's 134.7. On the Mean Absolute Percentage Error, however, the Seasonal Naive model performed better than the SARIMA model, achieving 141.1 vs. 179.3 for the SARIMA model. \n\nOverall, it seems like the accuracy metrics might favor the seasonal naive model, while the prediction forecasts look more accurate for the SARIMA model.\n\nCross Validation:\nLet's do a seasonal cross-validation with 1 and 10-step-ahead forecasts. \n```{r}\n\n    # I add a 100 day buffer to my period of 365 days to have enough data\n    test <- 100 \n    trainnum <- length(aaData) - test\n    rmse1 <- vector(mode = 'numeric', length = 100)\n    rmse2 <- vector(mode = 'numeric', length = 100)\n    rmse361 <- vector(mode = 'numeric', length = 100)\n    rmse362 <- vector(mode = 'numeric', length = 100)\n\n    for(i in 1:100) {\n\n        \n        xtrain <- aaData[c(1:(trainnum + i - 1))]\n        xtest <-  aaData[c((trainnum + i +1):(trainnum+i+10))]\n        \n    \n        ######## model ###########\n        fit2 <- arima(xtrain, order = c(1,1,1), seasonal = list(order = c(0,1,0)))\n        fcast2 <- predict(fit2, n.ahead = 10)$pred\n        \n        # Errors\n\n        rmse2[i]  <-sqrt((fcast2[1]-xtest[1])^2)\n        rmse362[i]  <- mean( sqrt((fcast2 -xtest)^2) )\n        \n    }\n    \n# create index\nindex <- c(1:100)\nggplot() +\n    geom_line(aes(x = index, y = rmse2), color = 'blue' ) + \n    geom_line(aes(x = index, y = rmse362), color = 'red')\n```\n\nThe chart above shows the RMSE for the cross validated forecasts with windows 1 and 10. I had to use 10 for my seasonal window as my computer was unable to handle the 365 window, and could not produce results. But my data also had short-term seasonality so I relied upon that here. The red line represents the 10-step ahead forecast average RMSE and the blue line represents the 1-step ahead forecast RMSE. Overall you can see that both forecasts perform better and worse around the same time, except that the short-term forecast has a lagged reaction to the same periods where the long-term forecast performed poorly. In some cases, however, the 1-step RMSE does exceed the 10-step RMSE, suggesting poor short term performance.\n\n\n\n\n","srcMarkdownNoYaml":"\n\nLoading packages\n\n```{r setup, include=FALSE} \nknitr::opts_chunk$set(warning = FALSE, message = FALSE) \n```\n\n\n``` {r message = FALSE}\nlibrary(tidyverse)\nlibrary(quantmod)\nlibrary(forecast)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(lubridate)\n```\n\n\n\nBringing the data into this tab as well:\n\n``` {r}\n#| code-summary: \"Show Code\"\n\nspyIn <- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn <- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn <- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\n\nspyIn$spyRange <- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange <- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange <- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n\n\ndiff1SPY <- diff(spyIn$spyRange)\ndiff1QQQ <- diff(qqqIn$qqqRange)\ndiff1IWM <- diff(iwmIn$iwmRange)\n\n```\n\n\n\n## Stationarity of the Time Series\n\nBased on previous results, and the fact that I am using \"pseudo-differenced data\" in that I am taking the percentage range in prices, in addition to a single differencing, means that the time series are stationary\n\n\n## Building ARIMA Model\n\nSince I did some of this work with SPY data on the EDA tab, I will focus on QQQ range data here.\n\n``` {r}\n#print(diff1QQQ)\nacf(diff1QQQ, na.action = na.exclude)\npacf(diff1QQQ, na.action = na.exclude)\n\n```\n\nBased on these charts the order I would pick for QQQ is: ARIMA(2,1,0)\n\n``` {r}\n\nmodelQQQ1 <- arima(diff1QQQ, order = c(2,1,0))\nsummary(modelQQQ1)\n```\n\n5. Equation is x = -1.0034x(t-1) - 0.4832x(t-2) + error\n\n6. Model Diagnostic:\n``` {r}\n\nstats::tsdiag(modelQQQ1)\n\n```\n\nThe Ljung Box statistics look cood, although the ACF of the residuals does have 1 significant term.\n\nI originally tried a (4,1,2) model, however the ljung box statistics were highly correlated, and I suspected overfitting. After reducing the parametrization greatly, the new model performed mnuch better.\n\n7.\n``` {r}\n\nautoQQQ <- auto.arima(diff1QQQ)\nsummary(autoQQQ)\n```\n\nThe auto.arima method chose an ARIMA(1,0,1) model. However, this model did not perform as well in terms of AIC, with the Auto arima model having a score of -4799 while my model had a score of -4292.\n\n\n8. Forecasting with my model\n\n``` {r}\nplot(forecast(modelQQQ1, 10), xlim = c(650,750))   \n\n```\n\n\nForecasting with auto arima model\n``` {r}\nplot(forecast(autoQQQ, 10), xlim = c(650,750))\n\n```\n\nOverall, my model has a slightly more dynamic prediction than the auto arima function, which quicly levels out to 0. However, my model also has a much wider uncertainty band.\n\n\n9. Compare ARIMA model with benchmarks\n```{r}\n\nnaiveModelQQQ <- naive(diff1QQQ, h=1)\nsnaiveModelQQQ <- snaive(diff1QQQ, h=1)\n\nsummary(naiveModelQQQ)\nsummary(snaiveModelQQQ)\nsummary(modelQQQ1)\n\n```\n\nI fit a naive and seasonal naive model. On RMSE my model had the best performance, with 0.011, while the naive and snaive models had 0.017 rmse each (since there was no seasonal period I realized they were the same model). On MAE my arima model had 0.008 while the seasonal naive models had 0.0122.\n\nLet's compare forecasts:\n```{r}\nplot(forecast(modelQQQ1, 10), xlim = c(650,750)) \n```\n\n```{r}\nplot(forecast(naiveModelQQQ, 10), xlim = c(650,750))   \n```\n\n\nHere, the naive method can only forecast 1 observation into the future, since the seasonal period is one. Which is an advantage to my model, but realistically means the naive model should be evaluated with cross validation.\n\n\n## SARIMA \n\nLet's look for a seasonal affect in the ACF plots, using the weather events data. First we prepare the data:\n```{r}\nweather_data <- read.csv('data/storms_clean.csv')\n\n\nweather_data$month <- weather_data$BEGIN_YEARMONTH %% 100\n\nweather_data <- weather_data %>%\n    mutate(realdate = make_date(YEAR, month, BEGIN_DAY)) %>%\n    mutate(DAMAGE_PROPERTY =  str_replace(DAMAGE_PROPERTY, \"K\", \"\") )  %>%\n    mutate(DAMAGE_PROPERTY = as.numeric(DAMAGE_PROPERTY)) %>%\n    mutate(DAMAGE_PROPERTY = replace_na(DAMAGE_PROPERTY, 0))\n\n\n# Daily Event Number\ndaily_events <- weather_data %>%\n    group_by(realdate) %>%\n    summarize(events = length(EPISODE_ID))\n\n# Daily Property Damage\ndaily_property <-  weather_data %>%\n    group_by(realdate) %>%\n    summarize(pdam = sum(DAMAGE_PROPERTY))\n\n# Daily Daily Casualties\ndaily_casualties <-  weather_data %>%\n    group_by(realdate) %>%\n    summarize(casualties = sum(INJURIES_DIRECT) + sum(INJURIES_INDIRECT) + sum(DEATHS_DIRECT) + sum(DEATHS_INDIRECT))\n\n# Daily Hurricanes\ndaily_hurricanes <- weather_data %>%\n    filter(EVENT_TYPE == \"Hurricane\") %>%\n    group_by(realdate) %>%\n    summarize(hurricaneWarnings = length(EPISODE_ID))\n\n\n# Daily joined data\n\nweather_merged <- full_join(daily_events, daily_property, by = \"realdate\")\nweather_merged <- full_join(weather_merged, daily_casualties, by = 'realdate')\nweather_merged <- full_join(weather_merged, daily_hurricanes, by = 'realdate')\n\nhead(weather_merged)\n\n```\n\nNow, lets look at the acf plot:\n```{r}\nacf(weather_merged$events, lag.max = 365)\n\n```\n\nWith a 365 lag plot (as we are looking at weather data), we can see that for about 1/4 of the 365 lags, there is some positive correlation in the residuals (the same season), then for 1/2 the lags after that there is negative correlation (the opposite seasons), and then a return to significant positive correlation about 3/4 of the way through the data. This appears to show a clear seasonal effect of about 365. So let's seasonally difference the data.\n\n```{r}\n\nseasonDiff <- weather_merged$events %>% diff(lag = 365)\nacf(seasonDiff, lag.max = 365)\npacf(seasonDiff)\n```\n\nAfter seasonal differencing, this plot looks much much better, without noticeable season-to-season correlations in the lags, although there is still some short-term correlation. And some repeating period which appears to be almost weekly in the residuals.\n\n\nBased on the ACF and PACF plots, I would consider p of 1, d of 0, and q of 3. Then for P and Q I might consider 0, D would be 1 since we seasonally differenced. But let's run some code to see the AIC of different values:\n\n```{r}\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \ntemp=c()\nd=1\nD=1\ns=12\n \ni=1\ntemp= data.frame()\nls=matrix(rep(NA,9*378),nrow=378)\n \nfor (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          for(d in d1:d2)\n       \n        {\n          if(p+d+q+P+D+Q<=8)\n          {\n            \n            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  \n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\nSARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=weather_merged$events) %>% filter(!is.na(p))\n\nSARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=seasonDiff) %>% filter(!is.na(p))\n```\n\nBased on the results of the function, the minimum AIC and BIC are for the model: (0,1,2)(0,1,0). If I run the SARIMA function on the 365 differenced data, then it returns (1,1,1,)(0,1,0) as the model with the lowest AIC. So I will compare these two models for the series, using diagnostics.\n\n```{r}\nmod1 <- Arima(weather_merged$events,order=c(0,1,2),seasonal=c(0,1,0))\nmod2 <- Arima(weather_merged$events,order=c(1,1,1),seasonal=c(0,1,0))\n\ncheckresiduals(mod1 )\n\n```\n\nThe residuals for model 1 (0,1,2)(0,1,0) show some clustering of volatility. In addition, they appear to be skewed to the right, as the right tail of the residual distribution is fatter than the left tail and has more outlying values. Finally, the ACF plot of the residuals looks good, with little visible correlation and no values crossing the significance line. In addition, the Ljung-Box test returns p=0.43, suggesting we can reject the idea that there is autocorrelation in the residuals.\n\n\n```{r}\ncheckresiduals(mod2 )\n```\n\nThe residual diagnostics for model 2 (1,1,1)(0,1,0) are similar to model 1, except that they have even less correlatoin visible in the residual plots. The residual's distribution is still skewed to the right, with a fatter positive tail. The ACF plot, however, has even less correlation visible, with only two values even coming marginally close to the significance line. There is still some heteroskedacticity in the plot over time, however, suggesting clustering of volatility.\n\n\nNow, let's use an Auto.Arima function to determine the correct model:\n```{r}\naaData <- ts(weather_merged$events)\nmod3 <- auto.arima(aaData, seasonal = TRUE, trace = TRUE)\n\n```\n\nRegardless of the frequency fed into the model, Auto.arima only wants to fit a (2,0,1) ARIMA model. I tried 365, 90, 60, 40, 14, and 7 day frequencies, and in each case the seasonal term was not chosen for the data. I think the reason that it doesn't recognize the seasonality is because it doesn't worok with 365, which should be the best frequency for the data. \n\n\nForecast with a confidence band: Model 1 (0,1,2)(0,1,0)\n```{r}\n\nplot(forecast(mod2), xlim = c(850,925))\n\n```\n\nModel 2: (1,1,1)(0,1,0)\n```{r}\nplot(forecast(mod1), xlim = c(850,925))\n```\n\nI think the forecasts are interesting, because model 2 has a more dynamic forecast, with a decrease over several days before leveling out its prediction. Model 1, meanwhile, predicts that the series will hardly change after its first prediction. While the series does not have a lot of trend going into the prediction interval, weather events are dynamic and I would tend to believe the model which includes more variation as opposed to constant numbers of events. Hence, I would select the (1,1,1)(0,1,0) SARIMA model.\n\nBenchmark Comparison\n\nWe will use two benchmark methods: A seasonal naive forecast and a mean forecast.\n```{r}\n\nbase1 <- snaive(aaData, 10)\nbase2 <- meanf(aaData, 10)\n\nplot(base1, xlim = c(850,925))\n```\n\nHere we can see the plot for the seasonal naive model's forecasts (10 days out), which show a predicted value close to the last observed value in the series. It has a high degree of uncertainty as shown by the prediction interval, which is quite wide.\n\n\n```{r}\nplot(base2, xlim = c(850,925) ) \n\n```\n\nThe forecast for the meanf model (above) departs further from the previously observed values, as the mean of the series is substantially below recently observed values. However, the model has a smaller prediction interval than the seasonal naive forecast, which is a slight advantage.\n\nNow let's look at the accuracy of the three forcasts:\n```{r}\n\n\naccuracy(snaive(aaData))\naccuracy(meanf(aaData))\naccuracy(mod2)\n\n```\n\nThe accuracy statistics were a mixed result between the seasonal naive forecast and the SARIMA(1,1,1)(0,1,0) model. The mean forecast did not perform better on any metric than the other two models, and could be discarded. On Root Mean Squared Error, the SARIMA model beat the Seasonal Naive model with a value of 182.4 vs. 222.3, respectively. On Mean Absolute Error, the SARIMA model also performed better, with 120.3 compared to the Seasonal Naive model's 134.7. On the Mean Absolute Percentage Error, however, the Seasonal Naive model performed better than the SARIMA model, achieving 141.1 vs. 179.3 for the SARIMA model. \n\nOverall, it seems like the accuracy metrics might favor the seasonal naive model, while the prediction forecasts look more accurate for the SARIMA model.\n\nCross Validation:\nLet's do a seasonal cross-validation with 1 and 10-step-ahead forecasts. \n```{r}\n\n    # I add a 100 day buffer to my period of 365 days to have enough data\n    test <- 100 \n    trainnum <- length(aaData) - test\n    rmse1 <- vector(mode = 'numeric', length = 100)\n    rmse2 <- vector(mode = 'numeric', length = 100)\n    rmse361 <- vector(mode = 'numeric', length = 100)\n    rmse362 <- vector(mode = 'numeric', length = 100)\n\n    for(i in 1:100) {\n\n        \n        xtrain <- aaData[c(1:(trainnum + i - 1))]\n        xtest <-  aaData[c((trainnum + i +1):(trainnum+i+10))]\n        \n    \n        ######## model ###########\n        fit2 <- arima(xtrain, order = c(1,1,1), seasonal = list(order = c(0,1,0)))\n        fcast2 <- predict(fit2, n.ahead = 10)$pred\n        \n        # Errors\n\n        rmse2[i]  <-sqrt((fcast2[1]-xtest[1])^2)\n        rmse362[i]  <- mean( sqrt((fcast2 -xtest)^2) )\n        \n    }\n    \n# create index\nindex <- c(1:100)\nggplot() +\n    geom_line(aes(x = index, y = rmse2), color = 'blue' ) + \n    geom_line(aes(x = index, y = rmse362), color = 'red')\n```\n\nThe chart above shows the RMSE for the cross validated forecasts with windows 1 and 10. I had to use 10 for my seasonal window as my computer was unable to handle the 365 window, and could not produce results. But my data also had short-term seasonality so I relied upon that here. The red line represents the 10-step ahead forecast average RMSE and the blue line represents the 1-step ahead forecast RMSE. Overall you can see that both forecasts perform better and worse around the same time, except that the short-term forecast has a lagged reaction to the same periods where the long-term forecast performed poorly. In some cases, however, the 1-step RMSE does exceed the 10-step RMSE, suggesting poor short term performance.\n\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"css":["styles.css"],"output-file":"ARMA ARIMA SARIMA Models.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"sandstone","code-summary":"Show Code","title":"ARMA ARIMA SARIMA MODELS"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}