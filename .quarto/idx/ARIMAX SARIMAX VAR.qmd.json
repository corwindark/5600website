{"title":"Data Sources","markdown":{"yaml":{"title":"Data Sources","author":"Corwin Dark","engine":"knitr"},"headingText":"8 is vixIn$VIX.Close","containsRefs":false,"markdown":"\n\n\n<h2> Planning Models </h2>\n\nWe have the following independent variables:\n1. Interest Rate Expectation Changes - 3 Months \n2. Interest Rate Expectation Changes - 6 Months \n3. Interest Rate Expectation Changes - 1 Year\n4. Extreme Weather Events - Daily Event Number\n5. Extreme Weather Events - Daily Property Damage\n6. Extreme Weather Events - Daily Casualties\n7. Extreme Weather Events - Hurricanes\n8. Expected Volatility (VIX) - Value\n9. Expected Volatility (VIX) - Daily Change\n10. Work Stoppages - Daily Striking Worker Total\n11. Work Stoppages - Daily New Strike Beggining\n12. Work Stoppages - Daily New Workers Striking\n\n\n\n\n<h3> Preparing Exogenous Data </h3>\n\nFirst we need to create all 12 predictors, then we can combine them to estimate the models as needed.\n```{r}\nlibrary(knitr)\nlibrary(tidyverse)\nlibrary(quantmod)\nlibrary(forecast)\nlibrary(tseries)\nlibrary(lubridate)\nlibrary(reticulate)\n```\n\nLet's  quickly retrieve the daily stock price ranges for the indices:\n```{r}\nspyIn <- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn <- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn <- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\n\nspyIn$spyRange <- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange <- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange <- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n```\n\nNow, let's gather the VIX data, since it is also treated like a stock price, and should be available from the same package\n```{r}\nvixIn <- quantmod::getSymbols(\"^VIX\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\nvixIn$dailyChange <- vixIn$VIX.Close - lag(vixIn$VIX.Close)\n# 9 is vixIn$dailyChange\n\n#vixIn <- vixIn %>% \n#    mutate(date = ymd(index(vixIn)))\nhead(vixIn)\n```\n\nWe have bond yields stored in a CSV, but let's calculate daily changes:\n```{r}\nyieldCurve <- read.csv('data/treasuries.csv')\n\nyieldCurve$mo3delta <- yieldCurve$X3.Mo - lag(yieldCurve$X3.Mo)\nyieldCurve$mo6delta <- yieldCurve$X6.Mo - lag(yieldCurve$X6.Mo)\nyieldCurve$mo12delta <- yieldCurve$X1.Yr - lag(yieldCurve$X1.Yr) \n\nyieldCurve$Date <- mdy(yieldCurve$Date)\n```\n\nWorth noting: Both the treasury data and the VIX data only start on January 4th.\n\n\nNext up, let's prepare the weather event data:\n```{r}\nweather_data <- read.csv('data/storms_clean.csv')\n\n\nweather_data$month <- weather_data$BEGIN_YEARMONTH %% 100\n\nweather_data <- weather_data %>%\n    mutate(realdate = make_date(YEAR, month, BEGIN_DAY)) %>%\n    mutate(DAMAGE_PROPERTY =  str_replace(DAMAGE_PROPERTY, \"K\", \"\") )  %>%\n    mutate(DAMAGE_PROPERTY = as.numeric(DAMAGE_PROPERTY)) %>%\n    mutate(DAMAGE_PROPERTY = replace_na(DAMAGE_PROPERTY, 0))\n\n\n# Daily Event Number\ndaily_events <- weather_data %>%\n    group_by(realdate) %>%\n    summarize(events = length(EPISODE_ID))\n\n# Daily Property Damage\ndaily_property <-  weather_data %>%\n    group_by(realdate) %>%\n    summarize(pdam = sum(DAMAGE_PROPERTY))\n\n# Daily Daily Casualties\ndaily_casualties <-  weather_data %>%\n    group_by(realdate) %>%\n    summarize(casualties = sum(INJURIES_DIRECT) + sum(INJURIES_INDIRECT) + sum(DEATHS_DIRECT) + sum(DEATHS_INDIRECT))\n\n# Daily Hurricanes\ndaily_hurricanes <- weather_data %>%\n    filter(EVENT_TYPE == \"Hurricane\") %>%\n    group_by(realdate) %>%\n    summarize(hurricaneWarnings = length(EPISODE_ID))\n\n\n# Daily joined data\n\nweather_merged <- full_join(daily_events, daily_property, by = \"realdate\")\nweather_merged <- full_join(weather_merged, daily_casualties, by = 'realdate')\nweather_merged <- full_join(weather_merged, daily_hurricanes, by = 'realdate')\n\nhead(weather_merged)\n```\n\nFinally, lets get the striking worker data ready:\n```{r}\nstrike_data <- read.csv('data/strikes.csv')\n\n# clean date format\nstrike_data$start = mdy(strike_data$Work.stoppage.beginning.date)\nstrike_data$end = mdy(strike_data$Work.stoppage.ending.date)\nstrike_data$workers = as.numeric(str_replace(strike_data$Number.of.workers.2., \",\", \"\" ))\n\n\nhead(strike_data)\n\ntarget_dates <- ymd(index(spyIn))\n\ndaily_workers <- vector(mode = \"numeric\", length = length(target_dates))\n\nfor(i in seq_along(target_dates)) {\n    tempDat <- strike_data %>%\n        filter(start <= target_dates[i]) %>%\n        filter(end >= target_dates[i])\n\n    daily_workers[i] = sum(tempDat$workers)\n}\n\nworkerDF <- data.frame('workers' = daily_workers, 'date' = target_dates)\nplot(daily_workers, type = 'l')\n     \n```\n\nNow, we can combined all of these datasets into one dataframe, joining on the date columns\n```{r}\n# Convert TS objects to df, and fix the date column\nvixDF <- data.frame(vixIn)\nvixDF$date <- ymd(index(vixIn))\nspyDF <- data.frame(spyIn)\nspyDF$date <- ymd(index(spyIn))\nqqqDF <- data.frame(qqqIn)\nqqqDF$date <- ymd(index(qqqIn))\niwmDF <- data.frame(iwmIn)\niwmDF$date <- ymd(index(iwmIn))\n\n# Join symbols together\ntickers <- left_join(spyDF, vixDF, by = 'date')\ntickers <- left_join(tickers, qqqDF, by = 'date')\ntickers <- left_join(tickers, iwmDF, by = 'date')\n\n# Join weather data\ncombinedData <- left_join(tickers, weather_merged, by = c(\"date\" = \"realdate\"))\n\n# Join Bond Yields\ncombinedData <- left_join(combinedData, yieldCurve, by = c(\"date\" = \"Date\"))\n\n# Join Labor Data\ncombinedData <- left_join(combinedData, workerDF, by = 'date')\n\nhead(combinedData)\n\n\n```\n\n\n<h3> Select Models Based on These Exogenous Variables </h3>\n\nWe will combine these 12 predictors into 5 models, for SPY, QQQ, and IWM intraday volatility:\n\n<h4> Model 1: (ARIMAX) SPY ~ Interest Rate 1-Year + Daily Weather Property Damage + Daily VIX Change + Daily Striking Worker Total </h2>\n\nThis model is selected based on the literature review, which suggested that weather events and investor expecations could affect stock prices. This is the \"kitchen sink\" model, where I am throwing in variables from all data sources. However, looking at the variables individually, such as daily property damage vs. SPY daily price range, we don't nessecarily see clear correlation (see plot below which resembles white noise). But I am interested to see how these variables are related when taking many different contextual factors into account in the same model.\n\n```{r}\nggplot(combinedData, aes(x = log(spyRange), y = log(pdam)) ) + geom_point() + labs(title = \"3 Month Interest Rate Changes vs. VIX Change \", x = \"Log SPY Daily Spread\", y = \"Log Property Damage From Storms\")\n```\n\n\n<h4> Model 2: (VAR) SPY ~ Interest Rate 3-Months + Daily VIX Value </h4>\n\nThis model is based on a belief that there is an interrelationship between VIX prices and bond yields. This is because both would increase and decrease based on investor expectations for macroeconomic performance in upcoming months. If investors feel the economy will perform poorly, then this might predict bond yields lowering, as well as increased volatility which would be reflected by increases in the VIX. We also see a weak linear correlation in these daily values, as pictured in the plot below. \n\n```{r}\nggplot(combinedData, aes(x = mo3delta, y = dailyChange ) ) + geom_point() + labs(title = \"3 Month Interest Rate Changes vs. VIX Change \", x = \"Change in 3-Month Interest Rates\", y = \"Change in VIX Price\")\n```\n\n<h4> Model 3: (ARIMAX) IWM ~ Casualties + Hurricanes + Interest Rate 3-Months </h4>\n\nThis model is all about exogenous shocks. New strikes beggining and hurricane warnings are infrequent but extreme events, which have been grouped together with short-term interest rates (3 month window) to try and capture extreme-but-short-termm influences on volatility.\n\n<h4> Model 4: (ARIMAX) QQQ ~ All Interest Rates + All Extreme Weather Events + Daily VIX Change + Daily Striking Workers </h4>\n<h4> Model 5: (ARIMAX) QQQ ~ Interest Rate 3 months + Daily Property Damage + Daily VIX Change + Daily New Striking Workers </h4>\n\nModels 4 and 5 follow the same logic as model 1, being selected based off of the literature review, but looking at QQQ as oppposed to SPY to see whether large-cap tech companies are more likely to be affected by this kind of volatility.\n\n<h2> Model Selection </h2>\n\nIn this section, I will begin by identifying the candidate model structures for each of the 5 overarching models outlined above. I will identify candidate models through auto.arima for ARIMAX models, plus hand-selected values. For VAR models, I will identify 2 candidates for each overall model with the autoVAR function.\n\n<h3> Model Selection for ARIMAX Models </h3>\n\n\n\n<h4> Model 1: SPY ~ Interest Rate 1-Year + Daily Weather Property Damage + Daily VIX Change + Daily Striking Worker Total </h2>\n```{r}\n\nxMatrix = combinedData[,c('mo12delta', 'pdam', 'dailyChange', 'workers')]\nxMatrix[is.na(xMatrix)] <- 0\nxMatrix = scale(xMatrix)\nxMatrix = as.matrix(xMatrix)\n\n#xMatrix\n\nmod1candidate1 = auto.arima(scale(combinedData$spyRange), xreg = xMatrix, trace = TRUE)\ncheckresiduals(mod1candidate1)\n```\n\nAuto ARIMA picks out the model (4,1,1) for the standardized data. The residual diagnostic plots look good, with the residuals normally distributed. \n\n```{r}\nxMatrix = as.data.frame(xMatrix)\n\n# Lets examine the residuals directly to identify \nmod1candidate2 <- lm(scale(combinedData$spyRange) ~ mo12delta + pdam + dailyChange + workers, data = xMatrix )\nsummary(mod1candidate2)\n\nresid1 <- mod1candidate2$residuals\npacf(resid1)\nacf(resid1)\n\n```\n\nBased on the PACF and ACF of the residuals from the regression, it seems we should definitely difference the series, as we have many significant lag terms in the ACF. On the PACF, we can see 4 terms clearly  signfificant. Based on these charts, I might try the model (4,1,0). I will try up through (4,2,2) and look for the lowest aic.\n```{r}\n\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \ntemp=c()\nd=1\nD=1\ns=12\n \ni=1\ntemp= data.frame()\nls=matrix(rep(NA,9*378),nrow=378)\n \n \nfor (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          for(d in d1:d2)\n       \n        {\n          if(p+d+q+P+D+Q<=8)\n          {\n            \n            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  \n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\nSARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid1) %>% filter(!is.na(p))\n\nmod1candidate2 <- arima(resid1, order = c(1,0,1), seasonal = list(order = c(0,1,0)))\ncheckresiduals(mod1candidate2)\n```\n\nThe function to evaluate various p,d,q values returns SARIMA(1,0,1)(0,1,0)[12] with the lowest AIC and BIC. The residuals of this second model show clear correlation around lags 2 and 4, which was not present in the 4,1,0 model that auto arima suggested. So overall, I would say the diagnostics look worse for the second model than the first.\n\n\n\n<h4> Model 3: (ARIMAX) IWM ~ Casualties + Hurricanes + Interest Rate 3-Months </h4>\n\n```{r}\n\nxMatrix3 = combinedData[,c('mo3delta', 'casualties', 'hurricaneWarnings')]\nxMatrix3[is.na(xMatrix3)] <- 0\nxMatrix3 = scale(xMatrix3)\nxMatrix3 = as.matrix(xMatrix3)\n\n#xMatrix\n\nmod3candidate1 = auto.arima(scale(combinedData$iwmRange), xreg = xMatrix3, trace = TRUE)\ncheckresiduals(mod3candidate1)\n```\n\nAuto.arima identifies (1,1,3) as the best model. The residuals show a low level of correlation in the lags, which is encouraging, and overall the residuals are mostly normally distributed although they are somewhat skewed to the right. Now, let's see what we manually select, also considering a SARIMAX model.\n\n\nPrepare residuals:\n```{r}\nxMatrix3 = as.data.frame(xMatrix3)\n\n# Lets examine the residuals directly to identify \nmod3candidate2 <- lm(scale(combinedData$iwmRange) ~ casualties + mo3delta + hurricaneWarnings, data = xMatrix3 )\nsummary(mod3candidate2)\n\nresid3 <- mod3candidate2$residuals\npacf(resid3)\nacf(resid3)\n\n```\n\nThe ACF and PACF plots of the residuals from linear regression are mixed, but there is clear correlation through value 5 in the PACF plot. The ACF plot has many significant terms, suggesting the series should be differenced. Now, I'll loop through all the options to see if there is a suitable SARIMA model for the residuals:\n\n\n```{r}\n\noutput=SARIMA.c(p1=1,p2=3,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid3)\noutput %>% filter(!is.na(p))\n\n```\n\nThe best model identified by a small margin is SARIMA(1,0,1)(1,1,0). Let's check the diagnostics\n```{r}\nresidualsMod3Can2 <- arima(resid3, order = c(1,0,1), seasonal = list(order = c(1,1,0)))\ncheckresiduals(residualsMod3Can2)\n\n```\n\nThe residuals for this model arent encouraging, as the Ljung Box test returns a p value of 0.03. THe residuals also do not look perfectly normally distributed.\n\n\n<h4> Model 4: (ARIMAX) QQQ ~ All Interest Rates + All Extreme Weather Events + Daily VIX Change + Daily Striking Workers </h4>\n\nRunning an auto arima:\n```{r}\n\nxMatrix4 = combinedData[,c('mo3delta', 'mo6delta', 'mo12delta', 'events', 'dailyChange', 'workers')]\nxMatrix4[is.na(xMatrix4)] <- 0\nxMatrix4 = scale(xMatrix4)\nxMatrix4 = as.matrix(xMatrix4)\n\n#xMatrix\n\nmod4candidate1 = auto.arima(scale(combinedData$qqqRange), xreg = xMatrix4, trace = TRUE)\ncheckresiduals(mod4candidate1)\n\n```\n\n\nAuto Arima returns (1,1,1). The diagnostics look acceptable, although there is clustered volatility in the residual plot. The Ljung-Box test returns p = 0.95, suggesting there is not autocorrelation in the residuals. However, the residual lag plot has high correlation around lag 20, and the correlation of the residuals slightly increases as the lags get greater.\n\nNow let's select a candidate manually, including from SARIMA models. First we calculate and review the residuals from the linear regression:\n```{r}\n\nxMatrix4 = as.data.frame(xMatrix4)\n\n# Lets examine the residuals directly to identify \nmod4candidate2 <- lm(scale(combinedData$qqqRange) ~ mo3delta + mo6delta + mo12delta + events + dailyChange, data = xMatrix4 )\nsummary(mod1candidate2)\n\nresid4 <- mod4candidate2$residuals\npacf(resid4)\nacf(resid4)\n```\n\nThe ACF plot has many significant lags (>10) which suggests we may need to difference the residuals. The PACF plot has high significance through lag 5. Let's run a function to check all of the values up through p=2 and q=5.\n\n\n```{r}\n\nmod4candidate2fit =SARIMA.c(p1=1,p2=2,q1=1,q2=5,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid4)\nmod4candidate2fit %>% filter(!is.na(p))\n\n\n```\n\n\nThe best AIC and BIC scores returned by the function are for the model SARIMA(1,0,1)(1,1,0). Let's look at the diagnostic plots to see how well this model captures the data:\n\n```{r}\nmod4candidate2fit = arima(resid4, order = c(1,0,1), seasonal = list(order = c(1,1,0)))\ncheckresiduals(mod4candidate2fit)\n\n\n```\n\nThe residuals for this model look similar to the auto.arima model, so it will be interesting to compare them with cross validation. Otherwise, it is notable that the residuals display clustered volatility, while the lag plot shows significant correlations at some values, although the Ljung-Box test returns 0.795 so we can conclude there is no autocorrelation in the residuals.\n\n<h4> Model 5: (ARIMAX) QQQ ~ Interest Rate 3 months + Daily Property Damage + Daily VIX Change + Daily New Striking Workers </h4>\n\nI am leaving this model to fit after the homework.\n\n<h3> Model Selection for VAR Models </h3>\n\n<h4> Model 2: (VAR) SPY ~ Interest Rate 3-Months + Daily VIX Value <h4>\n\nStep 1, let's fit VAR with p=1 just to see the relationship between our 3 variables (SPY intraday range, 3-month interest rate changes, and the real daily VIX values). \n\n```{r}\n\nxMatrix2 = combinedData[,c('VIX.Adjusted', 'mo3delta', 'spyRange') ]\nxMatrix2[is.na(xMatrix2)] <- 0\nxMatrix2 = scale(xMatrix2)\nxMatrix2 = as.matrix(xMatrix2)\n\n#xMatrix\n\nsummary(vars::VAR(xMatrix2, p = 1, type = 'both'))\n\n\n```\n\nThe initial VAR fit is encouraging, as the 3 variables are all significant. SPY range has a p value of 0.09, which is slightly above the 0.05 threshold that would be ideal, but still suggests it helps explain the variance in the other variables in the model. The overall R squared and adjusted R squared are also encouraging, at 0.5, which is exceptionally high for a model concerning stock prices. \n\nNow lets use VAR select to identify some preferrable p values.\n```{r}\n\nvars::VARselect(xMatrix2, lag.max = 10, type = 'both')\n\n\n```\n\nVAR select returns either p =5 or p = 1 as the best fits, with AIC and FPE selecting p=5, and HQ and SC selecting p =1. We will use cross validation to compare these options.\n\n<h2> Model Evaluation </h2>\n\nIn this section, I will use cross validation to select the best candidate model for each of the 5 overaching model designs. First, lets define a cross validation function \n\n\n```{r}\n\n#######\n\ncrossVal <- function(arima1order, arima2order, sarima2order, data) {\n\n    # window is always 1\n    test <- 30\n    trainnum <- length(data) - test\n    rmse1 <- vector(mode = 'numeric', length = 30)\n    rmse2 <- vector(mode = 'numeric', length = 30)\n\n\n    for(i in 1:30) {\n        #print(trainnum + ((i-1) * 4))\n        #print(trainnum + (i*4))\n        #print(trainnum + ((i-1) * 4) +1)\n        \n        xtrain <- data[c(1:(trainnum + i - 1))]\n        xtest <-  data[c((trainnum+1):(trainnum+i+1))]\n        \n        \n        \n        ######## first Model ############\n        fit <- arima(xtrain, order = arima1order)\n        fcast <- predict(fit, n.ahead = 1)$pred[1]\n        \n        \n        ######## second model ###########\n        fit2 <- arima(xtrain, order = arima2order, seasonal = sarima2order)\n        fcast2 <- predict(fit2, n.ahead = 1)$pred[1]\n        \n        # Errors\n\n        rmse1[i]  <-sqrt((fcast-xtest[1])^2)\n        rmse2[i]  <-sqrt((fcast2-xtest[1])^2)\n        \n    }\n    \n    outputs = data.frame(\"rmse1\" = rmse1, 'rmse2' = rmse2)\n    return(outputs)\n\n}\n```\n\n<h3> Model 1 (ARIMAX) </h3>\n\nLets test the function out on the first model, comparing ARIMA(4,1,1) vs. SARIMA(1,0,1)(0,1,0) on the residuals of the linear regression.\n\n```{r}\nmodel1comparison = crossVal(c(4,1,1), c(1,0,1), list(order = c(0,1,0)), resid1)\n\nmean(model1comparison$rmse1)\nmean(model1comparison$rmse2)\n```\n\nBetween the two models, model 1, selected by auto.arima, beats out the sarima model with a mean RMSE of 0.2690 vs. 0.2696. However, the models do perform similarly to eachother. Let's look at a graph to make the difference more clear:\n\n\n```{r}\nindex1 = c(1:nrow(model1comparison))\nggplot(data = model1comparison, aes(x = index1, y = rmse1), color = 'blue') + geom_line() + geom_line(aes(x = index1, y = rmse2), color = 'red') + labs(title = 'Comparing RMSE of ARIMAX(4,1,1) Black and SARIMAX(1,0,1)(0,1,0) Red')\n\n```\n\nAs we can see in the cross-validation chart, the two models perform similarly, and tend to have higher and lower errors at the same time, with both of the models performing poorly near the middle of the cross validation data sets. But overall, the ARIMA (ARIMAX) model performs the best at predicting the residuals. As such, my chosen model for Model 1 is ARIMAX(4,1,1).\n\n<h4> Predictions </h4>\n\nNow, let's make predictions:\n```{r}\n\n#mod1candidate2 <- lm(scale(combinedData$spyRange) ~ mo12delta + pdam + dailyChange + workers, data = xMatrix )\n\n\nmod1pdam <- forecast(auto.arima(combinedData$pdam), 10)\nmod1delta12 <- forecast(auto.arima(combinedData$mo12delta), 10)\nmod1dailyChange <- forecast(auto.arima(combinedData$dailyChange), 10)\nmod1workers <- forecast(auto.arima(combinedData$workers), 10)\n\npredictors1 <- data.frame(cbind(pdam = mod1pdam$mean, mo12delta = mod1delta12$mean, dailyChange = mod1dailyChange$mean, workers = mod1workers$mean))\n\nfit = arima(combinedData$spyRange, order = c(4,1,1), xreg = xMatrix)\n\n#summary(fit)\n#forecast(fit)\nmod1 = predict(fit, newxreg = predictors1)\n\nautoplot(mod1$pred)\n```\n\nHere we can see the models predictions for the SPY daily upcoming range, using auto.arima generated models to predict the external regressors. Overall, the model predicts a precipitous drop in the daily range in SPY prices in the upcoming 10 days.\n\n\n<h3> Model 3 (ARIMAX)  IWM ~ Casualties + Hurricanes + Interest Rate 3-Months </h3>\n\nLet's compare the model returned by auto.arima, ARIMA(1,1,3), vs the model I found by hand, SARIMA(1,0,1)(1,1,0), on the residuals of the linear regression for model 3.\n\n```{r}\nmodel3comparison = crossVal(c(1,1,3), c(1,0,1), list(order = c(1,1,0)), resid3)\n\nmean(model3comparison$rmse1)\nmean(model3comparison$rmse2)\n```\n\nOnce again, the simple ARIMA model beats out the SARIMA architecture in terms of average RMSE. The average for ARIMA(1,1,3) was 0.554, while for SARIMA(1,0,1)(1,1,0) it was 0.601. Let's look at a plot of the rmse values to see how the models fared:\n\n```{r}\nindex3 = c(1:nrow(model3comparison))\nggplot(data = model3comparison, aes(x = index3, y = rmse1), color = 'blue') + geom_line() + geom_line(aes(x = index3, y = rmse2), color = 'red') + labs(title = 'Comparing RMSE of ARIMAX(1,1,3) Black and SARIMAX(1,0,1)(1,1,0) Red')\n\n```\n\nJust like for model 1, the two approaches performed similarly. If one model had a high RMSE for a particular value, the other model was likely to perform poorly as well. Overall however, we can see that for a given value the black line (ARIMA) tended to perform better. In the end, the ARIMAX models seems to fit the data well. As such, my chosen model for Model 3 is: ARIMAX(1,1,3)/.\n\n<h4> Predictions </h4>\n\nNow, let's make predictions:\n```{r}\n#xMatrix3 = combinedData[,c('mo3delta', 'casualties', 'hurricaneWarnings')]\n\nmod3cas <- forecast(auto.arima(combinedData$casualties), 10)\nmod3delta3 <- forecast(auto.arima(combinedData$mo3delta), 10)\nmod3hurricane <- forecast(auto.arima(combinedData$hurricaneWarnings), 10)\n\npredictors3 <- data.frame(cbind(casualties = mod3cas$mean, mo3delta = mod3delta3$mean, hurricaneWarnings = mod3hurricane$mean))\n\nfit3 = arima(combinedData$iwmRange, order = c(1,1,3), xreg = xMatrix3)\n\n#summary(fit)\n#forecast(fit)\nmod3 = predict(fit3, newxreg = predictors3)\n\nautoplot(mod3$pred)\n```\n\nHere we can see the models predictions for the IWM daily upcoming range, using auto.arima generated models to predict the external regressors. Overall, the model predicts a steep incline in IWM intraday ranges in the upcoming 10 days, especially in the first 5 before leveling off.\n\n<h3> Model 4 ARIMAX </h3>\nLeaving for future work.\n<h3> Model 5 ARIMAX </h3>\nLeaving for future work.\n\n<h3> Model 2 VAR </h3>\n\nLet's forecast our VAR model, which used 3-month interest rate changes and daily VIX values to predict SPY's intraday range. For this model we wanted to compare the p values of 1 and 5 to find the best model.\n\n\nLets, run our CV function:\n```{r}\n\ndata = xMatrix2\n\n    # window is always 1\n    test <- 30\n    trainnum <- nrow(data) - test\n    rmse1 <- matrix(NA, 30,3)\n    rmse1 <- data.frame(rmse1)\n    rmse2 <- matrix(NA, 30,3)\n    rmse2 <- data.frame(rmse2)\n\n\n    for(i in 1:29) {\n\n        xtrain <- data[c(1:(trainnum + i - 1)),]\n        xtest <-  data[c((trainnum+i):(trainnum+i+1)),]\n        \n        \n        \n        ######## first Model ############\n        fit <- vars::VAR(xtrain, p = 1, type = 'both')\n        \n        fcast <- predict(fit, n.ahead = 1)$fcst\n        \n        ff<-data.frame(fcast$VIX.Adjusted[,1],fcast$mo3delta[,1],fcast$spyRange[,1])\n        \n        ######## second model ###########\n        fit2 <- vars::VAR(xtrain,p =5, type = 'both')\n        fcast2 <- predict(fit2, n.ahead = 1)$fcst\n        \n        ff2<-data.frame(fcast2$VIX.Adjusted[,1],fcast2$mo3delta[,1],fcast2$spyRange[,1])\n\n        # Errors\n\n        rmse1[i,]  = sqrt((ff-xtest)^2)\n        rmse2[i,]  = sqrt((ff2-xtest)^2)\n        \n    }\n    \n    \n#print(rmse1)\n\n\nnames(rmse1) =c(\"VIXPrice\", \"3mo\",\"SPYDailyRange\")\nnames(rmse2) =c(\"VIXPrice\", \"3mo\",\"SPYDailyRange\")\n\ncolMeans(rmse1, na.rm = TRUE)\ncolMeans(rmse2, na.rm = TRUE)\n```\n\nAfter cross validating the 2 VAR models across 30 1-day intervals, we obtain the following average RMSE for the different variables: VIX Price: p=1 -> 0.148, p=5 -> 0.139. 3 Month Interest Rate Changes: p=1 -> 1.109, p=5 -> 1.190. SPY Daily Range: p=1 -> 0.696, p=5 -> 0.682. \n\nOverall, the p=1 VAR model was better at predicting the interest rate changes variable, and the p=5 VAR model performed better on the VIX Price and SPY daily range variables.\n\nLet's plot their performance:\n\n\n```{r}\nindex2 = c(1:nrow(rmse1))\n\nggplot() + \n  geom_line(data = rmse1, aes(x = index2, y = VIXPrice),color = \"blue\") +\n  geom_line(data = rmse2, aes(x = index2, y = VIXPrice),color = \"red\") +\n  labs(\n    title = \"CV RMSE for Vix Prices, Blue = (p=1), Red = (p=5)\",\n    x = \"Date\",\n    y = \"RMSE\",\n    guides(colour=guide_legend(title=\"Fit\")))\n\n\nggplot() + \n  geom_line(data = rmse1, aes(x = index2, y = SPYDailyRange),color = \"blue\") +\n  geom_line(data = rmse2, aes(x = index2, y = SPYDailyRange),color = \"red\") +\n  labs(\n    title = \"CV RMSE for SPY Daily Range, Blue = (p=1), Red = (p=5)\",\n    x = \"Date\",\n    y = \"RMSE\",\n    guides(colour=guide_legend(title=\"Fit\")))\n\n\n```\n\nOverall, the charts show what we confirmed with the average values: That the mean performance of the p=5 model was better on average.\n\nNow let's predict:\n```{r}\n\nfinalmod2 = vars::VAR(xMatrix2, p = 5, type = 'both')\n        \nmod2forecast <- predict(finalmod2, n.ahead = 10)$fcst\n\nindexmod2 = c(1:10)\nggplot() +\n    geom_line(aes(x = indexmod2, y = mod2forecast$spyRange[1:10]),color = \"blue\") +\n    geom_line(aes(x = indexmod2, y = mod2forecast$mo3delta[1:10]),color = \"red\") +\n    geom_line(aes(x = indexmod2, y = mod2forecast$VIX.Adjusted[1:10]),color = \"green\")\n\n```\n\nHere we can see the scale forecasts for the 3 key variables, which are created with the predict function for the VAR model with p=5. Overall, the model predicts the SPY range to raise slightly for the next 10 days, and the 3 month interest rates to change sharply.\n","srcMarkdownNoYaml":"\n\n\n<h2> Planning Models </h2>\n\nWe have the following independent variables:\n1. Interest Rate Expectation Changes - 3 Months \n2. Interest Rate Expectation Changes - 6 Months \n3. Interest Rate Expectation Changes - 1 Year\n4. Extreme Weather Events - Daily Event Number\n5. Extreme Weather Events - Daily Property Damage\n6. Extreme Weather Events - Daily Casualties\n7. Extreme Weather Events - Hurricanes\n8. Expected Volatility (VIX) - Value\n9. Expected Volatility (VIX) - Daily Change\n10. Work Stoppages - Daily Striking Worker Total\n11. Work Stoppages - Daily New Strike Beggining\n12. Work Stoppages - Daily New Workers Striking\n\n\n\n\n<h3> Preparing Exogenous Data </h3>\n\nFirst we need to create all 12 predictors, then we can combine them to estimate the models as needed.\n```{r}\nlibrary(knitr)\nlibrary(tidyverse)\nlibrary(quantmod)\nlibrary(forecast)\nlibrary(tseries)\nlibrary(lubridate)\nlibrary(reticulate)\n```\n\nLet's  quickly retrieve the daily stock price ranges for the indices:\n```{r}\nspyIn <- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn <- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn <- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\n\nspyIn$spyRange <- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange <- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange <- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n```\n\nNow, let's gather the VIX data, since it is also treated like a stock price, and should be available from the same package\n```{r}\nvixIn <- quantmod::getSymbols(\"^VIX\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\nvixIn$dailyChange <- vixIn$VIX.Close - lag(vixIn$VIX.Close)\n# 8 is vixIn$VIX.Close\n# 9 is vixIn$dailyChange\n\n#vixIn <- vixIn %>% \n#    mutate(date = ymd(index(vixIn)))\nhead(vixIn)\n```\n\nWe have bond yields stored in a CSV, but let's calculate daily changes:\n```{r}\nyieldCurve <- read.csv('data/treasuries.csv')\n\nyieldCurve$mo3delta <- yieldCurve$X3.Mo - lag(yieldCurve$X3.Mo)\nyieldCurve$mo6delta <- yieldCurve$X6.Mo - lag(yieldCurve$X6.Mo)\nyieldCurve$mo12delta <- yieldCurve$X1.Yr - lag(yieldCurve$X1.Yr) \n\nyieldCurve$Date <- mdy(yieldCurve$Date)\n```\n\nWorth noting: Both the treasury data and the VIX data only start on January 4th.\n\n\nNext up, let's prepare the weather event data:\n```{r}\nweather_data <- read.csv('data/storms_clean.csv')\n\n\nweather_data$month <- weather_data$BEGIN_YEARMONTH %% 100\n\nweather_data <- weather_data %>%\n    mutate(realdate = make_date(YEAR, month, BEGIN_DAY)) %>%\n    mutate(DAMAGE_PROPERTY =  str_replace(DAMAGE_PROPERTY, \"K\", \"\") )  %>%\n    mutate(DAMAGE_PROPERTY = as.numeric(DAMAGE_PROPERTY)) %>%\n    mutate(DAMAGE_PROPERTY = replace_na(DAMAGE_PROPERTY, 0))\n\n\n# Daily Event Number\ndaily_events <- weather_data %>%\n    group_by(realdate) %>%\n    summarize(events = length(EPISODE_ID))\n\n# Daily Property Damage\ndaily_property <-  weather_data %>%\n    group_by(realdate) %>%\n    summarize(pdam = sum(DAMAGE_PROPERTY))\n\n# Daily Daily Casualties\ndaily_casualties <-  weather_data %>%\n    group_by(realdate) %>%\n    summarize(casualties = sum(INJURIES_DIRECT) + sum(INJURIES_INDIRECT) + sum(DEATHS_DIRECT) + sum(DEATHS_INDIRECT))\n\n# Daily Hurricanes\ndaily_hurricanes <- weather_data %>%\n    filter(EVENT_TYPE == \"Hurricane\") %>%\n    group_by(realdate) %>%\n    summarize(hurricaneWarnings = length(EPISODE_ID))\n\n\n# Daily joined data\n\nweather_merged <- full_join(daily_events, daily_property, by = \"realdate\")\nweather_merged <- full_join(weather_merged, daily_casualties, by = 'realdate')\nweather_merged <- full_join(weather_merged, daily_hurricanes, by = 'realdate')\n\nhead(weather_merged)\n```\n\nFinally, lets get the striking worker data ready:\n```{r}\nstrike_data <- read.csv('data/strikes.csv')\n\n# clean date format\nstrike_data$start = mdy(strike_data$Work.stoppage.beginning.date)\nstrike_data$end = mdy(strike_data$Work.stoppage.ending.date)\nstrike_data$workers = as.numeric(str_replace(strike_data$Number.of.workers.2., \",\", \"\" ))\n\n\nhead(strike_data)\n\ntarget_dates <- ymd(index(spyIn))\n\ndaily_workers <- vector(mode = \"numeric\", length = length(target_dates))\n\nfor(i in seq_along(target_dates)) {\n    tempDat <- strike_data %>%\n        filter(start <= target_dates[i]) %>%\n        filter(end >= target_dates[i])\n\n    daily_workers[i] = sum(tempDat$workers)\n}\n\nworkerDF <- data.frame('workers' = daily_workers, 'date' = target_dates)\nplot(daily_workers, type = 'l')\n     \n```\n\nNow, we can combined all of these datasets into one dataframe, joining on the date columns\n```{r}\n# Convert TS objects to df, and fix the date column\nvixDF <- data.frame(vixIn)\nvixDF$date <- ymd(index(vixIn))\nspyDF <- data.frame(spyIn)\nspyDF$date <- ymd(index(spyIn))\nqqqDF <- data.frame(qqqIn)\nqqqDF$date <- ymd(index(qqqIn))\niwmDF <- data.frame(iwmIn)\niwmDF$date <- ymd(index(iwmIn))\n\n# Join symbols together\ntickers <- left_join(spyDF, vixDF, by = 'date')\ntickers <- left_join(tickers, qqqDF, by = 'date')\ntickers <- left_join(tickers, iwmDF, by = 'date')\n\n# Join weather data\ncombinedData <- left_join(tickers, weather_merged, by = c(\"date\" = \"realdate\"))\n\n# Join Bond Yields\ncombinedData <- left_join(combinedData, yieldCurve, by = c(\"date\" = \"Date\"))\n\n# Join Labor Data\ncombinedData <- left_join(combinedData, workerDF, by = 'date')\n\nhead(combinedData)\n\n\n```\n\n\n<h3> Select Models Based on These Exogenous Variables </h3>\n\nWe will combine these 12 predictors into 5 models, for SPY, QQQ, and IWM intraday volatility:\n\n<h4> Model 1: (ARIMAX) SPY ~ Interest Rate 1-Year + Daily Weather Property Damage + Daily VIX Change + Daily Striking Worker Total </h2>\n\nThis model is selected based on the literature review, which suggested that weather events and investor expecations could affect stock prices. This is the \"kitchen sink\" model, where I am throwing in variables from all data sources. However, looking at the variables individually, such as daily property damage vs. SPY daily price range, we don't nessecarily see clear correlation (see plot below which resembles white noise). But I am interested to see how these variables are related when taking many different contextual factors into account in the same model.\n\n```{r}\nggplot(combinedData, aes(x = log(spyRange), y = log(pdam)) ) + geom_point() + labs(title = \"3 Month Interest Rate Changes vs. VIX Change \", x = \"Log SPY Daily Spread\", y = \"Log Property Damage From Storms\")\n```\n\n\n<h4> Model 2: (VAR) SPY ~ Interest Rate 3-Months + Daily VIX Value </h4>\n\nThis model is based on a belief that there is an interrelationship between VIX prices and bond yields. This is because both would increase and decrease based on investor expectations for macroeconomic performance in upcoming months. If investors feel the economy will perform poorly, then this might predict bond yields lowering, as well as increased volatility which would be reflected by increases in the VIX. We also see a weak linear correlation in these daily values, as pictured in the plot below. \n\n```{r}\nggplot(combinedData, aes(x = mo3delta, y = dailyChange ) ) + geom_point() + labs(title = \"3 Month Interest Rate Changes vs. VIX Change \", x = \"Change in 3-Month Interest Rates\", y = \"Change in VIX Price\")\n```\n\n<h4> Model 3: (ARIMAX) IWM ~ Casualties + Hurricanes + Interest Rate 3-Months </h4>\n\nThis model is all about exogenous shocks. New strikes beggining and hurricane warnings are infrequent but extreme events, which have been grouped together with short-term interest rates (3 month window) to try and capture extreme-but-short-termm influences on volatility.\n\n<h4> Model 4: (ARIMAX) QQQ ~ All Interest Rates + All Extreme Weather Events + Daily VIX Change + Daily Striking Workers </h4>\n<h4> Model 5: (ARIMAX) QQQ ~ Interest Rate 3 months + Daily Property Damage + Daily VIX Change + Daily New Striking Workers </h4>\n\nModels 4 and 5 follow the same logic as model 1, being selected based off of the literature review, but looking at QQQ as oppposed to SPY to see whether large-cap tech companies are more likely to be affected by this kind of volatility.\n\n<h2> Model Selection </h2>\n\nIn this section, I will begin by identifying the candidate model structures for each of the 5 overarching models outlined above. I will identify candidate models through auto.arima for ARIMAX models, plus hand-selected values. For VAR models, I will identify 2 candidates for each overall model with the autoVAR function.\n\n<h3> Model Selection for ARIMAX Models </h3>\n\n\n\n<h4> Model 1: SPY ~ Interest Rate 1-Year + Daily Weather Property Damage + Daily VIX Change + Daily Striking Worker Total </h2>\n```{r}\n\nxMatrix = combinedData[,c('mo12delta', 'pdam', 'dailyChange', 'workers')]\nxMatrix[is.na(xMatrix)] <- 0\nxMatrix = scale(xMatrix)\nxMatrix = as.matrix(xMatrix)\n\n#xMatrix\n\nmod1candidate1 = auto.arima(scale(combinedData$spyRange), xreg = xMatrix, trace = TRUE)\ncheckresiduals(mod1candidate1)\n```\n\nAuto ARIMA picks out the model (4,1,1) for the standardized data. The residual diagnostic plots look good, with the residuals normally distributed. \n\n```{r}\nxMatrix = as.data.frame(xMatrix)\n\n# Lets examine the residuals directly to identify \nmod1candidate2 <- lm(scale(combinedData$spyRange) ~ mo12delta + pdam + dailyChange + workers, data = xMatrix )\nsummary(mod1candidate2)\n\nresid1 <- mod1candidate2$residuals\npacf(resid1)\nacf(resid1)\n\n```\n\nBased on the PACF and ACF of the residuals from the regression, it seems we should definitely difference the series, as we have many significant lag terms in the ACF. On the PACF, we can see 4 terms clearly  signfificant. Based on these charts, I might try the model (4,1,0). I will try up through (4,2,2) and look for the lowest aic.\n```{r}\n\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \ntemp=c()\nd=1\nD=1\ns=12\n \ni=1\ntemp= data.frame()\nls=matrix(rep(NA,9*378),nrow=378)\n \n \nfor (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          for(d in d1:d2)\n       \n        {\n          if(p+d+q+P+D+Q<=8)\n          {\n            \n            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  \n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\nSARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid1) %>% filter(!is.na(p))\n\nmod1candidate2 <- arima(resid1, order = c(1,0,1), seasonal = list(order = c(0,1,0)))\ncheckresiduals(mod1candidate2)\n```\n\nThe function to evaluate various p,d,q values returns SARIMA(1,0,1)(0,1,0)[12] with the lowest AIC and BIC. The residuals of this second model show clear correlation around lags 2 and 4, which was not present in the 4,1,0 model that auto arima suggested. So overall, I would say the diagnostics look worse for the second model than the first.\n\n\n\n<h4> Model 3: (ARIMAX) IWM ~ Casualties + Hurricanes + Interest Rate 3-Months </h4>\n\n```{r}\n\nxMatrix3 = combinedData[,c('mo3delta', 'casualties', 'hurricaneWarnings')]\nxMatrix3[is.na(xMatrix3)] <- 0\nxMatrix3 = scale(xMatrix3)\nxMatrix3 = as.matrix(xMatrix3)\n\n#xMatrix\n\nmod3candidate1 = auto.arima(scale(combinedData$iwmRange), xreg = xMatrix3, trace = TRUE)\ncheckresiduals(mod3candidate1)\n```\n\nAuto.arima identifies (1,1,3) as the best model. The residuals show a low level of correlation in the lags, which is encouraging, and overall the residuals are mostly normally distributed although they are somewhat skewed to the right. Now, let's see what we manually select, also considering a SARIMAX model.\n\n\nPrepare residuals:\n```{r}\nxMatrix3 = as.data.frame(xMatrix3)\n\n# Lets examine the residuals directly to identify \nmod3candidate2 <- lm(scale(combinedData$iwmRange) ~ casualties + mo3delta + hurricaneWarnings, data = xMatrix3 )\nsummary(mod3candidate2)\n\nresid3 <- mod3candidate2$residuals\npacf(resid3)\nacf(resid3)\n\n```\n\nThe ACF and PACF plots of the residuals from linear regression are mixed, but there is clear correlation through value 5 in the PACF plot. The ACF plot has many significant terms, suggesting the series should be differenced. Now, I'll loop through all the options to see if there is a suitable SARIMA model for the residuals:\n\n\n```{r}\n\noutput=SARIMA.c(p1=1,p2=3,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid3)\noutput %>% filter(!is.na(p))\n\n```\n\nThe best model identified by a small margin is SARIMA(1,0,1)(1,1,0). Let's check the diagnostics\n```{r}\nresidualsMod3Can2 <- arima(resid3, order = c(1,0,1), seasonal = list(order = c(1,1,0)))\ncheckresiduals(residualsMod3Can2)\n\n```\n\nThe residuals for this model arent encouraging, as the Ljung Box test returns a p value of 0.03. THe residuals also do not look perfectly normally distributed.\n\n\n<h4> Model 4: (ARIMAX) QQQ ~ All Interest Rates + All Extreme Weather Events + Daily VIX Change + Daily Striking Workers </h4>\n\nRunning an auto arima:\n```{r}\n\nxMatrix4 = combinedData[,c('mo3delta', 'mo6delta', 'mo12delta', 'events', 'dailyChange', 'workers')]\nxMatrix4[is.na(xMatrix4)] <- 0\nxMatrix4 = scale(xMatrix4)\nxMatrix4 = as.matrix(xMatrix4)\n\n#xMatrix\n\nmod4candidate1 = auto.arima(scale(combinedData$qqqRange), xreg = xMatrix4, trace = TRUE)\ncheckresiduals(mod4candidate1)\n\n```\n\n\nAuto Arima returns (1,1,1). The diagnostics look acceptable, although there is clustered volatility in the residual plot. The Ljung-Box test returns p = 0.95, suggesting there is not autocorrelation in the residuals. However, the residual lag plot has high correlation around lag 20, and the correlation of the residuals slightly increases as the lags get greater.\n\nNow let's select a candidate manually, including from SARIMA models. First we calculate and review the residuals from the linear regression:\n```{r}\n\nxMatrix4 = as.data.frame(xMatrix4)\n\n# Lets examine the residuals directly to identify \nmod4candidate2 <- lm(scale(combinedData$qqqRange) ~ mo3delta + mo6delta + mo12delta + events + dailyChange, data = xMatrix4 )\nsummary(mod1candidate2)\n\nresid4 <- mod4candidate2$residuals\npacf(resid4)\nacf(resid4)\n```\n\nThe ACF plot has many significant lags (>10) which suggests we may need to difference the residuals. The PACF plot has high significance through lag 5. Let's run a function to check all of the values up through p=2 and q=5.\n\n\n```{r}\n\nmod4candidate2fit =SARIMA.c(p1=1,p2=2,q1=1,q2=5,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid4)\nmod4candidate2fit %>% filter(!is.na(p))\n\n\n```\n\n\nThe best AIC and BIC scores returned by the function are for the model SARIMA(1,0,1)(1,1,0). Let's look at the diagnostic plots to see how well this model captures the data:\n\n```{r}\nmod4candidate2fit = arima(resid4, order = c(1,0,1), seasonal = list(order = c(1,1,0)))\ncheckresiduals(mod4candidate2fit)\n\n\n```\n\nThe residuals for this model look similar to the auto.arima model, so it will be interesting to compare them with cross validation. Otherwise, it is notable that the residuals display clustered volatility, while the lag plot shows significant correlations at some values, although the Ljung-Box test returns 0.795 so we can conclude there is no autocorrelation in the residuals.\n\n<h4> Model 5: (ARIMAX) QQQ ~ Interest Rate 3 months + Daily Property Damage + Daily VIX Change + Daily New Striking Workers </h4>\n\nI am leaving this model to fit after the homework.\n\n<h3> Model Selection for VAR Models </h3>\n\n<h4> Model 2: (VAR) SPY ~ Interest Rate 3-Months + Daily VIX Value <h4>\n\nStep 1, let's fit VAR with p=1 just to see the relationship between our 3 variables (SPY intraday range, 3-month interest rate changes, and the real daily VIX values). \n\n```{r}\n\nxMatrix2 = combinedData[,c('VIX.Adjusted', 'mo3delta', 'spyRange') ]\nxMatrix2[is.na(xMatrix2)] <- 0\nxMatrix2 = scale(xMatrix2)\nxMatrix2 = as.matrix(xMatrix2)\n\n#xMatrix\n\nsummary(vars::VAR(xMatrix2, p = 1, type = 'both'))\n\n\n```\n\nThe initial VAR fit is encouraging, as the 3 variables are all significant. SPY range has a p value of 0.09, which is slightly above the 0.05 threshold that would be ideal, but still suggests it helps explain the variance in the other variables in the model. The overall R squared and adjusted R squared are also encouraging, at 0.5, which is exceptionally high for a model concerning stock prices. \n\nNow lets use VAR select to identify some preferrable p values.\n```{r}\n\nvars::VARselect(xMatrix2, lag.max = 10, type = 'both')\n\n\n```\n\nVAR select returns either p =5 or p = 1 as the best fits, with AIC and FPE selecting p=5, and HQ and SC selecting p =1. We will use cross validation to compare these options.\n\n<h2> Model Evaluation </h2>\n\nIn this section, I will use cross validation to select the best candidate model for each of the 5 overaching model designs. First, lets define a cross validation function \n\n\n```{r}\n\n#######\n\ncrossVal <- function(arima1order, arima2order, sarima2order, data) {\n\n    # window is always 1\n    test <- 30\n    trainnum <- length(data) - test\n    rmse1 <- vector(mode = 'numeric', length = 30)\n    rmse2 <- vector(mode = 'numeric', length = 30)\n\n\n    for(i in 1:30) {\n        #print(trainnum + ((i-1) * 4))\n        #print(trainnum + (i*4))\n        #print(trainnum + ((i-1) * 4) +1)\n        \n        xtrain <- data[c(1:(trainnum + i - 1))]\n        xtest <-  data[c((trainnum+1):(trainnum+i+1))]\n        \n        \n        \n        ######## first Model ############\n        fit <- arima(xtrain, order = arima1order)\n        fcast <- predict(fit, n.ahead = 1)$pred[1]\n        \n        \n        ######## second model ###########\n        fit2 <- arima(xtrain, order = arima2order, seasonal = sarima2order)\n        fcast2 <- predict(fit2, n.ahead = 1)$pred[1]\n        \n        # Errors\n\n        rmse1[i]  <-sqrt((fcast-xtest[1])^2)\n        rmse2[i]  <-sqrt((fcast2-xtest[1])^2)\n        \n    }\n    \n    outputs = data.frame(\"rmse1\" = rmse1, 'rmse2' = rmse2)\n    return(outputs)\n\n}\n```\n\n<h3> Model 1 (ARIMAX) </h3>\n\nLets test the function out on the first model, comparing ARIMA(4,1,1) vs. SARIMA(1,0,1)(0,1,0) on the residuals of the linear regression.\n\n```{r}\nmodel1comparison = crossVal(c(4,1,1), c(1,0,1), list(order = c(0,1,0)), resid1)\n\nmean(model1comparison$rmse1)\nmean(model1comparison$rmse2)\n```\n\nBetween the two models, model 1, selected by auto.arima, beats out the sarima model with a mean RMSE of 0.2690 vs. 0.2696. However, the models do perform similarly to eachother. Let's look at a graph to make the difference more clear:\n\n\n```{r}\nindex1 = c(1:nrow(model1comparison))\nggplot(data = model1comparison, aes(x = index1, y = rmse1), color = 'blue') + geom_line() + geom_line(aes(x = index1, y = rmse2), color = 'red') + labs(title = 'Comparing RMSE of ARIMAX(4,1,1) Black and SARIMAX(1,0,1)(0,1,0) Red')\n\n```\n\nAs we can see in the cross-validation chart, the two models perform similarly, and tend to have higher and lower errors at the same time, with both of the models performing poorly near the middle of the cross validation data sets. But overall, the ARIMA (ARIMAX) model performs the best at predicting the residuals. As such, my chosen model for Model 1 is ARIMAX(4,1,1).\n\n<h4> Predictions </h4>\n\nNow, let's make predictions:\n```{r}\n\n#mod1candidate2 <- lm(scale(combinedData$spyRange) ~ mo12delta + pdam + dailyChange + workers, data = xMatrix )\n\n\nmod1pdam <- forecast(auto.arima(combinedData$pdam), 10)\nmod1delta12 <- forecast(auto.arima(combinedData$mo12delta), 10)\nmod1dailyChange <- forecast(auto.arima(combinedData$dailyChange), 10)\nmod1workers <- forecast(auto.arima(combinedData$workers), 10)\n\npredictors1 <- data.frame(cbind(pdam = mod1pdam$mean, mo12delta = mod1delta12$mean, dailyChange = mod1dailyChange$mean, workers = mod1workers$mean))\n\nfit = arima(combinedData$spyRange, order = c(4,1,1), xreg = xMatrix)\n\n#summary(fit)\n#forecast(fit)\nmod1 = predict(fit, newxreg = predictors1)\n\nautoplot(mod1$pred)\n```\n\nHere we can see the models predictions for the SPY daily upcoming range, using auto.arima generated models to predict the external regressors. Overall, the model predicts a precipitous drop in the daily range in SPY prices in the upcoming 10 days.\n\n\n<h3> Model 3 (ARIMAX)  IWM ~ Casualties + Hurricanes + Interest Rate 3-Months </h3>\n\nLet's compare the model returned by auto.arima, ARIMA(1,1,3), vs the model I found by hand, SARIMA(1,0,1)(1,1,0), on the residuals of the linear regression for model 3.\n\n```{r}\nmodel3comparison = crossVal(c(1,1,3), c(1,0,1), list(order = c(1,1,0)), resid3)\n\nmean(model3comparison$rmse1)\nmean(model3comparison$rmse2)\n```\n\nOnce again, the simple ARIMA model beats out the SARIMA architecture in terms of average RMSE. The average for ARIMA(1,1,3) was 0.554, while for SARIMA(1,0,1)(1,1,0) it was 0.601. Let's look at a plot of the rmse values to see how the models fared:\n\n```{r}\nindex3 = c(1:nrow(model3comparison))\nggplot(data = model3comparison, aes(x = index3, y = rmse1), color = 'blue') + geom_line() + geom_line(aes(x = index3, y = rmse2), color = 'red') + labs(title = 'Comparing RMSE of ARIMAX(1,1,3) Black and SARIMAX(1,0,1)(1,1,0) Red')\n\n```\n\nJust like for model 1, the two approaches performed similarly. If one model had a high RMSE for a particular value, the other model was likely to perform poorly as well. Overall however, we can see that for a given value the black line (ARIMA) tended to perform better. In the end, the ARIMAX models seems to fit the data well. As such, my chosen model for Model 3 is: ARIMAX(1,1,3)/.\n\n<h4> Predictions </h4>\n\nNow, let's make predictions:\n```{r}\n#xMatrix3 = combinedData[,c('mo3delta', 'casualties', 'hurricaneWarnings')]\n\nmod3cas <- forecast(auto.arima(combinedData$casualties), 10)\nmod3delta3 <- forecast(auto.arima(combinedData$mo3delta), 10)\nmod3hurricane <- forecast(auto.arima(combinedData$hurricaneWarnings), 10)\n\npredictors3 <- data.frame(cbind(casualties = mod3cas$mean, mo3delta = mod3delta3$mean, hurricaneWarnings = mod3hurricane$mean))\n\nfit3 = arima(combinedData$iwmRange, order = c(1,1,3), xreg = xMatrix3)\n\n#summary(fit)\n#forecast(fit)\nmod3 = predict(fit3, newxreg = predictors3)\n\nautoplot(mod3$pred)\n```\n\nHere we can see the models predictions for the IWM daily upcoming range, using auto.arima generated models to predict the external regressors. Overall, the model predicts a steep incline in IWM intraday ranges in the upcoming 10 days, especially in the first 5 before leveling off.\n\n<h3> Model 4 ARIMAX </h3>\nLeaving for future work.\n<h3> Model 5 ARIMAX </h3>\nLeaving for future work.\n\n<h3> Model 2 VAR </h3>\n\nLet's forecast our VAR model, which used 3-month interest rate changes and daily VIX values to predict SPY's intraday range. For this model we wanted to compare the p values of 1 and 5 to find the best model.\n\n\nLets, run our CV function:\n```{r}\n\ndata = xMatrix2\n\n    # window is always 1\n    test <- 30\n    trainnum <- nrow(data) - test\n    rmse1 <- matrix(NA, 30,3)\n    rmse1 <- data.frame(rmse1)\n    rmse2 <- matrix(NA, 30,3)\n    rmse2 <- data.frame(rmse2)\n\n\n    for(i in 1:29) {\n\n        xtrain <- data[c(1:(trainnum + i - 1)),]\n        xtest <-  data[c((trainnum+i):(trainnum+i+1)),]\n        \n        \n        \n        ######## first Model ############\n        fit <- vars::VAR(xtrain, p = 1, type = 'both')\n        \n        fcast <- predict(fit, n.ahead = 1)$fcst\n        \n        ff<-data.frame(fcast$VIX.Adjusted[,1],fcast$mo3delta[,1],fcast$spyRange[,1])\n        \n        ######## second model ###########\n        fit2 <- vars::VAR(xtrain,p =5, type = 'both')\n        fcast2 <- predict(fit2, n.ahead = 1)$fcst\n        \n        ff2<-data.frame(fcast2$VIX.Adjusted[,1],fcast2$mo3delta[,1],fcast2$spyRange[,1])\n\n        # Errors\n\n        rmse1[i,]  = sqrt((ff-xtest)^2)\n        rmse2[i,]  = sqrt((ff2-xtest)^2)\n        \n    }\n    \n    \n#print(rmse1)\n\n\nnames(rmse1) =c(\"VIXPrice\", \"3mo\",\"SPYDailyRange\")\nnames(rmse2) =c(\"VIXPrice\", \"3mo\",\"SPYDailyRange\")\n\ncolMeans(rmse1, na.rm = TRUE)\ncolMeans(rmse2, na.rm = TRUE)\n```\n\nAfter cross validating the 2 VAR models across 30 1-day intervals, we obtain the following average RMSE for the different variables: VIX Price: p=1 -> 0.148, p=5 -> 0.139. 3 Month Interest Rate Changes: p=1 -> 1.109, p=5 -> 1.190. SPY Daily Range: p=1 -> 0.696, p=5 -> 0.682. \n\nOverall, the p=1 VAR model was better at predicting the interest rate changes variable, and the p=5 VAR model performed better on the VIX Price and SPY daily range variables.\n\nLet's plot their performance:\n\n\n```{r}\nindex2 = c(1:nrow(rmse1))\n\nggplot() + \n  geom_line(data = rmse1, aes(x = index2, y = VIXPrice),color = \"blue\") +\n  geom_line(data = rmse2, aes(x = index2, y = VIXPrice),color = \"red\") +\n  labs(\n    title = \"CV RMSE for Vix Prices, Blue = (p=1), Red = (p=5)\",\n    x = \"Date\",\n    y = \"RMSE\",\n    guides(colour=guide_legend(title=\"Fit\")))\n\n\nggplot() + \n  geom_line(data = rmse1, aes(x = index2, y = SPYDailyRange),color = \"blue\") +\n  geom_line(data = rmse2, aes(x = index2, y = SPYDailyRange),color = \"red\") +\n  labs(\n    title = \"CV RMSE for SPY Daily Range, Blue = (p=1), Red = (p=5)\",\n    x = \"Date\",\n    y = \"RMSE\",\n    guides(colour=guide_legend(title=\"Fit\")))\n\n\n```\n\nOverall, the charts show what we confirmed with the average values: That the mean performance of the p=5 model was better on average.\n\nNow let's predict:\n```{r}\n\nfinalmod2 = vars::VAR(xMatrix2, p = 5, type = 'both')\n        \nmod2forecast <- predict(finalmod2, n.ahead = 10)$fcst\n\nindexmod2 = c(1:10)\nggplot() +\n    geom_line(aes(x = indexmod2, y = mod2forecast$spyRange[1:10]),color = \"blue\") +\n    geom_line(aes(x = indexmod2, y = mod2forecast$mo3delta[1:10]),color = \"red\") +\n    geom_line(aes(x = indexmod2, y = mod2forecast$VIX.Adjusted[1:10]),color = \"green\")\n\n```\n\nHere we can see the scale forecasts for the 3 key variables, which are created with the predict function for the VAR model with p=5. Overall, the model predicts the SPY range to raise slightly for the next 10 days, and the 3 month interest rates to change sharply.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"ARIMAX SARIMAX VAR.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"sandstone","title":"Data Sources","author":"Corwin Dark"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}