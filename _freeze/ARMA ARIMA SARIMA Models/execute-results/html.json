{
  "hash": "e0b5848336ccd43865a2b542aa4b76ae",
  "result": {
    "markdown": "---\ntitle: \"ARMA ARIMA SARIMA MODELS\"\n---\n\n\nLoading packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(quantmod)\nlibrary(forecast)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(lubridate)\n```\n:::\n\n\n\n\nBringing the data into this tab as well:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Show Code\"}\nspyIn <- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn <- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn <- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\n\nspyIn$spyRange <- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange <- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange <- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n\n\ndiff1SPY <- diff(spyIn$spyRange)\ndiff1QQQ <- diff(qqqIn$qqqRange)\ndiff1IWM <- diff(iwmIn$iwmRange)\n```\n:::\n\n\n\n\n<h2> Stationarity of the time series </h2>\n\nBased on previous results, and the fact that I am using \"pseudo-differenced data\" in that I am taking the percentage range in prices, in addition to a single differencing, means that the time series are stationary\n\n\n<h2> Building ARIMA Model </h2>\n\nSince I did some of this work with SPY data on the EDA tab, I will focus on QQQ range data here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#print(diff1QQQ)\nacf(diff1QQQ, na.action = na.exclude)\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\npacf(diff1QQQ, na.action = na.exclude)\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\nBased on these charts the order I would pick for QQQ is: ARIMA(2,1,0)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelQQQ1 <- arima(diff1QQQ, order = c(2,1,0))\nsummary(modelQQQ1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\narima(x = diff1QQQ, order = c(2, 1, 0))\n\nCoefficients:\n          ar1      ar2\n      -1.0035  -0.4832\ns.e.   0.0334   0.0334\n\nsigma^2 estimated as 0.0001131:  log likelihood = 2149.08,  aic = -4292.16\n\nTraining set error measures:\n                       ME       RMSE         MAE      MPE     MAPE      MASE\nTraining set 4.630039e-05 0.01062913 0.007805518 87.46782 258.6253 0.6398223\n                   ACF1\nTraining set -0.1944037\n```\n:::\n:::\n\n\n5. Equation is x = -1.0034x(t-1) - 0.4832x(t-2) + error\n\n6. Model Diagnostic:\n\n::: {.cell}\n\n```{.r .cell-code}\nstats::tsdiag(modelQQQ1)\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThe Ljung Box statistics look cood, although the ACF of the residuals does have 1 significant term.\n\nI originally tried a (4,1,2) model, however the ljung box statistics were highly correlated, and I suspected overfitting. After reducing the parametrization greatly, the new model performed mnuch better.\n\n7.\n\n::: {.cell}\n\n```{.r .cell-code}\nautoQQQ <- auto.arima(diff1QQQ)\nsummary(autoQQQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSeries: diff1QQQ \nARIMA(1,0,1) with zero mean \n\nCoefficients:\n          ar1      ma1\n      -0.0008  -0.8122\ns.e.   0.0524   0.0361\n\nsigma^2 = 5.483e-05:  log likelihood = 2402.77\nAIC=-4799.55   AICc=-4799.51   BIC=-4785.94\n\nTraining set error measures:\n                        ME       RMSE         MAE      MPE     MAPE     MASE\nTraining set -6.694728e-05 0.00739421 0.005455453 283.3672 549.0245 0.446905\n                    ACF1\nTraining set 0.003755607\n```\n:::\n:::\n\n\nThe auto.arima method chose an ARIMA(1,0,1) model. However, this model did not perform as well in terms of AIC, with the Auto arima model having a score of -4799 while my model had a score of -4292.\n\n\n8. Forecasting with my model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(forecast(modelQQQ1, 10), xlim = c(650,750))   \n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\nForecasting with auto arima model\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(forecast(autoQQQ, 10), xlim = c(650,750))\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nOverall, my model has a slightly more dynamic prediction than the auto arima function, which quicly levels out to 0. However, my model also has a much wider uncertainty band.\n\n\n9. Compare ARIMA model with benchmarks\n\n::: {.cell}\n\n```{.r .cell-code}\nnaiveModelQQQ <- naive(diff1QQQ, h=1)\nsnaiveModelQQQ <- snaive(diff1QQQ, h=1)\n\nsummary(naiveModelQQQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nForecast method: Naive method\n\nModel Information:\nCall: naive(y = diff1QQQ, h = 1) \n\nResidual sd: 0.0165 \n\nError measures:\n                       ME     RMSE        MAE      MPE     MAPE MASE       ACF1\nTraining set 2.387746e-05 0.016488 0.01219951 309.6279 564.6879    1 -0.6746326\n\nForecasts:\n    Point Forecast       Lo 80      Hi 80       Lo 95      Hi 95\n691   -0.003168135 -0.02429836 0.01796209 -0.03548403 0.02914776\n```\n:::\n\n```{.r .cell-code}\nsummary(snaiveModelQQQ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nForecast method: Seasonal naive method\n\nModel Information:\nCall: snaive(y = diff1QQQ, h = 1) \n\nResidual sd: 0.0165 \n\nError measures:\n                       ME     RMSE        MAE      MPE     MAPE MASE       ACF1\nTraining set 2.387746e-05 0.016488 0.01219951 309.6279 564.6879    1 -0.6746326\n\nForecasts:\n    Point Forecast       Lo 80      Hi 80       Lo 95      Hi 95\n691   -0.003168135 -0.02429836 0.01796209 -0.03548403 0.02914776\n```\n:::\n\n```{.r .cell-code}\nsummary(modelQQQ1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\narima(x = diff1QQQ, order = c(2, 1, 0))\n\nCoefficients:\n          ar1      ar2\n      -1.0035  -0.4832\ns.e.   0.0334   0.0334\n\nsigma^2 estimated as 0.0001131:  log likelihood = 2149.08,  aic = -4292.16\n\nTraining set error measures:\n                       ME       RMSE         MAE      MPE     MAPE      MASE\nTraining set 4.630039e-05 0.01062913 0.007805518 87.46782 258.6253 0.6398223\n                   ACF1\nTraining set -0.1944037\n```\n:::\n:::\n\n\nI fit a naive and seasonal naive model. On RMSE my model had the best performance, with 0.011, while the naive and snaive models had 0.017 rmse each (since there was no seasonal period I realized they were the same model). On MAE my arima model had 0.008 while the seasonal naive models had 0.0122.\n\nLet's compare forecasts:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(forecast(modelQQQ1, 10), xlim = c(650,750)) \n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(forecast(naiveModelQQQ, 10), xlim = c(650,750))   \n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\nHere, the naive method can only forecast 1 observation into the future, since the seasonal period is one. Which is an advantage to my model, but realistically means the naive model should be evaluated with cross validation.\n\n\n<h2> SARIMA </h2>\n\nLet's look for a seasonal affect in the ACF plots, using the weather events data. First we prepare the data:\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_data <- read.csv('data/storms_clean.csv')\n\n\nweather_data$month <- weather_data$BEGIN_YEARMONTH %% 100\n\nweather_data <- weather_data %>%\n    mutate(realdate = make_date(YEAR, month, BEGIN_DAY)) %>%\n    mutate(DAMAGE_PROPERTY =  str_replace(DAMAGE_PROPERTY, \"K\", \"\") )  %>%\n    mutate(DAMAGE_PROPERTY = as.numeric(DAMAGE_PROPERTY)) %>%\n    mutate(DAMAGE_PROPERTY = replace_na(DAMAGE_PROPERTY, 0))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: There was 1 warning in `mutate()`.\ni In argument: `DAMAGE_PROPERTY = as.numeric(DAMAGE_PROPERTY)`.\nCaused by warning:\n! NAs introduced by coercion\n```\n:::\n\n```{.r .cell-code}\n# Daily Event Number\ndaily_events <- weather_data %>%\n    group_by(realdate) %>%\n    summarize(events = length(EPISODE_ID))\n\n# Daily Property Damage\ndaily_property <-  weather_data %>%\n    group_by(realdate) %>%\n    summarize(pdam = sum(DAMAGE_PROPERTY))\n\n# Daily Daily Casualties\ndaily_casualties <-  weather_data %>%\n    group_by(realdate) %>%\n    summarize(casualties = sum(INJURIES_DIRECT) + sum(INJURIES_INDIRECT) + sum(DEATHS_DIRECT) + sum(DEATHS_INDIRECT))\n\n# Daily Hurricanes\ndaily_hurricanes <- weather_data %>%\n    filter(EVENT_TYPE == \"Hurricane\") %>%\n    group_by(realdate) %>%\n    summarize(hurricaneWarnings = length(EPISODE_ID))\n\n\n# Daily joined data\n\nweather_merged <- full_join(daily_events, daily_property, by = \"realdate\")\nweather_merged <- full_join(weather_merged, daily_casualties, by = 'realdate')\nweather_merged <- full_join(weather_merged, daily_hurricanes, by = 'realdate')\n\nhead(weather_merged)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 5\n  realdate   events  pdam casualties hurricaneWarnings\n  <date>      <int> <dbl>      <int>             <int>\n1 2021-01-01    643  918           1                NA\n2 2021-01-02     75  189.          0                NA\n3 2021-01-03     80   63           3                NA\n4 2021-01-04     44   20           0                NA\n5 2021-01-05     18    0           2                NA\n6 2021-01-06     27  850           2                NA\n```\n:::\n:::\n\n\nNow, lets look at the acf plot:\n\n::: {.cell}\n\n```{.r .cell-code}\nacf(weather_merged$events, lag.max = 365)\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nWith a 365 lag plot (as we are looking at weather data), we can see that for about 1/4 of the 365 lags, there is some positive correlation in the residuals (the same season), then for 1/2 the lags after that there is negative correlation (the opposite seasons), and then a return to significant positive correlation about 3/4 of the way through the data. This appears to show a clear seasonal effect of about 365. So let's seasonally difference the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseasonDiff <- weather_merged$events %>% diff(lag = 365)\nacf(seasonDiff, lag.max = 365)\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\npacf(seasonDiff)\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n:::\n\n\nAfter seasonal differencing, this plot looks much much better, without noticeable season-to-season correlations in the lags, although there is still some short-term correlation. And some repeating period which appears to be almost weekly in the residuals.\n\n\nBased on the ACF and PACF plots, I would consider p of 1, d of 0, and q of 3. Then for P and Q I might consider 0, D would be 1 since we seasonally differenced. But let's run some code to see the AIC of different values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \ntemp=c()\nd=1\nD=1\ns=12\n \ni=1\ntemp= data.frame()\nls=matrix(rep(NA,9*378),nrow=378)\n \nfor (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          for(d in d1:d2)\n       \n        {\n          if(p+d+q+P+D+Q<=8)\n          {\n            \n            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  \n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\nSARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=weather_merged$events) %>% filter(!is.na(p))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   p d q P D Q      AIC      BIC     AICc\n1  0 0 0 0 1 0 12204.30 12213.93 12204.32\n2  0 1 0 0 1 0 12419.43 12424.24 12419.43\n3  0 0 0 0 1 1 12204.30 12213.93 12204.32\n4  0 1 0 0 1 1 12419.43 12424.24 12419.43\n5  0 0 0 1 1 0 12204.30 12213.93 12204.32\n6  0 1 0 1 1 0 12419.43 12424.24 12419.43\n7  0 0 0 1 1 1 12204.30 12213.93 12204.32\n8  0 1 0 1 1 1 12419.43 12424.24 12419.43\n9  0 0 0 2 1 0 12204.30 12213.93 12204.32\n10 0 1 0 2 1 0 12419.43 12424.24 12419.43\n11 0 0 0 2 1 1 12204.30 12213.93 12204.32\n12 0 0 1 0 1 0 12102.10 12116.55 12102.13\n13 0 1 1 0 1 0 12130.44 12140.07 12130.46\n14 0 0 1 0 1 1 12102.10 12116.55 12102.13\n15 0 1 1 0 1 1 12130.44 12140.07 12130.46\n16 0 0 1 1 1 0 12102.10 12116.55 12102.13\n17 0 1 1 1 1 0 12130.44 12140.07 12130.46\n18 0 0 1 1 1 1 12102.10 12116.55 12102.13\n19 0 0 1 2 1 0 12102.10 12116.55 12102.13\n20 0 0 2 0 1 0 12090.24 12109.50 12090.28\n21 0 1 2 0 1 0 12071.61 12086.05 12071.64\n22 0 0 2 0 1 1 12090.24 12109.50 12090.28\n23 0 0 2 1 1 0 12090.24 12109.50 12090.28\n24 0 0 3 0 1 0 12090.34 12114.42 12090.41\n25 1 0 0 0 1 0 12084.41 12098.85 12084.43\n26 1 1 0 0 1 0 12303.82 12313.44 12303.83\n27 1 0 0 0 1 1 12084.41 12098.85 12084.43\n28 1 1 0 0 1 1 12303.82 12313.44 12303.83\n29 1 0 0 1 1 0 12084.41 12098.85 12084.43\n30 1 1 0 1 1 0 12303.82 12313.44 12303.83\n31 1 0 0 1 1 1 12084.41 12098.85 12084.43\n32 1 0 0 2 1 0 12084.41 12098.85 12084.43\n33 1 0 1 0 1 0 12084.67 12103.93 12084.72\n34 1 1 1 0 1 0 12067.11 12081.55 12067.14\n35 1 0 1 0 1 1 12084.67 12103.93 12084.72\n36 1 0 1 1 1 0 12084.67 12103.93 12084.72\n37 1 0 2 0 1 0 12077.36 12101.43 12077.43\n38 2 0 0 0 1 0 12085.17 12104.42 12085.21\n39 2 1 0 0 1 0 12240.65 12255.09 12240.67\n40 2 0 0 0 1 1 12085.17 12104.42 12085.21\n41 2 0 0 1 1 0 12085.17 12104.42 12085.21\n42 2 0 1 0 1 0 12074.21 12098.29 12074.28\n43 3 0 0 0 1 0 12085.39 12109.46 12085.45\n```\n:::\n\n```{.r .cell-code}\nSARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=seasonDiff) %>% filter(!is.na(p))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   p d q P D Q      AIC      BIC     AICc\n1  0 0 0 0 1 0 7590.941 7599.546 7590.963\n2  0 1 0 0 1 0 7681.255 7685.556 7681.263\n3  0 0 0 0 1 1 7590.941 7599.546 7590.963\n4  0 1 0 0 1 1 7681.255 7685.556 7681.263\n5  0 0 0 1 1 0 7590.941 7599.546 7590.963\n6  0 1 0 1 1 0 7681.255 7685.556 7681.263\n7  0 0 0 1 1 1 7590.941 7599.546 7590.963\n8  0 1 0 1 1 1 7681.255 7685.556 7681.263\n9  0 0 0 2 1 0 7590.941 7599.546 7590.963\n10 0 1 0 2 1 0 7681.255 7685.556 7681.263\n11 0 0 0 2 1 1 7590.941 7599.546 7590.963\n12 0 0 1 0 1 0 7508.844 7521.752 7508.888\n13 0 1 1 0 1 0 7574.405 7583.007 7574.427\n14 0 0 1 0 1 1 7508.844 7521.752 7508.888\n15 0 1 1 0 1 1 7574.405 7583.007 7574.427\n16 0 0 1 1 1 0 7508.844 7521.752 7508.888\n17 0 1 1 1 1 0 7574.405 7583.007 7574.427\n18 0 0 1 1 1 1 7508.844 7521.752 7508.888\n19 0 0 1 2 1 0 7508.844 7521.752 7508.888\n20 0 0 2 0 1 0 7502.242 7519.453 7502.316\n21 0 1 2 0 1 0 7501.777 7514.680 7501.822\n22 0 0 2 0 1 1 7502.242 7519.453 7502.316\n23 0 0 2 1 1 0 7502.242 7519.453 7502.316\n24 0 0 3 0 1 0 7504.242 7525.755 7504.353\n25 1 0 0 0 1 0 7502.164 7515.072 7502.208\n26 1 1 0 0 1 0 7641.447 7650.048 7641.469\n27 1 0 0 0 1 1 7502.164 7515.072 7502.208\n28 1 1 0 0 1 1 7641.447 7650.048 7641.469\n29 1 0 0 1 1 0 7502.164 7515.072 7502.208\n30 1 1 0 1 1 0 7641.447 7650.048 7641.469\n31 1 0 0 1 1 1 7502.164 7515.072 7502.208\n32 1 0 0 2 1 0 7502.164 7515.072 7502.208\n33 1 0 1 0 1 0 7502.957 7520.168 7503.031\n34 1 1 1 0 1 0 7494.739 7507.642 7494.784\n35 1 0 1 0 1 1 7502.957 7520.168 7503.031\n36 1 0 1 1 1 0 7502.957 7520.168 7503.031\n37 1 0 2 0 1 0 7504.242 7525.755 7504.353\n38 2 0 0 0 1 0 7502.828 7520.038 7502.902\n39 2 1 0 0 1 0 7610.893 7623.795 7610.937\n40 2 0 0 0 1 1 7502.828 7520.038 7502.902\n41 2 0 0 1 1 0 7502.828 7520.038 7502.902\n42 2 0 1 0 1 0 7504.793 7526.306 7504.904\n43 3 0 0 0 1 0 7504.726 7526.239 7504.838\n```\n:::\n:::\n\n\nBased on the results of the function, the minimum AIC and BIC are for the model: (0,1,2)(0,1,0). If I run the SARIMA function on the 365 differenced data, then it returns (1,1,1,)(0,1,0) as the model with the lowest AIC. So I will compare these two models for the series, using diagnostics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- Arima(weather_merged$events,order=c(0,1,2),seasonal=c(0,1,0))\nmod2 <- Arima(weather_merged$events,order=c(1,1,1),seasonal=c(0,1,0))\n\ncheckresiduals(mod1 )\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tLjung-Box test\n\ndata:  Residuals from ARIMA(0,1,2)\nQ* = 8.0235, df = 8, p-value = 0.4312\n\nModel df: 2.   Total lags used: 10\n```\n:::\n:::\n\n\nThe residuals for model 1 (0,1,2)(0,1,0) show some clustering of volatility. In addition, they appear to be skewed to the right, as the right tail of the residual distribution is fatter than the left tail and has more outlying values. Finally, the ACF plot of the residuals looks good, with little visible correlation and no values crossing the significance line. In addition, the Ljung-Box test returns p=0.43, suggesting we can reject the idea that there is autocorrelation in the residuals.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckresiduals(mod2 )\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tLjung-Box test\n\ndata:  Residuals from ARIMA(1,1,1)\nQ* = 2.7198, df = 8, p-value = 0.9507\n\nModel df: 2.   Total lags used: 10\n```\n:::\n:::\n\n\nThe residual diagnostics for model 2 (1,1,1)(0,1,0) are similar to model 1, except that they have even less correlatoin visible in the residual plots. The residual's distribution is still skewed to the right, with a fatter positive tail. The ACF plot, however, has even less correlation visible, with only two values even coming marginally close to the significance line. There is still some heteroskedacticity in the plot over time, however, suggesting clustering of volatility.\n\n\nNow, let's use an Auto.Arima function to determine the correct model:\n\n::: {.cell}\n\n```{.r .cell-code}\naaData <- ts(weather_merged$events)\nmod3 <- auto.arima(aaData, seasonal = TRUE, trace = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Fitting models using approximations to speed things up...\n\n ARIMA(2,0,2) with non-zero mean : 12069.53\n ARIMA(0,0,0) with non-zero mean : 12204.32\n ARIMA(1,0,0) with non-zero mean : 12079.82\n ARIMA(0,0,1) with non-zero mean : 12102.76\n ARIMA(0,0,0) with zero mean     : 12785.96\n ARIMA(1,0,2) with non-zero mean : 12082.52\n ARIMA(2,0,1) with non-zero mean : 12069.52\n ARIMA(1,0,1) with non-zero mean : 12081.01\n ARIMA(2,0,0) with non-zero mean : 12079.36\n ARIMA(3,0,1) with non-zero mean : 12069.61\n ARIMA(3,0,0) with non-zero mean : 12080.39\n ARIMA(3,0,2) with non-zero mean : 12072.31\n ARIMA(2,0,1) with zero mean     : Inf\n\n Now re-fitting the best model(s) without approximations...\n\n ARIMA(2,0,1) with non-zero mean : 12074.28\n\n Best model: ARIMA(2,0,1) with non-zero mean \n```\n:::\n:::\n\n\nRegardless of the frequency fed into the model, Auto.arima only wants to fit a (2,0,1) ARIMA model. I tried 365, 90, 60, 40, 14, and 7 day frequencies, and in each case the seasonal term was not chosen for the data. I think the reason that it doesn't recognize the seasonality is because it doesn't worok with 365, which should be the best frequency for the data. \n\n\nForecast with a confidence band: Model 1 (0,1,2)(0,1,0)\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(forecast(mod2), xlim = c(850,925))\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nModel 2: (1,1,1)(0,1,0)\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(forecast(mod1), xlim = c(850,925))\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nI think the forecasts are interesting, because model 2 has a more dynamic forecast, with a decrease over several days before leveling out its prediction. Model 1, meanwhile, predicts that the series will hardly change after its first prediction. While the series does not have a lot of trend going into the prediction interval, weather events are dynamic and I would tend to believe the model which includes more variation as opposed to constant numbers of events. Hence, I would select the (1,1,1)(0,1,0) SARIMA model.\n\nBenchmark Comparison\n\nWe will use two benchmark methods: A seasonal naive forecast and a mean forecast.\n\n::: {.cell}\n\n```{.r .cell-code}\nbase1 <- snaive(aaData, 10)\nbase2 <- meanf(aaData, 10)\n\nplot(base1, xlim = c(850,925))\n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nHere we can see the plot for the seasonal naive model's forecasts (10 days out), which show a predicted value close to the last observed value in the series. It has a high degree of uncertainty as shown by the prediction interval, which is quite wide.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(base2, xlim = c(850,925) ) \n```\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nThe forecast for the meanf model (above) departs further from the previously observed values, as the mean of the series is substantially below recently observed values. However, the model has a smaller prediction interval than the seasonal naive forecast, which is a slight advantage.\n\nNow let's look at the accuracy of the three forcasts:\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(snaive(aaData))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                    ME     RMSE      MAE       MPE    MAPE MASE       ACF1\nTraining set -0.232967 222.2549 134.6615 -92.97186 141.104    1 -0.3466138\n```\n:::\n\n```{.r .cell-code}\naccuracy(meanf(aaData))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                       ME     RMSE      MAE       MPE     MAPE     MASE\nTraining set 4.269057e-15 195.8141 137.4244 -231.3227 259.5254 1.020517\n                  ACF1\nTraining set 0.3527022\n```\n:::\n\n```{.r .cell-code}\naccuracy(mod2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 1.865123 182.4393 120.2761 -152.6725 179.3078 0.8931731\n                    ACF1\nTraining set 0.006055532\n```\n:::\n:::\n\n\nThe accuracy statistics were a mixed result between the seasonal naive forecast and the SARIMA(1,1,1)(0,1,0) model. The mean forecast did not perform better on any metric than the other two models, and could be discarded. On Root Mean Squared Error, the SARIMA model beat the Seasonal Naive model with a value of 182.4 vs. 222.3, respectively. On Mean Absolute Error, the SARIMA model also performed better, with 120.3 compared to the Seasonal Naive model's 134.7. On the Mean Absolute Percentage Error, however, the Seasonal Naive model performed better than the SARIMA model, achieving 141.1 vs. 179.3 for the SARIMA model. \n\nOverall, it seems like the accuracy metrics might favor the seasonal naive model, while the prediction forecasts look more accurate for the SARIMA model.\n\nCross Validation:\nLet's do a seasonal cross-validation with 1 and 10-step-ahead forecasts. \n\n::: {.cell}\n\n```{.r .cell-code}\n    # I add a 100 day buffer to my period of 365 days to have enough data\n    test <- 100 \n    trainnum <- length(aaData) - test\n    rmse1 <- vector(mode = 'numeric', length = 100)\n    rmse2 <- vector(mode = 'numeric', length = 100)\n    rmse361 <- vector(mode = 'numeric', length = 100)\n    rmse362 <- vector(mode = 'numeric', length = 100)\n\n    for(i in 1:100) {\n\n        \n        xtrain <- aaData[c(1:(trainnum + i - 1))]\n        xtest <-  aaData[c((trainnum + i +1):(trainnum+i+10))]\n        \n    \n        ######## model ###########\n        fit2 <- arima(xtrain, order = c(1,1,1), seasonal = list(order = c(0,1,0)))\n        fcast2 <- predict(fit2, n.ahead = 10)$pred\n        \n        # Errors\n\n        rmse2[i]  <-sqrt((fcast2[1]-xtest[1])^2)\n        rmse362[i]  <- mean( sqrt((fcast2 -xtest)^2) )\n        \n    }\n    \n# create index\nindex <- c(1:100)\nggplot() +\n    geom_line(aes(x = index, y = rmse2), color = 'blue' ) + \n    geom_line(aes(x = index, y = rmse362), color = 'red')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 row containing missing values (`geom_line()`).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 10 rows containing missing values (`geom_line()`).\n```\n:::\n\n::: {.cell-output-display}\n![](ARMA-ARIMA-SARIMA-Models_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nThe chart above shows the RMSE for the cross validated forecasts with windows 1 and 10. I had to use 10 for my seasonal window as my computer was unable to handle the 365 window, and could not produce results. But my data also had short-term seasonality so I relied upon that here. The red line represents the 10-step ahead forecast average RMSE and the blue line represents the 1-step ahead forecast RMSE. Overall you can see that both forecasts perform better and worse around the same time, except that the short-term forecast has a lagged reaction to the same periods where the long-term forecast performed poorly. In some cases, however, the 1-step RMSE does exceed the 10-step RMSE, suggesting poor short term performance.\n\n\n\n\n",
    "supporting": [
      "ARMA-ARIMA-SARIMA-Models_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}