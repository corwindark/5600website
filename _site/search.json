[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Time Series",
    "section": "",
    "text": "What is a Time Series ?\n\nAny metric that is measured over regular time intervals makes a Time Series. A time series is a sequence of data points or observations collected or recorded over a period of time at specific, equally spaced intervals. Each data point in a time series is associated with a particular timestamp or time period, making it possible to analyze and study how a particular variable or phenomenon changes over time. Time series data can be found in various domains and can represent a wide range of phenomena, including financial data, economic indicators, weather measurements, stock prices, sales figures, and more.\n\nExample: Weather data, Stock prices, Industry forecasts, etc are some of the common ones.\n\nThe analysis of experimental data that have been observed at different points in time leads to new and unique problems in statistical modeling and inference.\nThe obvious correlation introduced by the sampling of adjacent points in time can severely restrict the applicability of the many conventional statistical methods traditionally dependent on the assumption that these adjacent observations are independent and identically distributed.\n\nKey characteristics of time series data include:\nTemporal Order: Time series data is ordered chronologically, with each data point representing an observation at a specific point in time. The order of data points is critical for understanding trends and patterns over time.\nEqually Spaced Intervals: In most cases, time series data is collected at regular intervals, such as hourly, daily, weekly, monthly, or yearly. However, irregularly spaced time series data can also exist.\nDependency: Time series data often exhibits temporal dependency, meaning that the value at a given time is influenced by or related to the values at previous times. This dependency can take various forms, including trends, seasonality. This serial correlation is called as autocorrelation.\nComponents: Time series data can typically be decomposed into various components, including:\nTrend: The long-term movement or direction in the data. Seasonality: Repeating patterns or cycles that occur at fixed intervals. Noise/Irregularity: Random fluctuations or variability in the data that cannot be attributed to the trend or seasonality.\nApplications: Time series data is widely used for various applications, including forecasting future values, identifying patterns and anomalies, understanding underlying trends, and making informed decisions based on historical data.\nAnalyzing time series data involves techniques like time series decomposition, smoothing, statistical modeling, and forecasting. This class will cover but not be limited to traditional time series modeling including ARIMA, SARIMA, the multivariate Time Series modeling including; ARIMAX, SARIMAX, and VAR models, Financial Time Series modeling including; ARCH, GARCH models, and E-GARCH, M-GARCH..ect, Bayesian structural time series (BSTS) models, Spectral Analysis and Deep Learning Techniques for Time Series. Researchers and analysts use software tools like Python, R, and specialized time series libraries to work with and analyze time series data effectively.\nTime series analysis is essential in fields such as finance, economics, epidemiology, environmental science, engineering, and many others, as it provides insights into how variables change over time and allows for the development of predictive models to forecast future trends and outcomes."
  },
  {
    "objectID": "Exploratory Data Analysis.html",
    "href": "Exploratory Data Analysis.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Time Series Analysis\n\nLet’s start with the intraday range data. First with the S&P 500.\n\nlibrary(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.2.1     v dplyr   1.1.2\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(quantmod)\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\n######################### Warning from 'xts' package ##########################\n#                                                                             #\n# The dplyr lag() function breaks how base R's lag() function is supposed to  #\n# work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n# source() into this session won't work correctly.                            #\n#                                                                             #\n# Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n# conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n# dplyr from breaking base R's lag() function.                                #\n#                                                                             #\n# Code in packages is not affected. It's protected by R's namespace mechanism #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n###############################################################################\n\n\n\nAttaching package: 'xts'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nLoading required package: TTR\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nspyIn &lt;- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn &lt;- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn &lt;- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\n\nspyIn$spyRange &lt;- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange &lt;- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange &lt;- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n\n\n#decomposedSPY &lt;- decompose(spyIn$spyRange)\n\n##decompedSPY = HoltWinters(spyIn$spyRange,beta = FALSE,gamma = FALSE)\n#plot(decompedSPY)\n\nautoplot(spyIn$spyRange)\n\n\n\nacf(spyIn$spyRange)\n\n\n\npacf(spyIn$spyRange)\n\n\n\n\nUpon initial review of the SPY intraday range data, it appears that there is some trend, but no seasonality. The decomposition function would not work on the data as it could not recognize periodicity. As a next step, we can difference the data.\n\nlibrary(forecast)\n\n\ndiff1 &lt;- diff(spyIn$spyRange)\n#auto.arima(spyIn$spyRange)\nplot(diff1)\n\n\n\n\nAfter differencing, the data appears to have lost its trend. However, there is still visible heteroskedacticity in the differences between intraday ranges.\n\nacf(diff1,    na.action = na.exclude)\n\n\n\npacf(diff1,    na.action = na.exclude)\n\n\n\n\nAfter differencing, we see 2 lags being significant in the ACF plot. In the PACF plot, we see about 4 lags being significant. This is a marked departure from the original plots, where the ACF showed clear non-stationarity and the PACF had many significant lags.\n\nlibrary(tseries)\n\ndiffnoNA &lt;- diff1$spyRange[!is.na(diff1$spyRange)]\nadf.test(diffnoNA)\n\nWarning in adf.test(diffnoNA): p-value smaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diffnoNA\nDickey-Fuller = -12.455, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n\nWith dickey fuller test result of 0.01, we can reject the null hypothesis and conclude the series is stationary."
  },
  {
    "objectID": "Data Sources.html",
    "href": "Data Sources.html",
    "title": "Data Sources",
    "section": "",
    "text": "S&P 500 Data, Yahoo Finance\n\nhttps://finance.yahoo.com/quote/%5EGSPC/history?p=%255EGSPC\n\nDJIA Data, Yahoo Finance\n\nhttps://finance.yahoo.com/quote/%5EDJI/history?p=%255EDJI\nFinancial data from the S&P 500 and the Dow Jones Industrial Average. Data includes the open and close of stock prices for each day, as well as the highest and lowest price recorded for the day. These indices are widely used and will be a relevant outcome variable for the project to study.\n\nVIX Data, Yahoo Finance\n\nhttps://finance.yahoo.com/quote/%5EVIX/history?p=%255EVIX\nThe Chicago Board of Exchange (CBOE) VIX index is a widely-used tool to measure investor sentiment. The indicator itself represents the degree of volatility perceived by investors in the next month. It ranges from near zero up to about 60 in recent years, with scores at different intervals representing different levels of perceived volatility.\n\nTropical Storm and Hurricane Warning Reports, NOAA\n\nhttps://www.nhc.noaa.gov/TCR_StormReportsIndex.xml\nNOAA maintains records on each hurricane and tropical storm warning they send out for both the Atlantic and the Pacific. While a wealth of data, including GIS data, is available on NOAA’s website, not all of it is machine readable. As such, I chose the data linked above, which is an XML file that contains the names and dates of every hurricane and tropical storm in the Atlantic and Pacific since 1994.\n\nWildfire Data, Independent Researchers\n\nhttps://www.sciencebase.gov/catalog/item/61707c2ad34ea36449a6b066\nThis dataset was gathered meticulously and over several iterations to include all wildfires in the United States from the 1800s to present. It includes many types of data about each wildfire, such as the cause and start date, as well as polygons of the area burned.\n\nFederal Funds Effective Rate, FRED\n\nhttps://fred.stlouisfed.org/series/FEDFUNDS\nThe federal funds effective rate, provided here by FRED of the St. Louis Fed, measures the effective rate that financial institutions are paying to eachother overnight. The federal funds rate depends on the target federal funds rate, which is set as a matter of monetary policy, and which is used as the basis for government intervention to raise or lower the effective rate until it matches the target rate.\n\nAll Non-Farm Employee Payrolls, FRED\n\nhttps://fred.stlouisfed.org/series/PAYEMS\nThis data measures formal employment in the US economy. The non-farm distinction is a common one to make with payrolls, as farms employ a great deal of seasonal labor. Such metrics are closely watched by investors, which is what makes them interesting, as the monthly release of numbers has a clear and immediate impact on stock market prices. Numbers are sometimes revised later, after their initial release."
  },
  {
    "objectID": "about me.html",
    "href": "about me.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Data Visualization.html",
    "href": "Data Visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "The central question of this research project is about stock market volatility. As such the following visualizations will explore this subject in different areas. To start with, let’s define the outcome variables in question:\nFor each security: S&P 500, QQQ Pro-Shares ETF, and Russell 200 index, we have several metrics 1. Price 2. Standard deviation (10 day window) 3. True range (intraday difference between highest and lowest price/previous closing value) 4. Trading volume\nThe window of our investigation is January 1st 2021 - September 30th 2023.\n\nlibrary(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.2.1     v dplyr   1.1.2\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(quantmod)\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\n######################### Warning from 'xts' package ##########################\n#                                                                             #\n# The dplyr lag() function breaks how base R's lag() function is supposed to  #\n# work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n# source() into this session won't work correctly.                            #\n#                                                                             #\n# Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n# conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n# dplyr from breaking base R's lag() function.                                #\n#                                                                             #\n# Code in packages is not affected. It's protected by R's namespace mechanism #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n###############################################################################\n\n\n\nAttaching package: 'xts'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nLoading required package: TTR\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nspyIn &lt;- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn &lt;- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn &lt;- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\nhead(spyIn)\n\n           SPY.Open SPY.High SPY.Low SPY.Close SPY.Volume SPY.Adjusted\n2021-01-04   375.31   375.45  364.82    368.79  110210800     354.1974\n2021-01-05   368.10   372.50  368.05    371.33   66426200     356.6369\n2021-01-06   369.71   376.98  369.12    373.55  107997700     358.7691\n2021-01-07   376.10   379.90  375.91    379.10   68766800     364.0995\n2021-01-08   380.59   381.49  377.10    381.26   71677200     366.1740\n2021-01-11   377.85   380.58  377.72    378.69   51034700     363.7057\n\nhead(qqqIn)\n\n           QQQ.Open QQQ.High QQQ.Low QQQ.Close QQQ.Volume QQQ.Adjusted\n2021-01-04   315.11   315.29  305.18    309.31   45305900     304.2444\n2021-01-05   308.29   312.14  308.29    311.86   29323400     306.7526\n2021-01-06   307.00   311.88  305.98    307.54   52809600     302.5034\n2021-01-07   310.28   315.84  310.25    314.98   30394800     309.8215\n2021-01-08   317.34   319.39  315.08    319.03   33955800     313.8051\n2021-01-11   315.98   317.19  313.75    314.42   32746400     309.2707\n\nhead(iwmIn)\n\n           IWM.Open IWM.High IWM.Low IWM.Close IWM.Volume IWM.Adjusted\n2021-01-04   197.54   197.89  190.94    193.50   33664200     186.8583\n2021-01-05   193.09   197.62  193.07    196.49   27442900     189.7456\n2021-01-06   199.48   206.78  199.16    204.53   52952200     197.5097\n2021-01-07   205.71   208.52  205.70    208.17   24031400     201.0247\n2021-01-08   209.32   209.77  204.66    207.72   29017000     200.5902\n2021-01-11   205.09   208.12  204.83    207.54   20945100     200.4164\n\n\nLet’s start by simply seeing the absolute prices of these securities over time:\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\ncombinedCloses &lt;- cbind(spyIn$SPY.Close, qqqIn$QQQ.Close, iwmIn$IWM.Close)\n\n\nts.plot(combinedCloses, gpars = list(col = rainbow(3)))\n\nlegend(\"topleft\", legend = c(\"SPY\", \"QQQ\", \"IWM\"), col = 1:3, lty = 1)\n\n\n\n\nIn these charts, we can see that the overall trend for all three securities has been somewhat of a decline since the start of the time window. We can also see that QQQ and IWM have moved further in their trends than SPY, which makes sense as that is the most stable index of the three.\nNow, let us look at the intraday range volatility measure.\n\nspyIn$spyRange &lt;- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange &lt;- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange &lt;- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n\ncombinedIntradayPercentRange &lt;- cbind(spyIn$spyRange, qqqIn$qqqRange, iwmIn$iwmRange)\n\nhead(qqqIn$pctRange)\n\nNULL\n\nts.plot(combinedIntradayPercentRange, gpars = list(col = rainbow(3)))\n\nlegend(\"topleft\", legend = c(\"SPY\", \"QQQ\", \"IWM\"), col = 1:3, lty = 1)\n\ntitle(\"Daily High-Low Range as Percent of Open Price\")\n\n\n\n\nIn this chart, we can see that the three indices tended to move together, with the midpoint of the time window having a higher average range in daily prices than the beginning or end for all of the securities. However, we can also see again that volatility is not even between them, with SPY and IWM having higher daily ranges than QQQ on average (at least according to the naked eye).\nNow, let’s review the trends in the federal funds rate:\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\ndff &lt;- read.csv(\"./dff.csv\")\n\ndff &lt;- dff %&gt;%\n    mutate(DATE = ymd(DATE)) %&gt;%\n    filter(DATE &gt;= ymd(\"2021-01-01\"))\n\nplot3 &lt;- ggplot(dff, aes(x = DATE, y = DFF)) + geom_line() + labs(y = \"Daily Federal Fund Rate\", x = \"Time\", title = \"Daily Federal Funds Rate over Time\")\nggplotly(plot3)"
  },
  {
    "objectID": "dv.html",
    "href": "dv.html",
    "title": "Data Vizes in TS",
    "section": "",
    "text": "-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.2.1     v dplyr   1.1.2\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\n######################### Warning from 'xts' package ##########################\n#                                                                             #\n# The dplyr lag() function breaks how base R's lag() function is supposed to  #\n# work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n# source() into this session won't work correctly.                            #\n#                                                                             #\n# Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n# conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n# dplyr from breaking base R's lag() function.                                #\n#                                                                             #\n# Code in packages is not affected. It's protected by R's namespace mechanism #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n###############################################################################\n\n\n\nAttaching package: 'xts'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nLoading required package: TTR\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\n\n\n\n\nThis chart shows the extreme volatility of Moderna’s stock price compared to its peers. The stock has gone from the cheapest of the 5 per share, to the most expensive by a factor of 2, back down to the 2nd most expensive, in the 3-year window visible. Meanwhile, the other 4 stocks have followed a roughly slow and steady upward trend, with Abbivie and Amgen having the greatest progression during the time period.\n\n\n\n\n\n\nHere, we see a steep downward trend in BTC price before Winter 2022, however BTC price has recovered from the low and roughly stabalized after that inflection point.\n\n\n\n\n\n\nThe candlestick chart shows how volatile bitcoins price can be in each day of the window studied. The candlesticks show wide intraday ranges in price.\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\n      STATION                      NAME       DATE DAPR MDPR PRCP SNOW SNWD\n1 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-06   NA   NA    0    0   NA\n2 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-07   NA   NA    0    0   NA\n3 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-08   NA   NA    0    0   NA\n4 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-09   NA   NA    0    0   NA\n5 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-10   NA   NA    0    0   NA\n6 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-11   NA   NA    0    0   NA\n  TMAX TMIN TOBS WESD\n1   NA   NA   NA   NA\n2   NA   NA   NA   NA\n3   NA   NA   NA   NA\n4   NA   NA   NA   NA\n5   NA   NA   NA   NA\n6   NA   NA   NA   NA\n\n\nWarning: Removed 69 rows containing missing values (position_stack).\n\n\n\n\n\n\nthis chart shows the total precipitation recorded at 7 stations by month of the year. We can see the USC00182325 has a substantially higher total precipitation amount in August and September than all the other months. It is dubious, however, that the same station records no precipitation from October to December, and it leads me to wonder about whether the data is faulty. Secondly, we can see August has the highest total amount of precipitation recorded in the dataset.\n\n\n\n\n\n\nHere, we can see the CPI index has increased steadily since the 1940s, with a slower period of increase between 1960 and 1970, and a higher period of increase between 1970 and 1980, followed by a marked jump after 2020."
  },
  {
    "objectID": "Introduction.html",
    "href": "Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "For this project the time series I will be studying are major stock market indices, specifically the DJIA and S&P 500. The purpose of this project is to understand the factors driving the price of these indices, looking at climate events such as wildfires and hurricanes, investor confidence, and the impacts of COVID-19. I will use the statistical models we learn in class to investigate the relationships of these factors on stock market prices."
  },
  {
    "objectID": "Introduction.html#topic-explanation",
    "href": "Introduction.html#topic-explanation",
    "title": "Introduction",
    "section": "",
    "text": "For this project the time series I will be studying are major stock market indices, specifically the DJIA and S&P 500. The purpose of this project is to understand the factors driving the price of these indices, looking at climate events such as wildfires and hurricanes, investor confidence, and the impacts of COVID-19. I will use the statistical models we learn in class to investigate the relationships of these factors on stock market prices."
  },
  {
    "objectID": "Introduction.html#the-big-picture",
    "href": "Introduction.html#the-big-picture",
    "title": "Introduction",
    "section": "The Big Picture:",
    "text": "The Big Picture:\nFinancial markets are directly important to the well-being of everyday Americans. While the stock market is often seen as exclusive to a small circle of elite investors, in reality millions of Americans have exposure to the markets through retirement funds, which are made up of many different kinds of investments. If we can become better at predicting the course of financial markets, particularly in relation to external forces like climate change, it could promise to reduce volatility and inefficiency in the market. In turn, this would help everyday people build up their savings to enjoy a better quality of life, retire sooner, or have more security.\nFurther, understanding the movements of financial markets is important in controlling sentiment. In cases like the onset of the COVID-19 pandemic, stock market crashes could snowball into businesses cutting more jobs than needed, which would again directly impact everyday peoples’ livelihoods. With the hope of understanding these phenomena better, this project will look directly at investor sentiment and the impact of COVID-19.\n\n\n\nBig Picture"
  },
  {
    "objectID": "Introduction.html#analytical-angles",
    "href": "Introduction.html#analytical-angles",
    "title": "Introduction",
    "section": "Analytical Angles:",
    "text": "Analytical Angles:\nFirst, looking at stock prices as individual univariate time series. Conceptually, we are studying any intrinsic characteristics or patterns that publicly-traded stocks might have. This focuses on the properties of stocks themselves, and not how they react to external stimuli. Second, understanding stock prices as objects which are reflective of individuals actions and preferences. In this case, the individuals in question are investors, and we will look at investor sentiment and see how it might affect prices in financial markets. Third, viewing changes in stock prices in the context of external stimuli. From this analytical perspective, the stock market is a closed system, which is disrupted by external forces from time-to-time that cause unexpected behaviour. Studying the impact of climate events and economic data releasing will pertain to this point. Fourth, using stocks at output variables, which are a tool to investigate the impact of serious events like COVID-19. In this case, we are interested in looking at how the onset of COVID rippled through the stock market, and what we could learn from stock prices to help ameliorate similar disasters in the future."
  },
  {
    "objectID": "Introduction.html#literature-review",
    "href": "Introduction.html#literature-review",
    "title": "Introduction",
    "section": "Literature Review:",
    "text": "Literature Review:\nMany of the factors this project seeks to investigate have previously been reviewed by academics. For instance, the consequence of investor sentiment on the stock market has been widely studied, in terms of how it impacts stock market crises (Zouaoui, Nouyrigat, and Beer 2011), trading volume (So and Lei 2015), and especially returns (Smales 2017). Further, authors have previously found an impact of climate events, such as hurricanes (Liu, Ferreira, and Karali 2021) on stock prices of particular companies. The fact that these issues have been studied previously is encouraging, because in each case the authors chose a specific group of time and company limited stock market data. This project might extend their results to other stock market datasets, and might hope to incorporate these relationships into new statistical models"
  },
  {
    "objectID": "Introduction.html#guiding-questions",
    "href": "Introduction.html#guiding-questions",
    "title": "Introduction",
    "section": "Guiding Questions:",
    "text": "Guiding Questions:\n\nHow do markets react in anticipation of the release of macroeconomic data?\nHow do markets react when their predictions about macroeconomic data are more or less accurate?\nHow does investor confidence impact markets?\nCan time series data from financial markets tell us anything about future levels of investor confidence?\nHow does the stock market react to the increasing prevalence of climate events such as hurricanes, wildfires?\nWhich securities are most impacted by climate events?\nHow has COVID changed stock prices in the months and years after the onset of the pandemic?\nCan we predict the impact of future black swan events on the stock market by looking at COVID’s example?\nHow do the prices of different securities impact eachother?\nHow have the relationships between the prices of securities changed over time?"
  }
]