[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Time Series",
    "section": "",
    "text": "What is a Time Series ?\n\nAny metric that is measured over regular time intervals makes a Time Series. A time series is a sequence of data points or observations collected or recorded over a period of time at specific, equally spaced intervals. Each data point in a time series is associated with a particular timestamp or time period, making it possible to analyze and study how a particular variable or phenomenon changes over time. Time series data can be found in various domains and can represent a wide range of phenomena, including financial data, economic indicators, weather measurements, stock prices, sales figures, and more.\n\nExample: Weather data, Stock prices, Industry forecasts, etc are some of the common ones.\n\nThe analysis of experimental data that have been observed at different points in time leads to new and unique problems in statistical modeling and inference.\nThe obvious correlation introduced by the sampling of adjacent points in time can severely restrict the applicability of the many conventional statistical methods traditionally dependent on the assumption that these adjacent observations are independent and identically distributed.\n\nKey characteristics of time series data include:\nTemporal Order: Time series data is ordered chronologically, with each data point representing an observation at a specific point in time. The order of data points is critical for understanding trends and patterns over time.\nEqually Spaced Intervals: In most cases, time series data is collected at regular intervals, such as hourly, daily, weekly, monthly, or yearly. However, irregularly spaced time series data can also exist.\nDependency: Time series data often exhibits temporal dependency, meaning that the value at a given time is influenced by or related to the values at previous times. This dependency can take various forms, including trends, seasonality. This serial correlation is called as autocorrelation.\nComponents: Time series data can typically be decomposed into various components, including:\nTrend: The long-term movement or direction in the data. Seasonality: Repeating patterns or cycles that occur at fixed intervals. Noise/Irregularity: Random fluctuations or variability in the data that cannot be attributed to the trend or seasonality.\nApplications: Time series data is widely used for various applications, including forecasting future values, identifying patterns and anomalies, understanding underlying trends, and making informed decisions based on historical data.\nAnalyzing time series data involves techniques like time series decomposition, smoothing, statistical modeling, and forecasting. This class will cover but not be limited to traditional time series modeling including ARIMA, SARIMA, the multivariate Time Series modeling including; ARIMAX, SARIMAX, and VAR models, Financial Time Series modeling including; ARCH, GARCH models, and E-GARCH, M-GARCH..ect, Bayesian structural time series (BSTS) models, Spectral Analysis and Deep Learning Techniques for Time Series. Researchers and analysts use software tools like Python, R, and specialized time series libraries to work with and analyze time series data effectively.\nTime series analysis is essential in fields such as finance, economics, epidemiology, environmental science, engineering, and many others, as it provides insights into how variables change over time and allows for the development of predictive models to forecast future trends and outcomes."
  },
  {
    "objectID": "Exploratory Data Analysis.html",
    "href": "Exploratory Data Analysis.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Time Series Analysis\n\nLet’s start with reading in the intraday range data. First with the S&P 500.\n\nlibrary(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.2.1     v dplyr   1.1.2\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(quantmod)\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\n######################### Warning from 'xts' package ##########################\n#                                                                             #\n# The dplyr lag() function breaks how base R's lag() function is supposed to  #\n# work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n# source() into this session won't work correctly.                            #\n#                                                                             #\n# Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n# conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n# dplyr from breaking base R's lag() function.                                #\n#                                                                             #\n# Code in packages is not affected. It's protected by R's namespace mechanism #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n###############################################################################\n\n\n\nAttaching package: 'xts'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nLoading required package: TTR\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nspyIn &lt;- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn &lt;- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn &lt;- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\n\nspyIn$spyRange &lt;- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange &lt;- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange &lt;- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n\n\n#decomposedSPY &lt;- decompose(spyIn$spyRange)\n\n##decompedSPY = HoltWinters(spyIn$spyRange,beta = FALSE,gamma = FALSE)\n#plot(decompedSPY)\n\nautoplot(spyIn$spyRange)\n\n\n\nacf(spyIn$spyRange)\n\n\n\npacf(spyIn$spyRange)\n\n\n\n\nUpon initial review of the SPY intraday range data, it appears that there is some trend, but no seasonality. The decomposition function would not work on the data as it could not recognize periodicity. As a next step, we can difference the data.\n\nlibrary(forecast)\n\n\ndiff1 &lt;- diff(spyIn$spyRange)\n\n\n\n#write.csv(diff1SPY, \"/data/spyDiff.csv\")\n#auto.arima(spyIn$spyRange)\nplot(diff1)\n\n\n\n\nAfter differencing, the data appears to have lost its trend. However, there is still visible heteroskedacticity in the differences between intraday ranges.\n\nacf(diff1,    na.action = na.exclude)\n\n\n\npacf(diff1,    na.action = na.exclude)\n\n\n\n\nAfter differencing, we see 2 lags being significant in the ACF plot. In the PACF plot, we see about 4 lags being significant. This is a marked departure from the original plots, where the ACF showed clear non-stationarity and the PACF had many significant lags.\n\nlibrary(tseries)\n\ndiffnoNA &lt;- diff1$spyRange[!is.na(diff1$spyRange)]\nadf.test(diffnoNA)\n\nWarning in adf.test(diffnoNA): p-value smaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diffnoNA\nDickey-Fuller = -12.455, Lag order = 8, p-value = 0.01\nalternative hypothesis: stationary\n\n#\n\nWith dickey fuller test result of 0.01, we can reject the null hypothesis and conclude the series is stationary.\n\nMoving Average Smoothing\n\n\nspyDiff1 &lt;- as.ts(diffnoNA)\n\nspyAvg3Diff1 &lt;- stats::filter(spyDiff1, sides = 1, rep(1/3, 3))\nspyAvg5Diff1 &lt;- stats::filter(spyDiff1, sides = 1, rep(1/5, 5))\nspyAvg30Diff1 &lt;- stats::filter(spyDiff1, sides = 1, rep(1/30, 30))\nspyAvg50Diff1 &lt;- stats::filter(spyDiff1, sides = 1, rep(1/50, 50))\n\nspyAvg100Diff1 &lt;- stats::filter(spyDiff1, sides = 1, rep(1/100, 100))\n\n\nautoplot(spyAvg3Diff1)\n\n\n\nautoplot(spyAvg5Diff1)\n\n\n\nautoplot(spyAvg30Diff1)\n\n\n\nautoplot(spyAvg50Diff1)\n\n\n\nautoplot(spyAvg100Diff1)\n\n\n\n\nOverall the effect of the moving average at higher numbers is to reveal seasonality in the data. At lower smoothing levels (3 and 5 days), the time series looked almost unchanged, and still highly variant. Only at a 30 day average window did the seasonality start to appear, with clear periods in the data and a repeating pattern. Notably, even with a repeating pattern the data still showed obvious heteroskedasticity, with periods of increased varianced. The 50 and 100 day moving average windows began to obfuscate the periods, while keeping the heteroskedacticity, although they did have smaller variations and were nearer to 0 on average. In adition, the 50 and 100 days had discernable trends in the data."
  },
  {
    "objectID": "Data Sources.html",
    "href": "Data Sources.html",
    "title": "Data Sources",
    "section": "",
    "text": "S&P 500, Nasdaq 100, and Russel 2000, Daily Data Yahoo Finance\n\nhttps://finance.yahoo.com/quote/%5EGSPC/history?p=%255EGSPC\nFinancial data from tickers SPY, QQQ, and IWM. Data includes the open and close of stock prices for each day, as well as the highest and lowest price recorded for the day. These indices are widely used and will be a relevant outcome variable for the project to study. The main output value thaht will be calculated is the high-low range of the day.\n\nVIX Data, Yahoo Finance\n\nhttps://finance.yahoo.com/quote/%5EVIX/history?p=%255EVIX\nThe Chicago Board of Exchange (CBOE) VIX index is a widely-used tool to measure investor sentiment. The indicator itself represents the degree of volatility perceived by investors in the next month. It ranges from near zero up to about 60 in recent years, with scores at different intervals representing different levels of perceived volatility.\n\nWork Stoppages\n\nhttps://www.bls.gov/wsp/\nThis dataset contains all of the major strikes recorded by the bureau of labor statistics, such that I will be able to use the number of striking workers on any given day as a variable for analysis.\n\nDaily Yield Curve Next 3 Months\n\nhttps://home.treasury.gov/resource-center/data-chart-center/interest-rates/TextView?type=daily_treasury_yield_curve&field_tdr_date_value=2023\nWhile I originally considered the actual federal funds rate, the values did not change much day to day. Instead I would like to use the expectation of yield rates, measured through the pricing of bonds in the yield curve over the next few months. The data includes the prices of treasury bills 1, 2, and 3 months out on each date.\n\nStorm Events by Day\n\nhttps://www.ncdc.noaa.gov/stormevents/ftp.jsp\nNOAA maintains records on each storm warning they send out for the entire country. This dataset includes many types of storm warnings, such as for hurricanes, blizzards, flash floods, and tornadoes. Importantly, the dataset includes the day in which each weather event took place, as well as the property damage and bodily injury caused by the weather event."
  },
  {
    "objectID": "ARMA ARIMA SARIMA Models.html",
    "href": "ARMA ARIMA SARIMA Models.html",
    "title": "ARMA ARIMA SARIMA MODELS",
    "section": "",
    "text": "Loading packages\n\n\nCode\nlibrary(tidyverse)\nlibrary(quantmod)\nlibrary(forecast)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(lubridate)\n\n\nBringing the data into this tab as well:\n\n\nShow Code\nspyIn &lt;- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn &lt;- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn &lt;- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\n\nspyIn$spyRange &lt;- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange &lt;- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange &lt;- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n\n\ndiff1SPY &lt;- diff(spyIn$spyRange)\ndiff1QQQ &lt;- diff(qqqIn$qqqRange)\ndiff1IWM &lt;- diff(iwmIn$iwmRange)\n\n\n\nStationarity of the time series\n\nBased on previous results, and the fact that I am using “pseudo-differenced data” in that I am taking the percentage range in prices, in addition to a single differencing, means that the time series are stationary\n\nBuilding ARIMA Model\n\nSince I did some of this work with SPY data on the EDA tab, I will focus on QQQ range data here.\n\n\nCode\n#print(diff1QQQ)\nacf(diff1QQQ, na.action = na.exclude)\n\n\n\n\n\nCode\npacf(diff1QQQ, na.action = na.exclude)\n\n\n\n\n\nBased on these charts the order I would pick for QQQ is: ARIMA(2,1,0)\n\n\nCode\nmodelQQQ1 &lt;- arima(diff1QQQ, order = c(2,1,0))\nsummary(modelQQQ1)\n\n\n\nCall:\narima(x = diff1QQQ, order = c(2, 1, 0))\n\nCoefficients:\n          ar1      ar2\n      -1.0035  -0.4832\ns.e.   0.0334   0.0334\n\nsigma^2 estimated as 0.0001131:  log likelihood = 2149.08,  aic = -4292.16\n\nTraining set error measures:\n                       ME       RMSE         MAE      MPE     MAPE      MASE\nTraining set 4.630039e-05 0.01062913 0.007805518 87.46782 258.6253 0.6398223\n                   ACF1\nTraining set -0.1944037\n\n\n\nEquation is x = -1.0034x(t-1) - 0.4832x(t-2) + error\nModel Diagnostic:\n\n\n\nCode\nstats::tsdiag(modelQQQ1)\n\n\n\n\n\nThe Ljung Box statistics look cood, although the ACF of the residuals does have 1 significant term.\nI originally tried a (4,1,2) model, however the ljung box statistics were highly correlated, and I suspected overfitting. After reducing the parametrization greatly, the new model performed mnuch better.\n\n\n\n\n\nCode\nautoQQQ &lt;- auto.arima(diff1QQQ)\nsummary(autoQQQ)\n\n\nSeries: diff1QQQ \nARIMA(1,0,1) with zero mean \n\nCoefficients:\n          ar1      ma1\n      -0.0008  -0.8122\ns.e.   0.0524   0.0361\n\nsigma^2 = 5.483e-05:  log likelihood = 2402.77\nAIC=-4799.55   AICc=-4799.51   BIC=-4785.94\n\nTraining set error measures:\n                        ME       RMSE         MAE      MPE     MAPE     MASE\nTraining set -6.694728e-05 0.00739421 0.005455453 283.3672 549.0245 0.446905\n                    ACF1\nTraining set 0.003755607\n\n\nThe auto.arima method chose an ARIMA(1,0,1) model. However, this model did not perform as well in terms of AIC, with the Auto arima model having a score of -4799 while my model had a score of -4292.\n\nForecasting with my model\n\n\n\nCode\nplot(forecast(modelQQQ1, 10), xlim = c(650,750))   \n\n\n\n\n\nForecasting with auto arima model\n\n\nCode\nplot(forecast(autoQQQ, 10), xlim = c(650,750))\n\n\n\n\n\nOverall, my model has a slightly more dynamic prediction than the auto arima function, which quicly levels out to 0. However, my model also has a much wider uncertainty band.\n\nCompare ARIMA model with benchmarks\n\n\n\nCode\nnaiveModelQQQ &lt;- naive(diff1QQQ, h=1)\nsnaiveModelQQQ &lt;- snaive(diff1QQQ, h=1)\n\nsummary(naiveModelQQQ)\n\n\n\nForecast method: Naive method\n\nModel Information:\nCall: naive(y = diff1QQQ, h = 1) \n\nResidual sd: 0.0165 \n\nError measures:\n                       ME     RMSE        MAE      MPE     MAPE MASE       ACF1\nTraining set 2.387746e-05 0.016488 0.01219951 309.6279 564.6879    1 -0.6746326\n\nForecasts:\n    Point Forecast       Lo 80      Hi 80       Lo 95      Hi 95\n691   -0.003168135 -0.02429836 0.01796209 -0.03548403 0.02914776\n\n\nCode\nsummary(snaiveModelQQQ)\n\n\n\nForecast method: Seasonal naive method\n\nModel Information:\nCall: snaive(y = diff1QQQ, h = 1) \n\nResidual sd: 0.0165 \n\nError measures:\n                       ME     RMSE        MAE      MPE     MAPE MASE       ACF1\nTraining set 2.387746e-05 0.016488 0.01219951 309.6279 564.6879    1 -0.6746326\n\nForecasts:\n    Point Forecast       Lo 80      Hi 80       Lo 95      Hi 95\n691   -0.003168135 -0.02429836 0.01796209 -0.03548403 0.02914776\n\n\nCode\nsummary(modelQQQ1)\n\n\n\nCall:\narima(x = diff1QQQ, order = c(2, 1, 0))\n\nCoefficients:\n          ar1      ar2\n      -1.0035  -0.4832\ns.e.   0.0334   0.0334\n\nsigma^2 estimated as 0.0001131:  log likelihood = 2149.08,  aic = -4292.16\n\nTraining set error measures:\n                       ME       RMSE         MAE      MPE     MAPE      MASE\nTraining set 4.630039e-05 0.01062913 0.007805518 87.46782 258.6253 0.6398223\n                   ACF1\nTraining set -0.1944037\n\n\nI fit a naive and seasonal naive model. On RMSE my model had the best performance, with 0.011, while the naive and snaive models had 0.017 rmse each (since there was no seasonal period I realized they were the same model). On MAE my arima model had 0.008 while the seasonal naive models had 0.0122.\nLet’s compare forecasts:\n\n\nCode\nplot(forecast(modelQQQ1, 10), xlim = c(650,750)) \n\n\n\n\n\n\n\nCode\nplot(forecast(naiveModelQQQ, 10), xlim = c(650,750))   \n\n\n\n\n\nHere, the naive method can only forecast 1 observation into the future, since the seasonal period is one. Which is an advantage to my model, but realistically means the naive model should be evaluated with cross validation.\n\nSARIMA\n\nLet’s look for a seasonal affect in the ACF plots, using the weather events data. First we prepare the data:\n\n\nCode\nweather_data &lt;- read.csv('data/storms_clean.csv')\n\n\nweather_data$month &lt;- weather_data$BEGIN_YEARMONTH %% 100\n\nweather_data &lt;- weather_data %&gt;%\n    mutate(realdate = make_date(YEAR, month, BEGIN_DAY)) %&gt;%\n    mutate(DAMAGE_PROPERTY =  str_replace(DAMAGE_PROPERTY, \"K\", \"\") )  %&gt;%\n    mutate(DAMAGE_PROPERTY = as.numeric(DAMAGE_PROPERTY)) %&gt;%\n    mutate(DAMAGE_PROPERTY = replace_na(DAMAGE_PROPERTY, 0))\n\n\nWarning: There was 1 warning in `mutate()`.\ni In argument: `DAMAGE_PROPERTY = as.numeric(DAMAGE_PROPERTY)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\nCode\n# Daily Event Number\ndaily_events &lt;- weather_data %&gt;%\n    group_by(realdate) %&gt;%\n    summarize(events = length(EPISODE_ID))\n\n# Daily Property Damage\ndaily_property &lt;-  weather_data %&gt;%\n    group_by(realdate) %&gt;%\n    summarize(pdam = sum(DAMAGE_PROPERTY))\n\n# Daily Daily Casualties\ndaily_casualties &lt;-  weather_data %&gt;%\n    group_by(realdate) %&gt;%\n    summarize(casualties = sum(INJURIES_DIRECT) + sum(INJURIES_INDIRECT) + sum(DEATHS_DIRECT) + sum(DEATHS_INDIRECT))\n\n# Daily Hurricanes\ndaily_hurricanes &lt;- weather_data %&gt;%\n    filter(EVENT_TYPE == \"Hurricane\") %&gt;%\n    group_by(realdate) %&gt;%\n    summarize(hurricaneWarnings = length(EPISODE_ID))\n\n\n# Daily joined data\n\nweather_merged &lt;- full_join(daily_events, daily_property, by = \"realdate\")\nweather_merged &lt;- full_join(weather_merged, daily_casualties, by = 'realdate')\nweather_merged &lt;- full_join(weather_merged, daily_hurricanes, by = 'realdate')\n\nhead(weather_merged)\n\n\n# A tibble: 6 x 5\n  realdate   events  pdam casualties hurricaneWarnings\n  &lt;date&gt;      &lt;int&gt; &lt;dbl&gt;      &lt;int&gt;             &lt;int&gt;\n1 2021-01-01    643  918           1                NA\n2 2021-01-02     75  189.          0                NA\n3 2021-01-03     80   63           3                NA\n4 2021-01-04     44   20           0                NA\n5 2021-01-05     18    0           2                NA\n6 2021-01-06     27  850           2                NA\n\n\nNow, lets look at the acf plot:\n\n\nCode\nacf(weather_merged$events, lag.max = 365)\n\n\n\n\n\nWith a 365 lag plot (as we are looking at weather data), we can see that for about 1/4 of the 365 lags, there is some positive correlation in the residuals (the same season), then for 1/2 the lags after that there is negative correlation (the opposite seasons), and then a return to significant positive correlation about 3/4 of the way through the data. This appears to show a clear seasonal effect of about 365. So let’s seasonally difference the data.\n\n\nCode\nseasonDiff &lt;- weather_merged$events %&gt;% diff(lag = 365)\nacf(seasonDiff, lag.max = 365)\n\n\n\n\n\nCode\npacf(seasonDiff)\n\n\n\n\n\nAfter seasonal differencing, this plot looks much much better, without noticeable season-to-season correlations in the lags, although there is still some short-term correlation. And some repeating period which appears to be almost weekly in the residuals.\nBased on the ACF and PACF plots, I would consider p of 1, d of 0, and q of 3. Then for P and Q I might consider 0, D would be 1 since we seasonally differenced. But let’s run some code to see the AIC of different values:\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \ntemp=c()\nd=1\nD=1\ns=12\n \ni=1\ntemp= data.frame()\nls=matrix(rep(NA,9*378),nrow=378)\n \nfor (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          for(d in d1:d2)\n       \n        {\n          if(p+d+q+P+D+Q&lt;=8)\n          {\n            \n            model&lt;- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  \n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\nSARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=weather_merged$events) %&gt;% filter(!is.na(p))\n\n\n   p d q P D Q      AIC      BIC     AICc\n1  0 0 0 0 1 0 12204.30 12213.93 12204.32\n2  0 1 0 0 1 0 12419.43 12424.24 12419.43\n3  0 0 0 0 1 1 12204.30 12213.93 12204.32\n4  0 1 0 0 1 1 12419.43 12424.24 12419.43\n5  0 0 0 1 1 0 12204.30 12213.93 12204.32\n6  0 1 0 1 1 0 12419.43 12424.24 12419.43\n7  0 0 0 1 1 1 12204.30 12213.93 12204.32\n8  0 1 0 1 1 1 12419.43 12424.24 12419.43\n9  0 0 0 2 1 0 12204.30 12213.93 12204.32\n10 0 1 0 2 1 0 12419.43 12424.24 12419.43\n11 0 0 0 2 1 1 12204.30 12213.93 12204.32\n12 0 0 1 0 1 0 12102.10 12116.55 12102.13\n13 0 1 1 0 1 0 12130.44 12140.07 12130.46\n14 0 0 1 0 1 1 12102.10 12116.55 12102.13\n15 0 1 1 0 1 1 12130.44 12140.07 12130.46\n16 0 0 1 1 1 0 12102.10 12116.55 12102.13\n17 0 1 1 1 1 0 12130.44 12140.07 12130.46\n18 0 0 1 1 1 1 12102.10 12116.55 12102.13\n19 0 0 1 2 1 0 12102.10 12116.55 12102.13\n20 0 0 2 0 1 0 12090.24 12109.50 12090.28\n21 0 1 2 0 1 0 12071.61 12086.05 12071.64\n22 0 0 2 0 1 1 12090.24 12109.50 12090.28\n23 0 0 2 1 1 0 12090.24 12109.50 12090.28\n24 0 0 3 0 1 0 12090.34 12114.42 12090.41\n25 1 0 0 0 1 0 12084.41 12098.85 12084.43\n26 1 1 0 0 1 0 12303.82 12313.44 12303.83\n27 1 0 0 0 1 1 12084.41 12098.85 12084.43\n28 1 1 0 0 1 1 12303.82 12313.44 12303.83\n29 1 0 0 1 1 0 12084.41 12098.85 12084.43\n30 1 1 0 1 1 0 12303.82 12313.44 12303.83\n31 1 0 0 1 1 1 12084.41 12098.85 12084.43\n32 1 0 0 2 1 0 12084.41 12098.85 12084.43\n33 1 0 1 0 1 0 12084.67 12103.93 12084.72\n34 1 1 1 0 1 0 12067.11 12081.55 12067.14\n35 1 0 1 0 1 1 12084.67 12103.93 12084.72\n36 1 0 1 1 1 0 12084.67 12103.93 12084.72\n37 1 0 2 0 1 0 12077.36 12101.43 12077.43\n38 2 0 0 0 1 0 12085.17 12104.42 12085.21\n39 2 1 0 0 1 0 12240.65 12255.09 12240.67\n40 2 0 0 0 1 1 12085.17 12104.42 12085.21\n41 2 0 0 1 1 0 12085.17 12104.42 12085.21\n42 2 0 1 0 1 0 12074.21 12098.29 12074.28\n43 3 0 0 0 1 0 12085.39 12109.46 12085.45\n\n\nCode\nSARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=seasonDiff) %&gt;% filter(!is.na(p))\n\n\n   p d q P D Q      AIC      BIC     AICc\n1  0 0 0 0 1 0 7590.941 7599.546 7590.963\n2  0 1 0 0 1 0 7681.255 7685.556 7681.263\n3  0 0 0 0 1 1 7590.941 7599.546 7590.963\n4  0 1 0 0 1 1 7681.255 7685.556 7681.263\n5  0 0 0 1 1 0 7590.941 7599.546 7590.963\n6  0 1 0 1 1 0 7681.255 7685.556 7681.263\n7  0 0 0 1 1 1 7590.941 7599.546 7590.963\n8  0 1 0 1 1 1 7681.255 7685.556 7681.263\n9  0 0 0 2 1 0 7590.941 7599.546 7590.963\n10 0 1 0 2 1 0 7681.255 7685.556 7681.263\n11 0 0 0 2 1 1 7590.941 7599.546 7590.963\n12 0 0 1 0 1 0 7508.844 7521.752 7508.888\n13 0 1 1 0 1 0 7574.405 7583.007 7574.427\n14 0 0 1 0 1 1 7508.844 7521.752 7508.888\n15 0 1 1 0 1 1 7574.405 7583.007 7574.427\n16 0 0 1 1 1 0 7508.844 7521.752 7508.888\n17 0 1 1 1 1 0 7574.405 7583.007 7574.427\n18 0 0 1 1 1 1 7508.844 7521.752 7508.888\n19 0 0 1 2 1 0 7508.844 7521.752 7508.888\n20 0 0 2 0 1 0 7502.242 7519.453 7502.316\n21 0 1 2 0 1 0 7501.777 7514.680 7501.822\n22 0 0 2 0 1 1 7502.242 7519.453 7502.316\n23 0 0 2 1 1 0 7502.242 7519.453 7502.316\n24 0 0 3 0 1 0 7504.242 7525.755 7504.353\n25 1 0 0 0 1 0 7502.164 7515.072 7502.208\n26 1 1 0 0 1 0 7641.447 7650.048 7641.469\n27 1 0 0 0 1 1 7502.164 7515.072 7502.208\n28 1 1 0 0 1 1 7641.447 7650.048 7641.469\n29 1 0 0 1 1 0 7502.164 7515.072 7502.208\n30 1 1 0 1 1 0 7641.447 7650.048 7641.469\n31 1 0 0 1 1 1 7502.164 7515.072 7502.208\n32 1 0 0 2 1 0 7502.164 7515.072 7502.208\n33 1 0 1 0 1 0 7502.957 7520.168 7503.031\n34 1 1 1 0 1 0 7494.739 7507.642 7494.784\n35 1 0 1 0 1 1 7502.957 7520.168 7503.031\n36 1 0 1 1 1 0 7502.957 7520.168 7503.031\n37 1 0 2 0 1 0 7504.242 7525.755 7504.353\n38 2 0 0 0 1 0 7502.828 7520.038 7502.902\n39 2 1 0 0 1 0 7610.893 7623.795 7610.937\n40 2 0 0 0 1 1 7502.828 7520.038 7502.902\n41 2 0 0 1 1 0 7502.828 7520.038 7502.902\n42 2 0 1 0 1 0 7504.793 7526.306 7504.904\n43 3 0 0 0 1 0 7504.726 7526.239 7504.838\n\n\nBased on the results of the function, the minimum AIC and BIC are for the model: (0,1,2)(0,1,0). If I run the SARIMA function on the 365 differenced data, then it returns (1,1,1,)(0,1,0) as the model with the lowest AIC. So I will compare these two models for the series, using diagnostics.\n\n\nCode\nmod1 &lt;- Arima(weather_merged$events,order=c(0,1,2),seasonal=c(0,1,0))\nmod2 &lt;- Arima(weather_merged$events,order=c(1,1,1),seasonal=c(0,1,0))\n\ncheckresiduals(mod1 )\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,2)\nQ* = 8.0235, df = 8, p-value = 0.4312\n\nModel df: 2.   Total lags used: 10\n\n\nThe residuals for model 1 (0,1,2)(0,1,0) show some clustering of volatility. In addition, they appear to be skewed to the right, as the right tail of the residual distribution is fatter than the left tail and has more outlying values. Finally, the ACF plot of the residuals looks good, with little visible correlation and no values crossing the significance line. In addition, the Ljung-Box test returns p=0.43, suggesting we can reject the idea that there is autocorrelation in the residuals.\n\n\nCode\ncheckresiduals(mod2 )\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,1,1)\nQ* = 2.7198, df = 8, p-value = 0.9507\n\nModel df: 2.   Total lags used: 10\n\n\nThe residual diagnostics for model 2 (1,1,1)(0,1,0) are similar to model 1, except that they have even less correlatoin visible in the residual plots. The residual’s distribution is still skewed to the right, with a fatter positive tail. The ACF plot, however, has even less correlation visible, with only two values even coming marginally close to the significance line. There is still some heteroskedacticity in the plot over time, however, suggesting clustering of volatility.\nNow, let’s use an Auto.Arima function to determine the correct model:\n\n\nCode\naaData &lt;- ts(weather_merged$events)\nmod3 &lt;- auto.arima(aaData, seasonal = TRUE, trace = TRUE)\n\n\n\n Fitting models using approximations to speed things up...\n\n ARIMA(2,0,2) with non-zero mean : 12069.53\n ARIMA(0,0,0) with non-zero mean : 12204.32\n ARIMA(1,0,0) with non-zero mean : 12079.82\n ARIMA(0,0,1) with non-zero mean : 12102.76\n ARIMA(0,0,0) with zero mean     : 12785.96\n ARIMA(1,0,2) with non-zero mean : 12082.52\n ARIMA(2,0,1) with non-zero mean : 12069.52\n ARIMA(1,0,1) with non-zero mean : 12081.01\n ARIMA(2,0,0) with non-zero mean : 12079.36\n ARIMA(3,0,1) with non-zero mean : 12069.61\n ARIMA(3,0,0) with non-zero mean : 12080.39\n ARIMA(3,0,2) with non-zero mean : 12072.31\n ARIMA(2,0,1) with zero mean     : Inf\n\n Now re-fitting the best model(s) without approximations...\n\n ARIMA(2,0,1) with non-zero mean : 12074.28\n\n Best model: ARIMA(2,0,1) with non-zero mean \n\n\nRegardless of the frequency fed into the model, Auto.arima only wants to fit a (2,0,1) ARIMA model. I tried 365, 90, 60, 40, 14, and 7 day frequencies, and in each case the seasonal term was not chosen for the data. I think the reason that it doesn’t recognize the seasonality is because it doesn’t worok with 365, which should be the best frequency for the data.\nForecast with a confidence band: Model 1 (0,1,2)(0,1,0)\n\n\nCode\nplot(forecast(mod2), xlim = c(850,925))\n\n\n\n\n\nModel 2: (1,1,1)(0,1,0)\n\n\nCode\nplot(forecast(mod1), xlim = c(850,925))\n\n\n\n\n\nI think the forecasts are interesting, because model 2 has a more dynamic forecast, with a decrease over several days before leveling out its prediction. Model 1, meanwhile, predicts that the series will hardly change after its first prediction. While the series does not have a lot of trend going into the prediction interval, weather events are dynamic and I would tend to believe the model which includes more variation as opposed to constant numbers of events. Hence, I would select the (1,1,1)(0,1,0) SARIMA model.\nBenchmark Comparison\nWe will use two benchmark methods: A seasonal naive forecast and a mean forecast.\n\n\nCode\nbase1 &lt;- snaive(aaData, 10)\nbase2 &lt;- meanf(aaData, 10)\n\nplot(base1, xlim = c(850,925))\n\n\n\n\n\nHere we can see the plot for the seasonal naive model’s forecasts (10 days out), which show a predicted value close to the last observed value in the series. It has a high degree of uncertainty as shown by the prediction interval, which is quite wide.\n\n\nCode\nplot(base2, xlim = c(850,925) ) \n\n\n\n\n\nThe forecast for the meanf model (above) departs further from the previously observed values, as the mean of the series is substantially below recently observed values. However, the model has a smaller prediction interval than the seasonal naive forecast, which is a slight advantage.\nNow let’s look at the accuracy of the three forcasts:\n\n\nCode\naccuracy(snaive(aaData))\n\n\n                    ME     RMSE      MAE       MPE    MAPE MASE       ACF1\nTraining set -0.232967 222.2549 134.6615 -92.97186 141.104    1 -0.3466138\n\n\nCode\naccuracy(meanf(aaData))\n\n\n                       ME     RMSE      MAE       MPE     MAPE     MASE\nTraining set 4.269057e-15 195.8141 137.4244 -231.3227 259.5254 1.020517\n                  ACF1\nTraining set 0.3527022\n\n\nCode\naccuracy(mod2)\n\n\n                   ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 1.865123 182.4393 120.2761 -152.6725 179.3078 0.8931731\n                    ACF1\nTraining set 0.006055532\n\n\nThe accuracy statistics were a mixed result between the seasonal naive forecast and the SARIMA(1,1,1)(0,1,0) model. The mean forecast did not perform better on any metric than the other two models, and could be discarded. On Root Mean Squared Error, the SARIMA model beat the Seasonal Naive model with a value of 182.4 vs. 222.3, respectively. On Mean Absolute Error, the SARIMA model also performed better, with 120.3 compared to the Seasonal Naive model’s 134.7. On the Mean Absolute Percentage Error, however, the Seasonal Naive model performed better than the SARIMA model, achieving 141.1 vs. 179.3 for the SARIMA model.\nOverall, it seems like the accuracy metrics might favor the seasonal naive model, while the prediction forecasts look more accurate for the SARIMA model.\nCross Validation: Let’s do a seasonal cross-validation with 1 and 10-step-ahead forecasts.\n\n\nCode\n    # I add a 100 day buffer to my period of 365 days to have enough data\n    test &lt;- 100 \n    trainnum &lt;- length(aaData) - test\n    rmse1 &lt;- vector(mode = 'numeric', length = 100)\n    rmse2 &lt;- vector(mode = 'numeric', length = 100)\n    rmse361 &lt;- vector(mode = 'numeric', length = 100)\n    rmse362 &lt;- vector(mode = 'numeric', length = 100)\n\n    for(i in 1:100) {\n\n        \n        xtrain &lt;- aaData[c(1:(trainnum + i - 1))]\n        xtest &lt;-  aaData[c((trainnum + i +1):(trainnum+i+10))]\n        \n    \n        ######## model ###########\n        fit2 &lt;- arima(xtrain, order = c(1,1,1), seasonal = list(order = c(0,1,0)))\n        fcast2 &lt;- predict(fit2, n.ahead = 10)$pred\n        \n        # Errors\n\n        rmse2[i]  &lt;-sqrt((fcast2[1]-xtest[1])^2)\n        rmse362[i]  &lt;- mean( sqrt((fcast2 -xtest)^2) )\n        \n    }\n    \n# create index\nindex &lt;- c(1:100)\nggplot() +\n    geom_line(aes(x = index, y = rmse2), color = 'blue' ) + \n    geom_line(aes(x = index, y = rmse362), color = 'red')\n\n\nWarning: Removed 1 row containing missing values (`geom_line()`).\n\n\nWarning: Removed 10 rows containing missing values (`geom_line()`).\n\n\n\n\n\nThe chart above shows the RMSE for the cross validated forecasts with windows 1 and 10. I had to use 10 for my seasonal window as my computer was unable to handle the 365 window, and could not produce results. But my data also had short-term seasonality so I relied upon that here. The red line represents the 10-step ahead forecast average RMSE and the blue line represents the 1-step ahead forecast RMSE. Overall you can see that both forecasts perform better and worse around the same time, except that the short-term forecast has a lagged reaction to the same periods where the long-term forecast performed poorly. In some cases, however, the 1-step RMSE does exceed the 10-step RMSE, suggesting poor short term performance."
  },
  {
    "objectID": "about me.html",
    "href": "about me.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "ARIMAX SARIMAX VAR.html",
    "href": "ARIMAX SARIMAX VAR.html",
    "title": "ARIMAX SARIMAX VAR",
    "section": "",
    "text": "Planning Models\n\nWe have the following independent variables: 1. Interest Rate Expectation Changes - 3 Months 2. Interest Rate Expectation Changes - 6 Months 3. Interest Rate Expectation Changes - 1 Year 4. Extreme Weather Events - Daily Event Number 5. Extreme Weather Events - Daily Property Damage 6. Extreme Weather Events - Daily Casualties 7. Extreme Weather Events - Hurricanes 8. Expected Volatility (VIX) - Value 9. Expected Volatility (VIX) - Daily Change 10. Work Stoppages - Daily Striking Worker Total 11. Work Stoppages - Daily New Strike Beggining 12. Work Stoppages - Daily New Workers Striking\n\nPreparing Exogenous Data\n\nFirst we need to create all 12 predictors, then we can combine them to estimate the models as needed.\n\nlibrary(knitr)\nlibrary(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.2.1     v dplyr   1.1.2\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(quantmod)\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\n######################### Warning from 'xts' package ##########################\n#                                                                             #\n# The dplyr lag() function breaks how base R's lag() function is supposed to  #\n# work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n# source() into this session won't work correctly.                            #\n#                                                                             #\n# Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n# conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n# dplyr from breaking base R's lag() function.                                #\n#                                                                             #\n# Code in packages is not affected. It's protected by R's namespace mechanism #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n###############################################################################\n\n\n\nAttaching package: 'xts'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nLoading required package: TTR\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nlibrary(forecast)\nlibrary(tseries)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(reticulate)\n\nLet’s quickly retrieve the daily stock price ranges for the indices:\n\nspyIn &lt;- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn &lt;- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn &lt;- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\n\nspyIn$spyRange &lt;- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange &lt;- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange &lt;- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n\nNow, let’s gather the VIX data, since it is also treated like a stock price, and should be available from the same package\n\nvixIn &lt;- quantmod::getSymbols(\"^VIX\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\nWarning: ^VIX contains missing values. Some functions will not work if objects\ncontain missing values in the middle of the series. Consider using na.omit(),\nna.approx(), na.fill(), etc to remove or replace them.\n\nvixIn$dailyChange &lt;- vixIn$VIX.Close - lag(vixIn$VIX.Close)\n# 8 is vixIn$VIX.Close\n# 9 is vixIn$dailyChange\n\n#vixIn &lt;- vixIn %&gt;% \n#    mutate(date = ymd(index(vixIn)))\nhead(vixIn)\n\n           VIX.Open VIX.High VIX.Low VIX.Close VIX.Volume VIX.Adjusted\n2021-01-04    23.04    29.19   22.56     26.97          0        26.97\n2021-01-05    26.94    28.60   24.80     25.34          0        25.34\n2021-01-06    25.48    26.77   22.14     25.07          0        25.07\n2021-01-07    23.67    23.91   22.25     22.37          0        22.37\n2021-01-08    22.43    23.34   21.42     21.56          0        21.56\n2021-01-11    23.31    24.81   23.23     24.08          0        24.08\n           dailyChange\n2021-01-04          NA\n2021-01-05  -1.6299992\n2021-01-06  -0.2700005\n2021-01-07  -2.6999989\n2021-01-08  -0.8100014\n2021-01-11   2.5200005\n\n\nWe have bond yields stored in a CSV, but let’s calculate daily changes:\n\nyieldCurve &lt;- read.csv('data/treasuries.csv')\n\nyieldCurve$mo3delta &lt;- yieldCurve$X3.Mo - lag(yieldCurve$X3.Mo)\nyieldCurve$mo6delta &lt;- yieldCurve$X6.Mo - lag(yieldCurve$X6.Mo)\nyieldCurve$mo12delta &lt;- yieldCurve$X1.Yr - lag(yieldCurve$X1.Yr) \n\nyieldCurve$Date &lt;- mdy(yieldCurve$Date)\n\nWorth noting: Both the treasury data and the VIX data only start on January 4th.\nNext up, let’s prepare the weather event data:\n\nweather_data &lt;- read.csv('data/storms_clean.csv')\n\n\nweather_data$month &lt;- weather_data$BEGIN_YEARMONTH %% 100\n\nweather_data &lt;- weather_data %&gt;%\n    mutate(realdate = make_date(YEAR, month, BEGIN_DAY)) %&gt;%\n    mutate(DAMAGE_PROPERTY =  str_replace(DAMAGE_PROPERTY, \"K\", \"\") )  %&gt;%\n    mutate(DAMAGE_PROPERTY = as.numeric(DAMAGE_PROPERTY)) %&gt;%\n    mutate(DAMAGE_PROPERTY = replace_na(DAMAGE_PROPERTY, 0))\n\nWarning: There was 1 warning in `mutate()`.\ni In argument: `DAMAGE_PROPERTY = as.numeric(DAMAGE_PROPERTY)`.\nCaused by warning:\n! NAs introduced by coercion\n\n# Daily Event Number\ndaily_events &lt;- weather_data %&gt;%\n    group_by(realdate) %&gt;%\n    summarize(events = length(EPISODE_ID))\n\n# Daily Property Damage\ndaily_property &lt;-  weather_data %&gt;%\n    group_by(realdate) %&gt;%\n    summarize(pdam = sum(DAMAGE_PROPERTY))\n\n# Daily Daily Casualties\ndaily_casualties &lt;-  weather_data %&gt;%\n    group_by(realdate) %&gt;%\n    summarize(casualties = sum(INJURIES_DIRECT) + sum(INJURIES_INDIRECT) + sum(DEATHS_DIRECT) + sum(DEATHS_INDIRECT))\n\n# Daily Hurricanes\ndaily_hurricanes &lt;- weather_data %&gt;%\n    filter(EVENT_TYPE == \"Hurricane\") %&gt;%\n    group_by(realdate) %&gt;%\n    summarize(hurricaneWarnings = length(EPISODE_ID))\n\n\n# Daily joined data\n\nweather_merged &lt;- full_join(daily_events, daily_property, by = \"realdate\")\nweather_merged &lt;- full_join(weather_merged, daily_casualties, by = 'realdate')\nweather_merged &lt;- full_join(weather_merged, daily_hurricanes, by = 'realdate')\n\nhead(weather_merged)\n\n# A tibble: 6 x 5\n  realdate   events  pdam casualties hurricaneWarnings\n  &lt;date&gt;      &lt;int&gt; &lt;dbl&gt;      &lt;int&gt;             &lt;int&gt;\n1 2021-01-01    643  918           1                NA\n2 2021-01-02     75  189.          0                NA\n3 2021-01-03     80   63           3                NA\n4 2021-01-04     44   20           0                NA\n5 2021-01-05     18    0           2                NA\n6 2021-01-06     27  850           2                NA\n\n\nFinally, lets get the striking worker data ready:\n\nstrike_data &lt;- read.csv('data/strikes.csv')\n\n# clean date format\nstrike_data$start = mdy(strike_data$Work.stoppage.beginning.date)\nstrike_data$end = mdy(strike_data$Work.stoppage.ending.date)\nstrike_data$workers = as.numeric(str_replace(strike_data$Number.of.workers.2., \",\", \"\" ))\n\n\nhead(strike_data)\n\n            ï..Organizations.involved Industry.code.1.\n1          Hunts Point Produce Market           445200\n2                 Columbia University            61131\n3 Allegheny Technologies Incorporated           332710\n4              Warrior Met Coal, Inc.           212112\n5                 New York University            61131\n6                         Cook County           622110\n  Work.stoppage.beginning.date Work.stoppage.ending.date Number.of.workers.2.\n1                    1/17/2021                 1/23/2021                1,400\n2                    3/15/2021                  1/7/2022                3,000\n3                    3/30/2021                 7/13/2021                1,300\n4                     4/1/2021                 3/31/2022                1,100\n5                    4/26/2021                 5/15/2021                2,200\n6                    6/25/2021                 7/12/2021                2,000\n  Days.idle..cumulative.for.this.work.stoppage.3.      start        end workers\n1                                           5,600 2021-01-17 2021-01-23    1400\n2                                         177,000 2021-03-15 2022-01-07    3000\n3                                          94,900 2021-03-30 2021-07-13    1300\n4                                         273,900 2021-04-01 2022-03-31    1100\n5                                          33,000 2021-04-26 2021-05-15    2200\n6                                          22,000 2021-06-25 2021-07-12    2000\n\ntarget_dates &lt;- ymd(index(spyIn))\n\ndaily_workers &lt;- vector(mode = \"numeric\", length = length(target_dates))\n\nfor(i in seq_along(target_dates)) {\n    tempDat &lt;- strike_data %&gt;%\n        filter(start &lt;= target_dates[i]) %&gt;%\n        filter(end &gt;= target_dates[i])\n\n    daily_workers[i] = sum(tempDat$workers)\n}\n\nworkerDF &lt;- data.frame('workers' = daily_workers, 'date' = target_dates)\nplot(daily_workers, type = 'l')\n\n\n\n\nNow, we can combined all of these datasets into one dataframe, joining on the date columns\n\n# Convert TS objects to df, and fix the date column\nvixDF &lt;- data.frame(vixIn)\nvixDF$date &lt;- ymd(index(vixIn))\nspyDF &lt;- data.frame(spyIn)\nspyDF$date &lt;- ymd(index(spyIn))\nqqqDF &lt;- data.frame(qqqIn)\nqqqDF$date &lt;- ymd(index(qqqIn))\niwmDF &lt;- data.frame(iwmIn)\niwmDF$date &lt;- ymd(index(iwmIn))\n\n# Join symbols together\ntickers &lt;- left_join(spyDF, vixDF, by = 'date')\ntickers &lt;- left_join(tickers, qqqDF, by = 'date')\ntickers &lt;- left_join(tickers, iwmDF, by = 'date')\n\n# Join weather data\ncombinedData &lt;- left_join(tickers, weather_merged, by = c(\"date\" = \"realdate\"))\n\n# Join Bond Yields\ncombinedData &lt;- left_join(combinedData, yieldCurve, by = c(\"date\" = \"Date\"))\n\n# Join Labor Data\ncombinedData &lt;- left_join(combinedData, workerDF, by = 'date')\n\nhead(combinedData)\n\n  SPY.Open SPY.High SPY.Low SPY.Close SPY.Volume SPY.Adjusted    spyRange\n1   375.31   375.45  364.82    368.79  110210800     354.1974 0.028323266\n2   368.10   372.50  368.05    371.33   66426200     356.6368 0.012089139\n3   369.71   376.98  369.12    373.55  107997700     358.7690 0.021259950\n4   376.10   379.90  375.91    379.10   68766800     364.0995 0.010608854\n5   380.59   381.49  377.10    381.26   71677200     366.1740 0.011534681\n6   377.85   380.58  377.72    378.69   51034700     363.7057 0.007569102\n        date VIX.Open VIX.High VIX.Low VIX.Close VIX.Volume VIX.Adjusted\n1 2021-01-04    23.04    29.19   22.56     26.97          0        26.97\n2 2021-01-05    26.94    28.60   24.80     25.34          0        25.34\n3 2021-01-06    25.48    26.77   22.14     25.07          0        25.07\n4 2021-01-07    23.67    23.91   22.25     22.37          0        22.37\n5 2021-01-08    22.43    23.34   21.42     21.56          0        21.56\n6 2021-01-11    23.31    24.81   23.23     24.08          0        24.08\n  dailyChange QQQ.Open QQQ.High QQQ.Low QQQ.Close QQQ.Volume QQQ.Adjusted\n1          NA   315.11   315.29  305.18    309.31   45305900     304.2444\n2  -1.6299992   308.29   312.14  308.29    311.86   29323400     306.7526\n3  -0.2700005   307.00   311.88  305.98    307.54   52809600     302.5033\n4  -2.6999989   310.28   315.84  310.25    314.98   30394800     309.8215\n5  -0.8100014   317.34   319.39  315.08    319.03   33955800     313.8051\n6   2.5200005   315.98   317.19  313.75    314.42   32746400     309.2706\n    qqqRange IWM.Open IWM.High IWM.Low IWM.Close IWM.Volume IWM.Adjusted\n1 0.03208409   197.54   197.89  190.94    193.50   33664200     186.8583\n2 0.01248826   193.09   197.62  193.07    196.49   27442900     189.7457\n3 0.01921822   199.48   206.78  199.16    204.53   52952200     197.5097\n4 0.01801597   205.71   208.52  205.70    208.17   24031400     201.0247\n5 0.01358174   209.32   209.77  204.66    207.72   29017000     200.5902\n6 0.01088677   205.09   208.12  204.83    207.54   20945100     200.4163\n    iwmRange events pdam casualties hurricaneWarnings X1.Mo X2.Mo X3.Mo X4.Mo\n1 0.03518273     44   20          0                NA  0.09  0.09  0.09    NA\n2 0.02356408     18    0          2                NA  0.08  0.09  0.09    NA\n3 0.03819929     27  850          2                NA  0.09  0.09  0.09    NA\n4 0.01370865     74    0          0                NA  0.09  0.09  0.09    NA\n5 0.02441239     29   20          2                NA  0.08  0.08  0.08    NA\n6 0.01604171     68    0          0                NA  0.09  0.08  0.08    NA\n  X6.Mo X1.Yr X2.Yr X3.Yr X5.Yr X7.Yr X10.Yr X20.Yr X30.Yr mo3delta mo6delta\n1  0.09  0.10  0.11  0.16  0.36  0.64   0.93   1.46   1.66     0.00     0.00\n2  0.09  0.10  0.13  0.17  0.38  0.66   0.96   1.49   1.70     0.00     0.00\n3  0.09  0.11  0.14  0.20  0.43  0.74   1.04   1.60   1.81     0.00     0.00\n4  0.09  0.11  0.14  0.22  0.46  0.78   1.08   1.64   1.85     0.01     0.00\n5  0.09  0.10  0.14  0.24  0.49  0.81   1.13   1.67   1.87     0.00    -0.01\n6  0.10  0.10  0.14  0.22  0.50  0.84   1.15   1.68   1.88    -0.01     0.01\n  mo12delta workers\n1      0.00       0\n2     -0.01       0\n3      0.00       0\n4      0.01       0\n5      0.00       0\n6     -0.01       0\n\n\n\nSelect Models Based on These Exogenous Variables\n\nWe will combine these 12 predictors into 5 models, for SPY, QQQ, and IWM intraday volatility:\n\nModel 1: (ARIMAX) SPY ~ Interest Rate 1-Year + Daily Weather Property Damage + Daily VIX Change + Daily Striking Worker Total\n\nThis model is selected based on the literature review, which suggested that weather events and investor expecations could affect stock prices. This is the “kitchen sink” model, where I am throwing in variables from all data sources. However, looking at the variables individually, such as daily property damage vs. SPY daily price range, we don’t nessecarily see clear correlation (see plot below which resembles white noise). But I am interested to see how these variables are related when taking many different contextual factors into account in the same model.\n\nggplot(combinedData, aes(x = log(spyRange), y = log(pdam)) ) + geom_point() + labs(title = \"3 Month Interest Rate Changes vs. VIX Change \", x = \"Log SPY Daily Spread\", y = \"Log Property Damage From Storms\")\n\nWarning: Removed 63 rows containing missing values (geom_point).\n\n\n\n\n\n\nModel 2: (VAR) SPY ~ Interest Rate 3-Months + Daily VIX Value\n\nThis model is based on a belief that there is an interrelationship between VIX prices and bond yields. This is because both would increase and decrease based on investor expectations for macroeconomic performance in upcoming months. If investors feel the economy will perform poorly, then this might predict bond yields lowering, as well as increased volatility which would be reflected by increases in the VIX. We also see a weak linear correlation in these daily values, as pictured in the plot below.\n\nggplot(combinedData, aes(x = mo3delta, y = dailyChange ) ) + geom_point() + labs(title = \"3 Month Interest Rate Changes vs. VIX Change \", x = \"Change in 3-Month Interest Rates\", y = \"Change in VIX Price\")\n\nWarning: Removed 30 rows containing missing values (geom_point).\n\n\n\n\n\n\nModel 3: (ARIMAX) IWM ~ Casualties + Hurricanes + Interest Rate 3-Months\n\nThis model is all about exogenous shocks. New strikes beggining and hurricane warnings are infrequent but extreme events, which have been grouped together with short-term interest rates (3 month window) to try and capture extreme-but-short-termm influences on volatility.\n\nModel 4: (ARIMAX) QQQ ~ All Interest Rates + All Extreme Weather Events + Daily VIX Change + Daily Striking Workers\n\n\nModel 5: (ARIMAX) QQQ ~ Interest Rate 3 months + Daily Property Damage + Daily VIX Change + Daily New Striking Workers\n\nModels 4 and 5 follow the same logic as model 1, being selected based off of the literature review, but looking at QQQ as oppposed to SPY to see whether large-cap tech companies are more likely to be affected by this kind of volatility.\n\nModel Selection\n\nIn this section, I will begin by identifying the candidate model structures for each of the 5 overarching models outlined above. I will identify candidate models through auto.arima for ARIMAX models, plus hand-selected values. For VAR models, I will identify 2 candidates for each overall model with the autoVAR function.\n\nModel Selection for ARIMAX Models\n\n\nModel 1: SPY ~ Interest Rate 1-Year + Daily Weather Property Damage + Daily VIX Change + Daily Striking Worker Total\n\n\nxMatrix = combinedData[,c('mo12delta', 'pdam', 'dailyChange', 'workers')]\nxMatrix[is.na(xMatrix)] &lt;- 0\nxMatrix = scale(xMatrix)\nxMatrix = as.matrix(xMatrix)\n\n#xMatrix\n\nmod1candidate1 = auto.arima(scale(combinedData$spyRange), xreg = xMatrix, trace = TRUE)\n\n\n Fitting models using approximations to speed things up...\n\n Regression with ARIMA(2,1,2) errors : 1599.925\n Regression with ARIMA(0,1,0) errors : 1880.267\n Regression with ARIMA(1,1,0) errors : 1699.179\n Regression with ARIMA(0,1,1) errors : 1616.148\n Regression with ARIMA(0,1,0) errors : 1878.238\n Regression with ARIMA(1,1,2) errors : 1604.247\n Regression with ARIMA(2,1,1) errors : 1604.271\n Regression with ARIMA(3,1,2) errors : 1599.17\n Regression with ARIMA(3,1,1) errors : 1597.175\n Regression with ARIMA(3,1,0) errors : 1626.681\n Regression with ARIMA(4,1,1) errors : 1591.027\n Regression with ARIMA(4,1,0) errors : 1623.139\n Regression with ARIMA(5,1,1) errors : 1597.41\n Regression with ARIMA(4,1,2) errors : 1593.09\n Regression with ARIMA(5,1,0) errors : 1617.939\n Regression with ARIMA(5,1,2) errors : Inf\n Regression with ARIMA(4,1,1) errors : 1588.981\n Regression with ARIMA(3,1,1) errors : 1595.121\n Regression with ARIMA(4,1,0) errors : 1621.08\n Regression with ARIMA(5,1,1) errors : 1595.37\n Regression with ARIMA(4,1,2) errors : 1591.037\n Regression with ARIMA(3,1,0) errors : 1624.63\n Regression with ARIMA(3,1,2) errors : 1597.106\n Regression with ARIMA(5,1,0) errors : 1615.874\n Regression with ARIMA(5,1,2) errors : Inf\n\n Now re-fitting the best model(s) without approximations...\n\n Regression with ARIMA(4,1,1) errors : 1592.116\n\n Best model: Regression with ARIMA(4,1,1) errors \n\ncheckresiduals(mod1candidate1)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(4,1,1) errors\nQ* = 3.619, df = 5, p-value = 0.6055\n\nModel df: 5.   Total lags used: 10\n\n\nAuto ARIMA picks out the model (4,1,1) for the standardized data. The residual diagnostic plots look good, with the residuals normally distributed.\n\nxMatrix = as.data.frame(xMatrix)\n\n# Lets examine the residuals directly to identify \nmod1candidate2 &lt;- lm(scale(combinedData$spyRange) ~ mo12delta + pdam + dailyChange + workers, data = xMatrix )\nsummary(mod1candidate2)\n\n\nCall:\nlm(formula = scale(combinedData$spyRange) ~ mo12delta + pdam + \n    dailyChange + workers, data = xMatrix)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.5121 -0.7147 -0.2584  0.4739  5.6401 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.420e-16  3.766e-02   0.000 1.000000    \nmo12delta    1.479e-02  3.778e-02   0.392 0.695544    \npdam        -2.214e-02  3.788e-02  -0.584 0.559186    \ndailyChange  1.046e-01  3.772e-02   2.772 0.005731 ** \nworkers     -1.272e-01  3.791e-02  -3.355 0.000838 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9894 on 685 degrees of freedom\nMultiple R-squared:  0.02684,   Adjusted R-squared:  0.02116 \nF-statistic: 4.723 on 4 and 685 DF,  p-value: 0.0009156\n\nresid1 &lt;- mod1candidate2$residuals\npacf(resid1)\n\n\n\nacf(resid1)\n\n\n\n\nBased on the PACF and ACF of the residuals from the regression, it seems we should definitely difference the series, as we have many significant lag terms in the ACF. On the PACF, we can see 4 terms clearly signfificant. Based on these charts, I might try the model (4,1,0). I will try up through (4,2,2) and look for the lowest aic.\n\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \ntemp=c()\nd=1\nD=1\ns=12\n \ni=1\ntemp= data.frame()\nls=matrix(rep(NA,9*378),nrow=378)\n \n \nfor (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P2)\n      {\n        for(Q in Q1:Q2)\n        {\n          for(d in d1:d2)\n       \n        {\n          if(p+d+q+P+D+Q&lt;=8)\n          {\n            \n            model&lt;- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))\n            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  \n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\nSARIMA.c(p1=1,p2=5,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid1) %&gt;% filter(!is.na(p))\n\n   p d q P D Q      AIC      BIC     AICc\n1  0 0 0 0 1 0 1942.363 1951.437 1942.381\n2  0 1 0 0 1 0 1881.332 1885.868 1881.338\n3  0 0 0 0 1 1 1942.363 1951.437 1942.381\n4  0 1 0 0 1 1 1881.332 1885.868 1881.338\n5  0 0 0 1 1 0 1942.363 1951.437 1942.381\n6  0 1 0 1 1 0 1881.332 1885.868 1881.338\n7  0 0 0 1 1 1 1942.363 1951.437 1942.381\n8  0 1 0 1 1 1 1881.332 1885.868 1881.338\n9  0 0 0 2 1 0 1942.363 1951.437 1942.381\n10 0 1 0 2 1 0 1881.332 1885.868 1881.338\n11 0 0 0 2 1 1 1942.363 1951.437 1942.381\n12 0 0 1 0 1 0 1809.358 1822.969 1809.393\n13 0 1 1 0 1 0 1611.588 1620.658 1611.605\n14 0 0 1 0 1 1 1809.358 1822.969 1809.393\n15 0 1 1 0 1 1 1611.588 1620.658 1611.605\n16 0 0 1 1 1 0 1809.358 1822.969 1809.393\n17 0 1 1 1 1 0 1611.588 1620.658 1611.605\n18 0 0 1 1 1 1 1809.358 1822.969 1809.393\n19 0 0 1 2 1 0 1809.358 1822.969 1809.393\n20 0 0 2 0 1 0 1728.571 1746.718 1728.629\n21 0 1 2 0 1 0 1611.137 1624.743 1611.172\n22 0 0 2 0 1 1 1728.571 1746.718 1728.629\n23 0 0 2 1 1 0 1728.571 1746.718 1728.629\n24 0 0 3 0 1 0 1713.789 1736.472 1713.877\n25 1 0 0 0 1 0 1708.277 1721.887 1708.312\n26 1 1 0 0 1 0 1713.364 1722.434 1713.381\n27 1 0 0 0 1 1 1708.277 1721.887 1708.312\n28 1 1 0 0 1 1 1713.364 1722.434 1713.381\n29 1 0 0 1 1 0 1708.277 1721.887 1708.312\n30 1 1 0 1 1 0 1713.364 1722.434 1713.381\n31 1 0 0 1 1 1 1708.277 1721.887 1708.312\n32 1 0 0 2 1 0 1708.277 1721.887 1708.312\n33 1 0 1 0 1 0 1601.649 1619.796 1601.707\n34 1 1 1 0 1 0 1610.324 1623.930 1610.359\n35 1 0 1 0 1 1 1601.649 1619.796 1601.707\n36 1 0 1 1 1 0 1601.649 1619.796 1601.707\n37 1 0 2 0 1 0 1603.227 1625.911 1603.315\n38 2 0 0 0 1 0 1640.939 1659.086 1640.997\n39 2 1 0 0 1 0 1680.368 1693.974 1680.403\n40 2 0 0 0 1 1 1640.939 1659.086 1640.997\n41 2 0 0 1 1 0 1640.939 1659.086 1640.997\n42 2 0 1 0 1 0 1603.142 1625.825 1603.229\n43 3 0 0 0 1 0 1631.451 1654.134 1631.539\n\nmod1candidate2 &lt;- arima(resid1, order = c(1,0,1), seasonal = list(order = c(0,1,0)))\ncheckresiduals(mod1candidate2)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,0,1)\nQ* = 13.208, df = 8, p-value = 0.1049\n\nModel df: 2.   Total lags used: 10\n\n\nThe function to evaluate various p,d,q values returns SARIMA(1,0,1)(0,1,0)[12] with the lowest AIC and BIC. The residuals of this second model show clear correlation around lags 2 and 4, which was not present in the 4,1,0 model that auto arima suggested. So overall, I would say the diagnostics look worse for the second model than the first.\n\nModel 3: (ARIMAX) IWM ~ Casualties + Hurricanes + Interest Rate 3-Months\n\n\nxMatrix3 = combinedData[,c('mo3delta', 'casualties', 'hurricaneWarnings')]\nxMatrix3[is.na(xMatrix3)] &lt;- 0\nxMatrix3 = scale(xMatrix3)\nxMatrix3 = as.matrix(xMatrix3)\n\n#xMatrix\n\nmod3candidate1 = auto.arima(scale(combinedData$iwmRange), xreg = xMatrix3, trace = TRUE)\n\n\n Fitting models using approximations to speed things up...\n\n Regression with ARIMA(2,1,2) errors : 1751.36\n Regression with ARIMA(0,1,0) errors : 1999.57\n Regression with ARIMA(1,1,0) errors : 1844.166\n Regression with ARIMA(0,1,1) errors : 1765.158\n Regression with ARIMA(0,1,0) errors : 1997.547\n Regression with ARIMA(1,1,2) errors : 1744.072\n Regression with ARIMA(0,1,2) errors : 1761.437\n Regression with ARIMA(1,1,1) errors : 1749.049\n Regression with ARIMA(1,1,3) errors : 1740.657\n Regression with ARIMA(0,1,3) errors : 1751.237\n Regression with ARIMA(2,1,3) errors : 1748.946\n Regression with ARIMA(1,1,4) errors : 1742.521\n Regression with ARIMA(0,1,4) errors : 1752.517\n Regression with ARIMA(2,1,4) errors : 1749.048\n Regression with ARIMA(1,1,3) errors : 1738.675\n Regression with ARIMA(0,1,3) errors : 1749.422\n Regression with ARIMA(1,1,2) errors : 1742.035\n Regression with ARIMA(2,1,3) errors : 1747.358\n Regression with ARIMA(1,1,4) errors : 1740.549\n Regression with ARIMA(0,1,2) errors : 1759.509\n Regression with ARIMA(0,1,4) errors : 1750.738\n Regression with ARIMA(2,1,2) errors : 1749.538\n Regression with ARIMA(2,1,4) errors : 1747.409\n\n Now re-fitting the best model(s) without approximations...\n\n Regression with ARIMA(1,1,3) errors : 1735.245\n\n Best model: Regression with ARIMA(1,1,3) errors \n\ncheckresiduals(mod3candidate1)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(1,1,3) errors\nQ* = 5.873, df = 6, p-value = 0.4376\n\nModel df: 4.   Total lags used: 10\n\n\nAuto.arima identifies (1,1,3) as the best model. The residuals show a low level of correlation in the lags, which is encouraging, and overall the residuals are mostly normally distributed although they are somewhat skewed to the right. Now, let’s see what we manually select, also considering a SARIMAX model.\nPrepare residuals:\n\nxMatrix3 = as.data.frame(xMatrix3)\n\n# Lets examine the residuals directly to identify \nmod3candidate2 &lt;- lm(scale(combinedData$iwmRange) ~ casualties + mo3delta + hurricaneWarnings, data = xMatrix3 )\nsummary(mod3candidate2)\n\n\nCall:\nlm(formula = scale(combinedData$iwmRange) ~ casualties + mo3delta + \n    hurricaneWarnings, data = xMatrix3)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.5534 -0.7062 -0.2568  0.4825  4.7271 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)        2.694e-17  3.804e-02   0.000   1.0000  \ncasualties         1.599e-02  3.830e-02   0.418   0.6764  \nmo3delta          -1.079e-02  3.811e-02  -0.283   0.7771  \nhurricaneWarnings  7.385e-02  3.833e-02   1.927   0.0545 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9992 on 686 degrees of freedom\nMultiple R-squared:  0.006013,  Adjusted R-squared:  0.001666 \nF-statistic: 1.383 on 3 and 686 DF,  p-value: 0.2467\n\nresid3 &lt;- mod3candidate2$residuals\npacf(resid3)\n\n\n\nacf(resid3)\n\n\n\n\nThe ACF and PACF plots of the residuals from linear regression are mixed, but there is clear correlation through value 5 in the PACF plot. The ACF plot has many significant terms, suggesting the series should be differenced. Now, I’ll loop through all the options to see if there is a suitable SARIMA model for the residuals:\n\noutput=SARIMA.c(p1=1,p2=3,q1=1,q2=4,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid3)\noutput %&gt;% filter(!is.na(p))\n\n   p d q P D Q      AIC      BIC     AICc\n1  0 0 0 0 1 0 1956.973 1966.046 1956.991\n2  0 1 0 0 1 0 1997.404 2001.939 1997.410\n3  0 0 0 0 1 1 1956.973 1966.046 1956.991\n4  0 1 0 0 1 1 1997.404 2001.939 1997.410\n5  0 0 0 1 1 0 1956.973 1966.046 1956.991\n6  0 1 0 1 1 0 1997.404 2001.939 1997.410\n7  0 0 0 1 1 1 1956.973 1966.046 1956.991\n8  0 1 0 1 1 1 1997.404 2001.939 1997.410\n9  0 0 0 2 1 0 1956.973 1966.046 1956.991\n10 0 1 0 2 1 0 1997.404 2001.939 1997.410\n11 0 0 0 2 1 1 1956.973 1966.046 1956.991\n12 0 0 1 0 1 0 1854.645 1868.255 1854.680\n13 0 1 1 0 1 0 1758.768 1767.838 1758.785\n14 0 0 1 0 1 1 1854.645 1868.255 1854.680\n15 0 1 1 0 1 1 1758.768 1767.838 1758.785\n16 0 0 1 1 1 0 1854.645 1868.255 1854.680\n17 0 1 1 1 1 0 1758.768 1767.838 1758.785\n18 0 0 1 1 1 1 1854.645 1868.255 1854.680\n19 0 0 1 2 1 0 1854.645 1868.255 1854.680\n20 0 0 2 0 1 0 1792.008 1810.155 1792.066\n21 0 1 2 0 1 0 1754.136 1767.742 1754.171\n22 0 0 2 0 1 1 1792.008 1810.155 1792.066\n23 0 0 2 1 1 0 1792.008 1810.155 1792.066\n24 0 0 3 0 1 0 1781.413 1804.096 1781.500\n25 1 0 0 0 1 0 1790.787 1804.397 1790.822\n26 1 1 0 0 1 0 1839.888 1848.958 1839.905\n27 1 0 0 0 1 1 1790.787 1804.397 1790.822\n28 1 1 0 0 1 1 1839.888 1848.958 1839.905\n29 1 0 0 1 1 0 1790.787 1804.397 1790.822\n30 1 1 0 1 1 0 1839.888 1848.958 1839.905\n31 1 0 0 1 1 1 1790.787 1804.397 1790.822\n32 1 0 0 2 1 0 1790.787 1804.397 1790.822\n33 1 0 1 0 1 0 1734.079 1752.226 1734.137\n34 1 1 1 0 1 0 1748.894 1762.499 1748.929\n35 1 0 1 0 1 1 1734.079 1752.226 1734.137\n36 1 0 1 1 1 0 1734.079 1752.226 1734.137\n37 1 0 2 0 1 0 1736.034 1758.717 1736.121\n38 2 0 0 0 1 0 1745.835 1763.981 1745.893\n39 2 1 0 0 1 0 1811.995 1825.600 1812.030\n40 2 0 0 0 1 1 1745.835 1763.981 1745.893\n41 2 0 0 1 1 0 1745.835 1763.981 1745.893\n42 2 0 1 0 1 0 1736.014 1758.697 1736.102\n\n\nThe best model identified by a small margin is SARIMA(1,0,1)(1,1,0). Let’s check the diagnostics\n\nresidualsMod3Can2 &lt;- arima(resid3, order = c(1,0,1), seasonal = list(order = c(1,1,0)))\ncheckresiduals(residualsMod3Can2)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,0,1)\nQ* = 17.291, df = 8, p-value = 0.02722\n\nModel df: 2.   Total lags used: 10\n\n\nThe residuals for this model arent encouraging, as the Ljung Box test returns a p value of 0.03. THe residuals also do not look perfectly normally distributed.\n\nModel 4: (ARIMAX) QQQ ~ All Interest Rates + All Extreme Weather Events + Daily VIX Change + Daily Striking Workers\n\nRunning an auto arima:\n\nxMatrix4 = combinedData[,c('mo3delta', 'mo6delta', 'mo12delta', 'events', 'dailyChange', 'workers')]\nxMatrix4[is.na(xMatrix4)] &lt;- 0\nxMatrix4 = scale(xMatrix4)\nxMatrix4 = as.matrix(xMatrix4)\n\n#xMatrix\n\nmod4candidate1 = auto.arima(scale(combinedData$qqqRange), xreg = xMatrix4, trace = TRUE)\n\n\n Fitting models using approximations to speed things up...\n\n Regression with ARIMA(2,1,2) errors : 1646.527\n Regression with ARIMA(0,1,0) errors : 1985.591\n Regression with ARIMA(1,1,0) errors : 1789.889\n Regression with ARIMA(0,1,1) errors : 1653.554\n Regression with ARIMA(0,1,0) errors : 1983.547\n Regression with ARIMA(1,1,2) errors : 1643.615\n Regression with ARIMA(0,1,2) errors : 1655.565\n Regression with ARIMA(1,1,1) errors : 1641.759\n Regression with ARIMA(2,1,1) errors : 1644.847\n Regression with ARIMA(2,1,0) errors : 1723.561\n Regression with ARIMA(1,1,1) errors : 1639.7\n Regression with ARIMA(0,1,1) errors : 1651.558\n Regression with ARIMA(1,1,0) errors : 1787.836\n Regression with ARIMA(2,1,1) errors : 1642.787\n Regression with ARIMA(1,1,2) errors : 1641.551\n Regression with ARIMA(0,1,2) errors : 1653.561\n Regression with ARIMA(2,1,0) errors : 1721.502\n Regression with ARIMA(2,1,2) errors : 1644.457\n\n Now re-fitting the best model(s) without approximations...\n\n Regression with ARIMA(1,1,1) errors : 1645.163\n\n Best model: Regression with ARIMA(1,1,1) errors \n\ncheckresiduals(mod4candidate1)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(1,1,1) errors\nQ* = 2.722, df = 8, p-value = 0.9506\n\nModel df: 2.   Total lags used: 10\n\n\nAuto Arima returns (1,1,1). The diagnostics look acceptable, although there is clustered volatility in the residual plot. The Ljung-Box test returns p = 0.95, suggesting there is not autocorrelation in the residuals. However, the residual lag plot has high correlation around lag 20, and the correlation of the residuals slightly increases as the lags get greater.\nNow let’s select a candidate manually, including from SARIMA models. First we calculate and review the residuals from the linear regression:\n\nxMatrix4 = as.data.frame(xMatrix4)\n\n# Lets examine the residuals directly to identify \nmod4candidate2 &lt;- lm(scale(combinedData$qqqRange) ~ mo3delta + mo6delta + mo12delta + events + dailyChange, data = xMatrix4 )\nsummary(mod1candidate2)\n\n\nCall:\narima(x = resid1, order = c(1, 0, 1), seasonal = list(order = c(0, 1, 0)))\n\nCoefficients:\n         ar1      ma1\n      0.1099  -0.8103\ns.e.  0.0612   0.0446\n\nsigma^2 estimated as 0.6001:  log likelihood = -802.16,  aic = 1610.32\n\nTraining set error measures:\n                       ME      RMSE       MAE       MPE     MAPE      MASE\nTraining set -0.008908356 0.7740864 0.5740772 -314.3173 543.1463 0.8413363\n                     ACF1\nTraining set -0.003214659\n\nresid4 &lt;- mod4candidate2$residuals\npacf(resid4)\n\n\n\nacf(resid4)\n\n\n\n\nThe ACF plot has many significant lags (&gt;10) which suggests we may need to difference the residuals. The PACF plot has high significance through lag 5. Let’s run a function to check all of the values up through p=2 and q=5.\n\nmod4candidate2fit =SARIMA.c(p1=1,p2=2,q1=1,q2=5,P1=1,P2=3,Q1=1,Q2=2,d1=0,d2=1,data=resid4)\nmod4candidate2fit %&gt;% filter(!is.na(p))\n\n   p d q P D Q      AIC      BIC     AICc\n1  0 0 0 0 1 0 1942.736 1951.809 1942.753\n2  0 1 0 0 1 0 1984.792 1989.327 1984.798\n3  0 0 0 0 1 1 1942.736 1951.809 1942.753\n4  0 1 0 0 1 1 1984.792 1989.327 1984.798\n5  0 0 0 1 1 0 1942.736 1951.809 1942.753\n6  0 1 0 1 1 0 1984.792 1989.327 1984.798\n7  0 0 0 1 1 1 1942.736 1951.809 1942.753\n8  0 1 0 1 1 1 1984.792 1989.327 1984.798\n9  0 0 0 2 1 0 1942.736 1951.809 1942.753\n10 0 1 0 2 1 0 1984.792 1989.327 1984.798\n11 0 0 0 2 1 1 1942.736 1951.809 1942.753\n12 0 0 1 0 1 0 1844.520 1858.130 1844.555\n13 0 1 1 0 1 0 1642.996 1652.067 1643.014\n14 0 0 1 0 1 1 1844.520 1858.130 1844.555\n15 0 1 1 0 1 1 1642.996 1652.067 1643.014\n16 0 0 1 1 1 0 1844.520 1858.130 1844.555\n17 0 1 1 1 1 0 1642.996 1652.067 1643.014\n18 0 0 1 1 1 1 1844.520 1858.130 1844.555\n19 0 0 1 2 1 0 1844.520 1858.130 1844.555\n20 0 0 2 0 1 0 1788.823 1806.970 1788.881\n21 0 1 2 0 1 0 1644.979 1658.584 1645.014\n22 0 0 2 0 1 1 1788.823 1806.970 1788.881\n23 0 0 2 1 1 0 1788.823 1806.970 1788.881\n24 0 0 3 0 1 0 1761.530 1784.214 1761.618\n25 1 0 0 0 1 0 1777.225 1790.835 1777.260\n26 1 1 0 0 1 0 1788.204 1797.275 1788.222\n27 1 0 0 0 1 1 1777.225 1790.835 1777.260\n28 1 1 0 0 1 1 1788.204 1797.275 1788.222\n29 1 0 0 1 1 0 1777.225 1790.835 1777.260\n30 1 1 0 1 1 0 1788.204 1797.275 1788.222\n31 1 0 0 1 1 1 1777.225 1790.835 1777.260\n32 1 0 0 2 1 0 1777.225 1790.835 1777.260\n33 1 0 1 0 1 0 1638.017 1656.164 1638.075\n34 1 1 1 0 1 0 1644.977 1658.583 1645.012\n35 1 0 1 0 1 1 1638.017 1656.164 1638.075\n36 1 0 1 1 1 0 1638.017 1656.164 1638.075\n37 1 0 2 0 1 0 1639.444 1662.128 1639.532\n\n\nThe best AIC and BIC scores returned by the function are for the model SARIMA(1,0,1)(1,1,0). Let’s look at the diagnostic plots to see how well this model captures the data:\n\nmod4candidate2fit = arima(resid4, order = c(1,0,1), seasonal = list(order = c(1,1,0)))\ncheckresiduals(mod4candidate2fit)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(1,0,1)\nQ* = 4.6414, df = 8, p-value = 0.7951\n\nModel df: 2.   Total lags used: 10\n\n\nThe residuals for this model look similar to the auto.arima model, so it will be interesting to compare them with cross validation. Otherwise, it is notable that the residuals display clustered volatility, while the lag plot shows significant correlations at some values, although the Ljung-Box test returns 0.795 so we can conclude there is no autocorrelation in the residuals.\n\nModel 5: (ARIMAX) QQQ ~ Interest Rate 3 months + Daily Property Damage + Daily VIX Change + Daily New Striking Workers\n\nI am leaving this model to fit after the homework.\n\nModel Selection for VAR Models\n\n\nModel 2: (VAR) SPY ~ Interest Rate 3-Months + Daily VIX Value\n\nStep 1, let’s fit VAR with p=1 just to see the relationship between our 3 variables (SPY intraday range, 3-month interest rate changes, and the real daily VIX values).\n\nxMatrix2 = combinedData[,c('VIX.Adjusted', 'mo3delta', 'spyRange') ]\nxMatrix2[is.na(xMatrix2)] &lt;- 0\nxMatrix2 = scale(xMatrix2)\nxMatrix2 = as.matrix(xMatrix2)\n\n#xMatrix\n\nsummary(vars::VAR(xMatrix2, p = 1, type = 'both'))\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: VIX.Adjusted, mo3delta, spyRange \nDeterministic variables: both \nSample size: 689 \nLog Likelihood: -1891.17 \nRoots of the characteristic polynomial:\n0.9396 0.05755 0.05755\nCall:\nvars::VAR(y = xMatrix2, p = 1, type = \"both\")\n\n\nEstimation results for equation VIX.Adjusted: \n============================================= \nVIX.Adjusted = VIX.Adjusted.l1 + mo3delta.l1 + spyRange.l1 + const + trend \n\n                  Estimate Std. Error t value Pr(&gt;|t|)    \nVIX.Adjusted.l1  9.330e-01  1.915e-02  48.710   &lt;2e-16 ***\nmo3delta.l1     -2.685e-02  1.301e-02  -2.064   0.0394 *  \nspyRange.l1      4.189e-03  1.888e-02   0.222   0.8245    \nconst            1.716e-02  2.680e-02   0.641   0.5221    \ntrend           -5.707e-05  6.794e-05  -0.840   0.4013    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.3372 on 684 degrees of freedom\nMultiple R-Squared: 0.8869, Adjusted R-squared: 0.8862 \nF-statistic:  1341 on 4 and 684 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation mo3delta: \n========================================= \nmo3delta = VIX.Adjusted.l1 + mo3delta.l1 + spyRange.l1 + const + trend \n\n                  Estimate Std. Error t value Pr(&gt;|t|)   \nVIX.Adjusted.l1 -0.0429432  0.0558806  -0.768  0.44247   \nmo3delta.l1     -0.1137505  0.0379419  -2.998  0.00282 **\nspyRange.l1     -0.1245585  0.0550961  -2.261  0.02409 * \nconst            0.1330199  0.0781812   1.701  0.08932 . \ntrend           -0.0003844  0.0001982  -1.939  0.05287 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.9838 on 684 degrees of freedom\nMultiple R-Squared: 0.03914,    Adjusted R-squared: 0.03352 \nF-statistic: 6.965 on 4 and 684 DF,  p-value: 1.69e-05 \n\n\nEstimation results for equation spyRange: \n========================================= \nspyRange = VIX.Adjusted.l1 + mo3delta.l1 + spyRange.l1 + const + trend \n\n                  Estimate Std. Error t value Pr(&gt;|t|)    \nVIX.Adjusted.l1  0.6616598  0.0403536  16.397  &lt; 2e-16 ***\nmo3delta.l1      0.0662097  0.0273994   2.416   0.0159 *  \nspyRange.l1      0.0661674  0.0397871   1.663   0.0968 .  \nconst           -0.3143373  0.0564577  -5.568 3.71e-08 ***\ntrend            0.0008977  0.0001431   6.271 6.34e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.7104 on 684 degrees of freedom\nMultiple R-Squared: 0.496,  Adjusted R-squared: 0.4931 \nF-statistic: 168.3 on 4 and 684 DF,  p-value: &lt; 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n             VIX.Adjusted  mo3delta spyRange\nVIX.Adjusted      0.11371 -0.019172 0.076451\nmo3delta         -0.01917  0.967841 0.006324\nspyRange          0.07645  0.006324 0.504715\n\nCorrelation matrix of residuals:\n             VIX.Adjusted  mo3delta spyRange\nVIX.Adjusted      1.00000 -0.057792 0.319129\nmo3delta         -0.05779  1.000000 0.009049\nspyRange          0.31913  0.009049 1.000000\n\n\nThe initial VAR fit is encouraging, as the 3 variables are all significant. SPY range has a p value of 0.09, which is slightly above the 0.05 threshold that would be ideal, but still suggests it helps explain the variance in the other variables in the model. The overall R squared and adjusted R squared are also encouraging, at 0.5, which is exceptionally high for a model concerning stock prices.\nNow lets use VAR select to identify some preferrable p values.\n\nvars::VARselect(xMatrix2, lag.max = 10, type = 'both')\n\n$selection\nAIC(n)  HQ(n)  SC(n) FPE(n) \n     5      1      1      5 \n\n$criteria\n                 1           2           3          4           5           6\nAIC(n) -2.95967636 -2.96412325 -2.96215454 -2.9562924 -3.00144103 -2.99099019\nHQ(n)  -2.92106481 -2.90234476 -2.87720911 -2.8481801 -2.87016173 -2.83654396\nSC(n)  -2.85992432 -2.80451997 -2.74270003 -2.6769867 -2.66228407 -2.59198201\nFPE(n)  0.05183573  0.05160586  0.05170783  0.0520123  0.04971693  0.05024022\n                 7           8           9          10\nAIC(n) -2.98502423 -2.96721214 -2.95685167 -2.95666268\nHQ(n)  -2.80741107 -2.76643204 -2.73290464 -2.70954871\nSC(n)  -2.52616482 -2.44850150 -2.37828980 -2.31824958\nFPE(n)  0.05054219  0.05145229  0.05199039  0.05200299\n\n\nVAR select returns either p =5 or p = 1 as the best fits, with AIC and FPE selecting p=5, and HQ and SC selecting p =1. We will use cross validation to compare these options.\n\nModel Evaluation\n\nIn this section, I will use cross validation to select the best candidate model for each of the 5 overaching model designs. First, lets define a cross validation function\n\n#######\n\ncrossVal &lt;- function(arima1order, arima2order, sarima2order, data) {\n\n    # window is always 1\n    test &lt;- 30\n    trainnum &lt;- length(data) - test\n    rmse1 &lt;- vector(mode = 'numeric', length = 30)\n    rmse2 &lt;- vector(mode = 'numeric', length = 30)\n\n    for(i in 1:30) {\n        #print(trainnum + ((i-1) * 4))\n        #print(trainnum + (i*4))\n        #print(trainnum + ((i-1) * 4) +1)\n        \n        xtrain &lt;- data[c(1:(trainnum + i - 1))]\n        xtest &lt;-  data[c((trainnum+1):(trainnum+i+1))]\n        \n        \n        \n        ######## first Model ############\n        fit &lt;- arima(xtrain, order = arima1order)\n        fcast &lt;- predict(fit, n.ahead = 1)$pred[1]\n        \n        \n        ######## second model ###########\n        fit2 &lt;- arima(xtrain, order = arima2order, seasonal = sarima2order)\n        fcast2 &lt;- predict(fit2, n.ahead = 1)$pred[1]\n        \n        # Errors\n\n        rmse1[i]  &lt;-sqrt((fcast-xtest[1])^2)\n        rmse2[i]  &lt;-sqrt((fcast2-xtest[1])^2)\n        \n    }\n    \n    outputs = data.frame(\"rmse1\" = rmse1, 'rmse2' = rmse2)\n    return(outputs)\n\n}\n\n\nModel 1 (ARIMAX)\n\nLets test the function out on the first model, comparing ARIMA(4,1,1) vs. SARIMA(1,0,1)(0,1,0) on the residuals of the linear regression.\n\nmodel1comparison = crossVal(c(4,1,1), c(1,0,1), list(order = c(0,1,0)), resid1)\n\nmean(model1comparison$rmse1)\n\n[1] 0.2690243\n\nmean(model1comparison$rmse2)\n\n[1] 0.2696219\n\n\nBetween the two models, model 1, selected by auto.arima, beats out the sarima model with a mean RMSE of 0.2690 vs. 0.2696. However, the models do perform similarly to eachother. Let’s look at a graph to make the difference more clear:\n\nindex1 = c(1:nrow(model1comparison))\nggplot(data = model1comparison, aes(x = index1, y = rmse1), color = 'blue') + geom_line() + geom_line(aes(x = index1, y = rmse2), color = 'red') + labs(title = 'Comparing RMSE of ARIMAX(4,1,1) Black and SARIMAX(1,0,1)(0,1,0) Red')\n\n\n\n\nAs we can see in the cross-validation chart, the two models perform similarly, and tend to have higher and lower errors at the same time, with both of the models performing poorly near the middle of the cross validation data sets. But overall, the ARIMA (ARIMAX) model performs the best at predicting the residuals. As such, my chosen model for Model 1 is ARIMAX(4,1,1).\n\nPredictions\n\nNow, let’s make predictions:\n\n#mod1candidate2 &lt;- lm(scale(combinedData$spyRange) ~ mo12delta + pdam + dailyChange + workers, data = xMatrix )\n\n\nmod1pdam &lt;- forecast(auto.arima(combinedData$pdam), 10)\nmod1delta12 &lt;- forecast(auto.arima(combinedData$mo12delta), 10)\nmod1dailyChange &lt;- forecast(auto.arima(combinedData$dailyChange), 10)\nmod1workers &lt;- forecast(auto.arima(combinedData$workers), 10)\n\npredictors1 &lt;- data.frame(cbind(pdam = mod1pdam$mean, mo12delta = mod1delta12$mean, dailyChange = mod1dailyChange$mean, workers = mod1workers$mean))\n\nfit = arima(combinedData$spyRange, order = c(4,1,1), xreg = xMatrix)\n\n#summary(fit)\n#forecast(fit)\nmod1 = predict(fit, newxreg = predictors1)\n\nautoplot(mod1$pred)\n\n\n\n\nHere we can see the models predictions for the SPY daily upcoming range, using auto.arima generated models to predict the external regressors. Overall, the model predicts a precipitous drop in the daily range in SPY prices in the upcoming 10 days.\n\nModel 3 (ARIMAX) IWM ~ Casualties + Hurricanes + Interest Rate 3-Months\n\nLet’s compare the model returned by auto.arima, ARIMA(1,1,3), vs the model I found by hand, SARIMA(1,0,1)(1,1,0), on the residuals of the linear regression for model 3.\n\nmodel3comparison = crossVal(c(1,1,3), c(1,0,1), list(order = c(1,1,0)), resid3)\n\nmean(model3comparison$rmse1)\n\n[1] 0.5537179\n\nmean(model3comparison$rmse2)\n\n[1] 0.6006214\n\n\nOnce again, the simple ARIMA model beats out the SARIMA architecture in terms of average RMSE. The average for ARIMA(1,1,3) was 0.554, while for SARIMA(1,0,1)(1,1,0) it was 0.601. Let’s look at a plot of the rmse values to see how the models fared:\n\nindex3 = c(1:nrow(model3comparison))\nggplot(data = model3comparison, aes(x = index3, y = rmse1), color = 'blue') + geom_line() + geom_line(aes(x = index3, y = rmse2), color = 'red') + labs(title = 'Comparing RMSE of ARIMAX(1,1,3) Black and SARIMAX(1,0,1)(1,1,0) Red')\n\n\n\n\nJust like for model 1, the two approaches performed similarly. If one model had a high RMSE for a particular value, the other model was likely to perform poorly as well. Overall however, we can see that for a given value the black line (ARIMA) tended to perform better. In the end, the ARIMAX models seems to fit the data well. As such, my chosen model for Model 3 is: ARIMAX(1,1,3)/.\n\nPredictions\n\nNow, let’s make predictions:\n\n#xMatrix3 = combinedData[,c('mo3delta', 'casualties', 'hurricaneWarnings')]\n\nmod3cas &lt;- forecast(auto.arima(combinedData$casualties), 10)\nmod3delta3 &lt;- forecast(auto.arima(combinedData$mo3delta), 10)\nmod3hurricane &lt;- forecast(auto.arima(combinedData$hurricaneWarnings), 10)\n\npredictors3 &lt;- data.frame(cbind(casualties = mod3cas$mean, mo3delta = mod3delta3$mean, hurricaneWarnings = mod3hurricane$mean))\n\nfit3 = arima(combinedData$iwmRange, order = c(1,1,3), xreg = xMatrix3)\n\n#summary(fit)\n#forecast(fit)\nmod3 = predict(fit3, newxreg = predictors3)\n\nautoplot(mod3$pred)\n\n\n\n\nHere we can see the models predictions for the IWM daily upcoming range, using auto.arima generated models to predict the external regressors. Overall, the model predicts a steep incline in IWM intraday ranges in the upcoming 10 days, especially in the first 5 before leveling off.\n\nModel 4 ARIMAX\n\nLeaving for future work.\n\nModel 5 ARIMAX\n\nLeaving for future work.\n\nModel 2 VAR\n\nLet’s forecast our VAR model, which used 3-month interest rate changes and daily VIX values to predict SPY’s intraday range. For this model we wanted to compare the p values of 1 and 5 to find the best model.\nLets, run our CV function:\n\ndata = xMatrix2\n\n    # window is always 1\n    test &lt;- 30\n    trainnum &lt;- nrow(data) - test\n    rmse1 &lt;- matrix(NA, 30,3)\n    rmse1 &lt;- data.frame(rmse1)\n    rmse2 &lt;- matrix(NA, 30,3)\n    rmse2 &lt;- data.frame(rmse2)\n\n    for(i in 1:29) {\n\n        xtrain &lt;- data[c(1:(trainnum + i - 1)),]\n        xtest &lt;-  data[c((trainnum+i):(trainnum+i+1)),]\n        \n        \n        \n        ######## first Model ############\n        fit &lt;- vars::VAR(xtrain, p = 1, type = 'both')\n        \n        fcast &lt;- predict(fit, n.ahead = 1)$fcst\n        \n        ff&lt;-data.frame(fcast$VIX.Adjusted[,1],fcast$mo3delta[,1],fcast$spyRange[,1])\n        \n        ######## second model ###########\n        fit2 &lt;- vars::VAR(xtrain,p =5, type = 'both')\n        fcast2 &lt;- predict(fit2, n.ahead = 1)$fcst\n        \n        ff2&lt;-data.frame(fcast2$VIX.Adjusted[,1],fcast2$mo3delta[,1],fcast2$spyRange[,1])\n\n        # Errors\n\n        rmse1[i,]  = sqrt((ff-xtest)^2)\n        rmse2[i,]  = sqrt((ff2-xtest)^2)\n        \n    }\n    \n    \n#print(rmse1)\n\n\nnames(rmse1) =c(\"VIXPrice\", \"3mo\",\"SPYDailyRange\")\nnames(rmse2) =c(\"VIXPrice\", \"3mo\",\"SPYDailyRange\")\n\ncolMeans(rmse1, na.rm = TRUE)\n\n     VIXPrice           3mo SPYDailyRange \n    0.1477893     1.1090823     0.6958689 \n\ncolMeans(rmse2, na.rm = TRUE)\n\n     VIXPrice           3mo SPYDailyRange \n    0.1387773     1.1899464     0.6822915 \n\n\nAfter cross validating the 2 VAR models across 30 1-day intervals, we obtain the following average RMSE for the different variables: VIX Price: p=1 -&gt; 0.148, p=5 -&gt; 0.139. 3 Month Interest Rate Changes: p=1 -&gt; 1.109, p=5 -&gt; 1.190. SPY Daily Range: p=1 -&gt; 0.696, p=5 -&gt; 0.682.\nOverall, the p=1 VAR model was better at predicting the interest rate changes variable, and the p=5 VAR model performed better on the VIX Price and SPY daily range variables.\nLet’s plot their performance:\n\nindex2 = c(1:nrow(rmse1))\n\nggplot() + \n  geom_line(data = rmse1, aes(x = index2, y = VIXPrice),color = \"blue\") +\n  geom_line(data = rmse2, aes(x = index2, y = VIXPrice),color = \"red\") +\n  labs(\n    title = \"CV RMSE for Vix Prices, Blue = (p=1), Red = (p=5)\",\n    x = \"Date\",\n    y = \"RMSE\",\n    guides(colour=guide_legend(title=\"Fit\")))\n\nWarning: Removed 1 row(s) containing missing values (geom_path).\nRemoved 1 row(s) containing missing values (geom_path).\n\n\n\n\nggplot() + \n  geom_line(data = rmse1, aes(x = index2, y = SPYDailyRange),color = \"blue\") +\n  geom_line(data = rmse2, aes(x = index2, y = SPYDailyRange),color = \"red\") +\n  labs(\n    title = \"CV RMSE for SPY Daily Range, Blue = (p=1), Red = (p=5)\",\n    x = \"Date\",\n    y = \"RMSE\",\n    guides(colour=guide_legend(title=\"Fit\")))\n\nWarning: Removed 1 row(s) containing missing values (geom_path).\nRemoved 1 row(s) containing missing values (geom_path).\n\n\n\n\n\nOverall, the charts show what we confirmed with the average values: That the mean performance of the p=5 model was better on average.\nNow let’s predict:\n\nfinalmod2 = vars::VAR(xMatrix2, p = 5, type = 'both')\n        \nmod2forecast &lt;- predict(finalmod2, n.ahead = 10)$fcst\n\nindexmod2 = c(1:10)\nggplot() +\n    geom_line(aes(x = indexmod2, y = mod2forecast$spyRange[1:10]),color = \"blue\") +\n    geom_line(aes(x = indexmod2, y = mod2forecast$mo3delta[1:10]),color = \"red\") +\n    geom_line(aes(x = indexmod2, y = mod2forecast$VIX.Adjusted[1:10]),color = \"green\")\n\n\n\n\nHere we can see the scale forecasts for the 3 key variables, which are created with the predict function for the VAR model with p=5. Overall, the model predicts the SPY range to raise slightly for the next 10 days, and the 3 month interest rates to change sharply."
  },
  {
    "objectID": "Data Visualization.html",
    "href": "Data Visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "The central question of this research project is about stock market volatility. As such the following visualizations will explore this subject in different areas. To start with, let’s define the outcome variables in question:\nFor each security: S&P 500, QQQ Pro-Shares ETF, and Russell 200 index, we have several metrics 1. Price 2. Standard deviation (10 day window) 3. True range (intraday difference between highest and lowest price/previous closing value) 4. Trading volume\nThe window of our investigation is January 1st 2021 - September 30th 2023.\n\nlibrary(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.2.1     v dplyr   1.1.2\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(quantmod)\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\n######################### Warning from 'xts' package ##########################\n#                                                                             #\n# The dplyr lag() function breaks how base R's lag() function is supposed to  #\n# work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n# source() into this session won't work correctly.                            #\n#                                                                             #\n# Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n# conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n# dplyr from breaking base R's lag() function.                                #\n#                                                                             #\n# Code in packages is not affected. It's protected by R's namespace mechanism #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n###############################################################################\n\n\n\nAttaching package: 'xts'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nLoading required package: TTR\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nspyIn &lt;- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn &lt;- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn &lt;- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\nhead(spyIn)\n\n           SPY.Open SPY.High SPY.Low SPY.Close SPY.Volume SPY.Adjusted\n2021-01-04   375.31   375.45  364.82    368.79  110210800     354.1974\n2021-01-05   368.10   372.50  368.05    371.33   66426200     356.6370\n2021-01-06   369.71   376.98  369.12    373.55  107997700     358.7690\n2021-01-07   376.10   379.90  375.91    379.10   68766800     364.0995\n2021-01-08   380.59   381.49  377.10    381.26   71677200     366.1740\n2021-01-11   377.85   380.58  377.72    378.69   51034700     363.7057\n\nhead(qqqIn)\n\n           QQQ.Open QQQ.High QQQ.Low QQQ.Close QQQ.Volume QQQ.Adjusted\n2021-01-04   315.11   315.29  305.18    309.31   45305900     304.2443\n2021-01-05   308.29   312.14  308.29    311.86   29323400     306.7526\n2021-01-06   307.00   311.88  305.98    307.54   52809600     302.5034\n2021-01-07   310.28   315.84  310.25    314.98   30394800     309.8215\n2021-01-08   317.34   319.39  315.08    319.03   33955800     313.8051\n2021-01-11   315.98   317.19  313.75    314.42   32746400     309.2707\n\nhead(iwmIn)\n\n           IWM.Open IWM.High IWM.Low IWM.Close IWM.Volume IWM.Adjusted\n2021-01-04   197.54   197.89  190.94    193.50   33664200     186.8583\n2021-01-05   193.09   197.62  193.07    196.49   27442900     189.7456\n2021-01-06   199.48   206.78  199.16    204.53   52952200     197.5097\n2021-01-07   205.71   208.52  205.70    208.17   24031400     201.0247\n2021-01-08   209.32   209.77  204.66    207.72   29017000     200.5902\n2021-01-11   205.09   208.12  204.83    207.54   20945100     200.4164\n\n\nLet’s start by simply seeing the absolute prices of these securities over time:\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\ncombinedCloses &lt;- cbind(spyIn$SPY.Close, qqqIn$QQQ.Close, iwmIn$IWM.Close)\n\n\nts.plot(combinedCloses, gpars = list(col = rainbow(3)))\n\nlegend(\"topleft\", legend = c(\"SPY\", \"QQQ\", \"IWM\"), col = 1:3, lty = 1)\n\n\n\n\nIn these charts, we can see that the overall trend for all three securities has been somewhat of a decline since the start of the time window. We can also see that QQQ and IWM have moved further in their trends than SPY, which makes sense as that is the most stable index of the three.\nNow, let us look at the intraday range volatility measure.\n\nspyIn$spyRange &lt;- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange &lt;- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange &lt;- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n\ncombinedIntradayPercentRange &lt;- cbind(spyIn$spyRange, qqqIn$qqqRange, iwmIn$iwmRange)\n\nhead(qqqIn$pctRange)\n\nNULL\n\nts.plot(combinedIntradayPercentRange, gpars = list(col = rainbow(3)))\n\nlegend(\"topleft\", legend = c(\"SPY\", \"QQQ\", \"IWM\"), col = 1:3, lty = 1)\n\ntitle(\"Daily High-Low Range as Percent of Open Price\")\n\n\n\n\nIn this chart, we can see that the three indices tended to move together, with the midpoint of the time window having a higher average range in daily prices than the beginning or end for all of the securities. However, we can also see again that volatility is not even between them, with SPY and IWM having higher daily ranges than QQQ on average (at least according to the naked eye).\nNow, let’s review the trends in the federal funds rate:\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\ndff &lt;- read.csv(\"./dff.csv\")\n\ndff &lt;- dff %&gt;%\n    mutate(DATE = ymd(DATE)) %&gt;%\n    filter(DATE &gt;= ymd(\"2021-01-01\"))\n\nplot3 &lt;- ggplot(dff, aes(x = DATE, y = DFF)) + geom_line() + labs(y = \"Daily Federal Fund Rate\", x = \"Time\", title = \"Daily Federal Funds Rate over Time\")\nggplotly(plot3)"
  },
  {
    "objectID": "dv.html",
    "href": "dv.html",
    "title": "Data Vizes in TS",
    "section": "",
    "text": "-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.2.1     v dplyr   1.1.2\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\n######################### Warning from 'xts' package ##########################\n#                                                                             #\n# The dplyr lag() function breaks how base R's lag() function is supposed to  #\n# work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n# source() into this session won't work correctly.                            #\n#                                                                             #\n# Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n# conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n# dplyr from breaking base R's lag() function.                                #\n#                                                                             #\n# Code in packages is not affected. It's protected by R's namespace mechanism #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n###############################################################################\n\n\n\nAttaching package: 'xts'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nLoading required package: TTR\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\n\n\n\n\nThis chart shows the extreme volatility of Moderna’s stock price compared to its peers. The stock has gone from the cheapest of the 5 per share, to the most expensive by a factor of 2, back down to the 2nd most expensive, in the 3-year window visible. Meanwhile, the other 4 stocks have followed a roughly slow and steady upward trend, with Abbivie and Amgen having the greatest progression during the time period.\n\n\n\n\n\n\nHere, we see a steep downward trend in BTC price before Winter 2022, however BTC price has recovered from the low and roughly stabalized after that inflection point.\n\n\n\n\n\n\nThe candlestick chart shows how volatile bitcoins price can be in each day of the window studied. The candlesticks show wide intraday ranges in price.\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\n      STATION                      NAME       DATE DAPR MDPR PRCP SNOW SNWD\n1 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-06   NA   NA    0    0   NA\n2 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-07   NA   NA    0    0   NA\n3 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-08   NA   NA    0    0   NA\n4 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-09   NA   NA    0    0   NA\n5 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-10   NA   NA    0    0   NA\n6 US1DCDC0009 WASHINGTON 2.0 SSW, DC US 2021-03-11   NA   NA    0    0   NA\n  TMAX TMIN TOBS WESD\n1   NA   NA   NA   NA\n2   NA   NA   NA   NA\n3   NA   NA   NA   NA\n4   NA   NA   NA   NA\n5   NA   NA   NA   NA\n6   NA   NA   NA   NA\n\n\nWarning: Removed 69 rows containing missing values (position_stack).\n\n\n\n\n\n\nthis chart shows the total precipitation recorded at 7 stations by month of the year. We can see the USC00182325 has a substantially higher total precipitation amount in August and September than all the other months. It is dubious, however, that the same station records no precipitation from October to December, and it leads me to wonder about whether the data is faulty. Secondly, we can see August has the highest total amount of precipitation recorded in the dataset.\n\n\n\n\n\n\nHere, we can see the CPI index has increased steadily since the 1940s, with a slower period of increase between 1960 and 1970, and a higher period of increase between 1970 and 1980, followed by a marked jump after 2020."
  },
  {
    "objectID": "Introduction.html",
    "href": "Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "For this project the time series I will be studying are major stock market indices, specifically the S&P 500, the Russel 2000, and the Nasdaq 100 (QQQ). The purpose of this project is to understand the factors driving the price of these indices, looking at climate events such as wildfires and hurricanes, investor confidence, macroeconomic data, and the impacts of COVID-19. I will use the statistical models we learn in class to investigate the relationships of these factors on stock market prices."
  },
  {
    "objectID": "Introduction.html#topic-explanation",
    "href": "Introduction.html#topic-explanation",
    "title": "Introduction",
    "section": "",
    "text": "For this project the time series I will be studying are major stock market indices, specifically the S&P 500, the Russel 2000, and the Nasdaq 100 (QQQ). The purpose of this project is to understand the factors driving the price of these indices, looking at climate events such as wildfires and hurricanes, investor confidence, macroeconomic data, and the impacts of COVID-19. I will use the statistical models we learn in class to investigate the relationships of these factors on stock market prices."
  },
  {
    "objectID": "Introduction.html#the-big-picture",
    "href": "Introduction.html#the-big-picture",
    "title": "Introduction",
    "section": "The Big Picture:",
    "text": "The Big Picture:\nFinancial markets are directly important to the well-being of everyday Americans. While the stock market is often seen as exclusive to a small circle of elite investors, in reality millions of Americans have exposure to the markets through retirement funds, which are made up of many different kinds of investments. If we can become better at predicting the course of financial markets, particularly in relation to external forces like climate change, it could promise to reduce volatility and inefficiency in the market. In turn, this would help everyday people build up their savings to enjoy a better quality of life, retire sooner, or have more security.\nFurther, understanding the movements of financial markets is important in controlling sentiment. In cases like the onset of the COVID-19 pandemic, stock market crashes could snowball into businesses cutting more jobs than needed, which would again directly impact everyday peoples’ livelihoods. With the hope of understanding these phenomena better, this project will look directly at investor sentiment and the impact of COVID-19.\n\n\n\nBig Picture"
  },
  {
    "objectID": "Introduction.html#analytical-angles",
    "href": "Introduction.html#analytical-angles",
    "title": "Introduction",
    "section": "Analytical Angles:",
    "text": "Analytical Angles:\nFirst, looking at stock prices as individual univariate time series. Conceptually, we are studying any intrinsic characteristics or patterns that publicly-traded stocks might have. This focuses on the properties of stocks themselves, and not how they react to external stimuli. Second, understanding stock prices as objects which are reflective of individuals actions and preferences. In this case, the individuals in question are investors, and we will look at investor sentiment and see how it might affect prices in financial markets. Third, viewing changes in stock prices in the context of external stimuli. From this analytical perspective, the stock market is a closed system, which is disrupted by external forces from time-to-time that cause unexpected behaviour. Studying the impact of climate events and economic data releasing will pertain to this point. Fourth, using stocks at output variables, which are a tool to investigate the impact of serious events like COVID-19. In this case, we are interested in looking at how the onset of COVID rippled through the stock market, and what we could learn from stock prices to help ameliorate similar disasters in the future."
  },
  {
    "objectID": "Introduction.html#literature-review",
    "href": "Introduction.html#literature-review",
    "title": "Introduction",
    "section": "Literature Review:",
    "text": "Literature Review:\nMany of the factors this project seeks to investigate have previously been reviewed by academics. For instance, the consequence of investor sentiment on the stock market has been widely studied, in terms of how it impacts stock market crises (Zouaoui, Nouyrigat, and Beer 2011), trading volume (So and Lei 2015), and especially returns (Smales 2017). Further, authors have previously found an impact of climate events, such as hurricanes (Liu, Ferreira, and Karali 2021) on stock prices of particular companies. The fact that these issues have been studied previously is encouraging, because in each case the authors chose a specific group of time and company limited stock market data. This project might extend their results to other stock market datasets, and might hope to incorporate these relationships into new statistical models"
  },
  {
    "objectID": "Introduction.html#guiding-questions",
    "href": "Introduction.html#guiding-questions",
    "title": "Introduction",
    "section": "Guiding Questions:",
    "text": "Guiding Questions:\n\nHow do markets react in anticipation of the release of macroeconomic data?\nHow do markets react when their predictions about macroeconomic data are more or less accurate?\nHow does investor confidence impact markets?\nCan time series data from financial markets tell us anything about future levels of investor confidence?\nHow does the stock market react to the increasing prevalence of climate events such as hurricanes, wildfires?\nWhich securities are most impacted by climate events?\nHow has COVID changed stock prices in the months and years after the onset of the pandemic?\nCan we predict the impact of future black swan events on the stock market by looking at COVID’s example?\nHow do the prices of different securities impact eachother?\nHow have the relationships between the prices of securities changed over time?"
  },
  {
    "objectID": "Financial Time Series Models (ARCH GARCH).html",
    "href": "Financial Time Series Models (ARCH GARCH).html",
    "title": "Financial Time Series Models (ARCH GARCH)",
    "section": "",
    "text": "Introduction\n\nOn this page, I will look to see whether ARCH and GARCH models may be a good fit for the intraday range of popular stock market indices. While these models would usually be fitted on the returns of financial intstruments, intraday percent range also exhibits volatility clustering, and intraday range is the exact subject of my project. This means that modelling these time series successfully would be complementary with the other models I have tried to fit, and I am eager to investigate whether these methods will work well at answering my research questions. I will look to fit 3 models: 1 each for the daily range of SPY, QQQ, and IWM.\n\nStationarity and Volatility\n\nLoad packages\n\n\nCode\nlibrary(tidyverse)\n\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.4.4     v purrr   1.0.1\nv tibble  3.2.1     v dplyr   1.1.2\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(forecast)\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nCode\nlibrary(quantmod)\n\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\n######################### Warning from 'xts' package ##########################\n#                                                                             #\n# The dplyr lag() function breaks how base R's lag() function is supposed to  #\n# work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n# source() into this session won't work correctly.                            #\n#                                                                             #\n# Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n# conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n# dplyr from breaking base R's lag() function.                                #\n#                                                                             #\n# Code in packages is not affected. It's protected by R's namespace mechanism #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n###############################################################################\n\n\n\nAttaching package: 'xts'\n\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nLoading required package: TTR\n\n\nRead in data\n\n\nCode\nspyIn &lt;- quantmod::getSymbols(\"SPY\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\nqqqIn &lt;- quantmod::getSymbols(\"QQQ\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\niwmIn &lt;- quantmod::getSymbols(\"IWM\", from = as.Date(\"2021/01/01\"), to = as.Date(\"2023/09/30\"), periodicity = \"daily\", src = \"yahoo\", auto.assign = FALSE)\n\n\nspyIn$spyRange &lt;- (spyIn$SPY.High - spyIn$SPY.Low)/ spyIn$SPY.Open\nqqqIn$qqqRange &lt;- (qqqIn$QQQ.High - qqqIn$QQQ.Low)/ qqqIn$QQQ.Open\niwmIn$iwmRange &lt;- (iwmIn$IWM.High - iwmIn$IWM.Low)/ iwmIn$IWM.Open\n\n\nPlotting the daily ranges:\nSPY\n\n\nCode\nplot(spyIn$spyRange %&gt;% diff())\n\n\n\n\n\nThe SPY data certainly appears to have clustered volatility, as there are large swings in close proximity to eachother.\nQQQ\n\n\nCode\nplot(qqqIn$qqqRange)\n\n\n\n\n\nIWM\n\n\nCode\nplot(iwmIn$iwmRange)\n\n\n\n\n\n\nLook at past arima model for the data (fit here and copy to that tab later)\n\n\nLook at residuals, they will be clustered, decide to fit further\n\n\nFind ARCH or GARCH Model by looking at squared residuals and returns of each model.\n\n\nLjung box tests and model diagnostics for each model\n\n\nWriting out the final equations of the model"
  }
]